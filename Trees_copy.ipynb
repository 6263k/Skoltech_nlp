{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rdY16hLSRXXm"
   },
   "source": [
    "# Final project on topic\n",
    "# Named entity recognition: recognition quality of ontological objects depending on the depth of hyponymy\n",
    "\n",
    "### By Dochkina V. and Bragin D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hrni2z0FzPq"
   },
   "source": [
    "# General information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_AYnQhbjFzPs"
   },
   "source": [
    "Named-entity recognition (NER) is one of the most important tasks in the field of natural language processing (Natural language\n",
    "processing, NLP).\n",
    "\n",
    "The task of NER is to highlight and classify named entities in the text. A named entity is a word or phrase meaning subject or phenomenon of a certain category. Named entities are personalities (PERSON), names of organizations (ORGANIZATION), locations (LOCATION) and others. Example of tagged text: \n",
    "\"[ORGANIZATION Skoltech], is a Russian university, located in [LOCATION Moscow]\"\n",
    "\n",
    "Hyponyms are words that name objects (properties, attributes) as\n",
    "elements of a class (set) and consisting in a relationship of hyponymy with a word - the name of this class (hyperonym). For example, the words: ring, bracelet, necklace are\n",
    "hyponyms in relation to the word jewelry, and vice versa, from the point of view of the inverse relationship, jewelry acts as a hyperonym in relation to the words ring, bracelet,\n",
    "necklace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_H3o_BUFzPt"
   },
   "source": [
    "# Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZU_sy-CFzPw"
   },
   "source": [
    "The goal of our study is to highlight the object and then determine it to a specific type, that is, the comparison of a hyponym with its hyperonym. At the same time, the depth of hyponymy can be multilevel. For example, \"Mont Blanc\" refers to the Mountain class,\n",
    "which in turn belongs to the Geographic location class.\n",
    "The obtained information about ontological objects is useful in various tasks related to natural language processing, including answers to questions posed by the user and extracting dependencies between objects.\n",
    "\n",
    "To do that texts in the English language are used, followed by extraction of named entities. In the problem, proposals are given in the form of a sequence of tokens $w =\n",
    "= (w_1, w_2, ..., w_n)$ , and we need to output a sequence of tags $y = (y_1, y_2, ..., y_n)$.\n",
    "\n",
    "For this, the BIO markup format is used and each ontological object receives a tag corresponding to a given level of hyponymy. For every entity is built\n",
    "a chain of corresponding hyperonyms based on data from the WordNet system. Sets\n",
    "data differ depending on the given depth of hyponymy. The problem is solved with\n",
    "using standard NER models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phuvWK7OFzPx"
   },
   "source": [
    "# Main methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDvZyd5cFzPz"
   },
   "source": [
    "For the NER task, a neural network model with a hybrid architecture is used: BiLSTM-CRF.\n",
    "\n",
    "### Recurrent Neural Networks\n",
    "\n",
    "Unlike multilayer perceptrons, recurrent networks can use their internal memory to process sequences of arbitrary length. In real\n",
    "regular RNN only stores information about a short context (gradient attenuation).\n",
    "LSTM lacks such a drawback - a non-network recursive block consisting of the following elements: Main layers (as in usual RNN), three sigmoidal filter layers, Cell\n",
    "memory. Formulas for these components:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UdOqAHo0FzPz"
   },
   "source": [
    "\\begin{equation}  \n",
    "i_t= \\sigma( W_{ix}x_t+ W_{ih}h_{t-1}+b_i),\n",
    "\\end{equation}\n",
    "\\begin{equation}   \n",
    "f_t = \\sigma( W_{fx}x_t+ W_{fh}h_{t-1}+b_f),\n",
    "\\end{equation}\n",
    " \\begin{equation}  \n",
    "c_n = g( W_{cx}x_t+ W_{ch}h_{t-1}+b_c),\n",
    "\\end{equation}\n",
    " \\begin{equation}  \n",
    "c_t = f_{tt-1}+i_t  \\circ c_n,\n",
    "\\end{equation}\n",
    "\\begin{equation}  \n",
    "h_t = o_t\\circ g(c_t),\n",
    "\\end{equation}\n",
    "\\begin{equation}  o_t =  \\sigma( W_{ox}x_t+ W_{oh}h_{t-1}+b_o)\n",
    "\\end{equation}\n",
    "\n",
    "Variables:\n",
    "\n",
    "$ x_t $  - input vector\n",
    "$ h_ {t} $ is the output vector,\n",
    "$ c_ {t} $ - state vector,\n",
    "$ W, U $ and $ b $ are parameter matrices and a vector,\n",
    "$ f_t, i_ {t} $ and $ {o_ {t}} $ are the gate vectors,\n",
    "$ f_t $ - vector of forgetting gate, weight of remembering old information,\n",
    "$ {i_ {t}} $ - vector of the input gate, weight of receiving new information,\n",
    "$ {o_ {t}} $ - vector of the output gate, candidate for the output.\n",
    "\n",
    "\n",
    "Activation functions:\n",
    "\n",
    "\n",
    "$ {\\sigma _{g}} $ : sigmoida based.\n",
    "\n",
    "$ \\sigma _{c} $ : hyperbolitc tangens based.\n",
    "\n",
    "$ {\\ sigma _ {h}} $: based on the hyperbolic tangent, but in the work on the eyes (inspection holes) for LSTM it is assumed that $ {\\ sigma _ {h} (x) = x} $\n",
    "\n",
    "\n",
    "**Sigmoid**:\n",
    "\n",
    "$$f (x) = \\frac {1} {1 + e ^ x}$$\n",
    "- $ f (x) \\ in [0,1] $ - allows modeling probabilities\n",
    " - Differentiable and monotonous\n",
    " - Generalized by the softmax function\n",
    "\n",
    "\n",
    "**Hyperbolic tangens**:\n",
    "\n",
    "$$f (x) = tanh (x) $$\n",
    "- All properties of sigmoid\n",
    " - The value of $ f (x) $ is always non-negative\n",
    " - Commonly used for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2e01xDNaFzP1"
   },
   "source": [
    "### Bidirectional recurrent neural networks (Bi-LSTM) \n",
    "Bi-LSTM were designed to encode each element in a sequence, taking into account left and right contexts,\n",
    "making it one of the best options for the NER task. Normal LSTM takes into account\n",
    "only past contexts, bidirectional and future ones. The calculation of the bidirectional model consists of two stages: the first layer calculates the representation of the left context and the second layer calculates the representation of the right context. Outputs of these steps then\n",
    "combine to obtain a complete representation of an input sequence element. Bidirectional LSTM encoders have been shown to be useful in many NLP tasks,\n",
    "such as machine translation, answering questions, and especially to solve the NER problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6Zm4EEuFzP2"
   },
   "source": [
    "### CRF model for NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvW0T3ViFzP3"
   },
   "source": [
    "Conditional Random Field (CRF) is a probabilistic model for structural forecasting, which has been successfully applied in various fields, including natural language processing.\n",
    "The CRF model is trained to predict the vector of $  {y} = {y_0, y_1, ... y_n} $ tags, taking into account the sentence $ {x} = {x_0, x_1, .., x_N}. $ For this, the conditional probability:\n",
    " \n",
    "$$ p ( {y} \\mid  {x}) =\n",
    "\\frac {e ^ {Score (\\vec {x}, \\vec {y})}} {\\sum_ {y ^ {'}} e ^ {Score (\\vec {x}, \\vec {y})} } $$\n",
    "where $ Score $ is calculated by the formula:\n",
    " \n",
    "$$ Score (\\vec {x}, \\vec {y}) = \\sum_ {i = 0} ^ {n} A_ {y_i, y_ {i + 1}} + \\sum_ {i = 1} ^ {n } P_i y_i $$\n",
    "\n",
    "where $ A_ {y_i, y_ {i + 1}} $ denotes the probability of transition from the tag $ i $ to the tag $ j $, $ P_ {i, j}$ is the probability of transition, which represents the estimate of the $j-$th tag of the ith the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nT_UpVpeFzP5"
   },
   "source": [
    "### Combination of Bi-LSTM and CRF model\n",
    "\n",
    "In a combined model, the characters of each word in a sentence are fed into the network\n",
    "Bi-LSTM in order to capture the character features of words. Then these vector representations of the character level are combined with the word embedding vectors and\n",
    "transferred to another Bi-LSTM network. This network computes a sequence of ratings that represent the tag probabilities for each word in a sentence. To raise\n",
    "prediction accuracy, CRF level is trained to apply restrictions depending on\n",
    "tag order. For example, in the BIO scheme tag (B - Begin, I - Inside, O - Other) I never\n",
    "appears at the beginning of a sentence, or O I B O is an invalid tag sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmR1xdVrFzP6"
   },
   "source": [
    "# Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading WordNet lexical database to determine synsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "sS3rQJUL-V1o",
    "outputId": "7fba34ed-a6c5-4264-ac3e-fc69f478e61b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Даниил\n",
      "[nltk_data]     Брагин\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "Y8L_JWTOPBGT",
    "outputId": "e3f73305-982c-4928-ed90-72fb7c128a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pptree\n",
      "  Downloading https://files.pythonhosted.org/packages/19/62/1e4c3c30b722d6c41c3c92cd8cef723e93b48dde9adb1ae64b30583543b4/pptree-2.0.tar.gz\n",
      "Building wheels for collected packages: pptree\n",
      "  Building wheel for pptree (setup.py): started\n",
      "  Building wheel for pptree (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\1859~1\\AppData\\Local\\pip\\Cache\\wheels\\68\\b2\\d4\\6028fa5c48fc258dd13129ddb85dedc8e0ca85a11fdaff9829\n",
      "Successfully built pptree\n",
      "Installing collected packages: pptree\n",
      "Successfully installed pptree-2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pptree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0j762TaI-WOK"
   },
   "outputs": [],
   "source": [
    "from pptree import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mf3-2SGEAgvD"
   },
   "source": [
    "Visualization of tree by using wordnet (with the help of the functionget_tree) for depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNw2FjqZ-WPW"
   },
   "outputs": [],
   "source": [
    "word='j'\n",
    "def get_tree(word, tr=Node(word), first=1, hmax=3, current_h=1):\n",
    "    if first == 1: \n",
    "        try:\n",
    "            word_sn = wn.synsets(word)[0]\n",
    "            nod = Node(word)\n",
    "        except:\n",
    "            print('There is no such word in the dictionary') \n",
    "            return Node('error')\n",
    "    else:\n",
    "        word_sn = word\n",
    "        nod = Node(word_sn.lemma_names()[0], tr)\n",
    "    \n",
    "    current_h += 1\n",
    "    \n",
    "    if current_h <= hmax:\n",
    "        \n",
    "        nodes = word_sn.hyponyms()\n",
    "        \n",
    "        for node in nodes:\n",
    "            _ = get_tree(node, nod, first=0, current_h=current_h, hmax=hmax)\n",
    "        \n",
    "    return nod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qixO9D28AvMN"
   },
   "source": [
    "Visualization of tree for english word 'machine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "5vg-YEN8Pius",
    "outputId": "9ee0dfdd-86bc-4706-a751-726858860f8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('cyborg.n.01')]\n",
      "        ┌assembly\n",
      "        ├bagger\n",
      "        ├calculator\n",
      "        ├calender\n",
      "        ├cash_machine\n",
      "        ├comber\n",
      "        ├computer\n",
      "        ├concrete_mixer\n",
      "        ├corker\n",
      "        ├cotton_gin\n",
      "        ├decoder\n",
      "        ├farm_machine\n",
      "        ├franking_machine\n",
      "        ├hop-picker\n",
      "        ├machine_tool\n",
      "        ├machinery\n",
      "        ├milking_machine\n",
      "        ├motor\n",
      "        ├pavior\n",
      "        ├perpetual_motion_machine\n",
      "        ├pile_driver\n",
      " machine┤\n",
      "        ├Zamboni\n",
      "        ├workhorse\n",
      "        ├trimmer\n",
      "        ├time_machine\n",
      "        ├textile_machine\n",
      "        ├stapler\n",
      "        ├staple_gun\n",
      "        ├stamp\n",
      "        ├sorter\n",
      "        ├snow_thrower\n",
      "        ├slot_machine\n",
      "        ├slicer\n",
      "        ├simulator\n",
      "        ├self-feeder\n",
      "        ├riveting_machine\n",
      "        ├record_player\n",
      "        ├printer\n",
      "        ├press\n",
      "        ├press\n",
      "        ├power_tool\n",
      "        └power_shovel\n"
     ]
    }
   ],
   "source": [
    "word = 'machine'\n",
    "word_sn = wn.synsets(word)\n",
    "print(word_sn[1].hyponyms())\n",
    "\n",
    "t = get_tree(word, hmax=2)\n",
    "\n",
    "print_tree(t) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fN4obxzEBAdp"
   },
   "source": [
    "Here we are going to choose only some of the leaves of hyponymy/hypernomy tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "id": "70d1jxfVw0dw",
    "outputId": "ff0a81f3-84ed-416d-e374-e2c5f2175db1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        ┌economic process\n",
      "                                        ├human process\n",
      "                       ┌physical process┤\n",
      "                       │                ├organic process\n",
      "                       │                ├natural process\n",
      "                       │                └industrial process\n",
      "       ┌physical entity┤\n",
      "       │               │               ┌geological formation\n",
      "       │               │               ├land\n",
      "       │               │               ├location\n",
      "       │               └physical object┤\n",
      "       │                               ├artifact\n",
      "       │                               ├natural object\n",
      "       │                               └living thing\n",
      " __root┤\n",
      "       │                                     ┌cognition\n",
      "       │               ┌physiological feature┤\n",
      "       │               │                     ├event\n",
      "       │               │                     └motivation\n",
      "       └abstract entity┤\n",
      "                       │       ┌value\n",
      "                       │       ├volume\n",
      "                       ├measure┤\n",
      "                       │       ├time interval\n",
      "                       │       └time unit\n",
      "                       │         ┌time\n",
      "                       └attribute┤\n",
      "                                 ├quality\n",
      "                                 └property\n"
     ]
    }
   ],
   "source": [
    "root = Node(name='__root')\n",
    "\n",
    "first = {'physical entity': Node('physical entity', parent=root), \n",
    "         'abstract entity': Node('abstract entity', parent=root)}\n",
    "\n",
    "second = {'physical object': Node('physical object', parent=first['physical entity']), \n",
    "          'physical process': Node('physical process', parent=first['physical entity']),\n",
    "          \n",
    "          'physiological feature': Node('physiological feature', parent=first['abstract entity']),\n",
    "          'attribute': Node('attribute', parent=first['abstract entity']),\n",
    "          'measure': Node('measure', parent=first['abstract entity'])}\n",
    "\n",
    "third = {'geological formation': Node('geological formation', parent=second['physical object']),\n",
    "         'land': Node('land', parent=second['physical object']),\n",
    "         'location': Node('location', parent=second['physical object']),\n",
    "         'living thing': Node('living thing', parent=second['physical object']),\n",
    "         'natural object': Node('natural object', parent=second['physical object']),\n",
    "         'artifact': Node('artifact', parent=second['physical object']),\n",
    "         \n",
    "         'economic process': Node('economic process', parent=second['physical process']),\n",
    "         'human process': Node('human process', parent=second['physical process']),\n",
    "         'industrial process': Node('industrial process', parent=second['physical process']),\n",
    "         'natural process': Node('natural process', parent=second['physical process']),\n",
    "         'organic process': Node('organic process', parent=second['physical process']),\n",
    "          \n",
    "         'cognition': Node('cognition', parent=second['physiological feature']),\n",
    "         'motivation': Node('motivation', parent=second['physiological feature']),\n",
    "         'event': Node('event', parent=second['physiological feature']),\n",
    "         \n",
    "         'time': Node('time', parent=second['attribute']),\n",
    "         'property': Node('property', parent=second['attribute']),\n",
    "         'quality': Node('quality', parent=second['attribute']),\n",
    "         \n",
    "         'value': Node('value', parent=second['measure']),\n",
    "         'volume': Node('volume', parent=second['measure']),\n",
    "         'time unit': Node('time unit', parent=second['measure']),\n",
    "         'time interval': Node('time interval', parent=second['measure']),\n",
    "\n",
    "         }\n",
    "\n",
    "print_tree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOXXWULtBRjj"
   },
   "source": [
    "Function that is going to return hyponyms of the chosen word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PrpPZDyZAPpE"
   },
   "outputs": [],
   "source": [
    "def get_all_hyps_by_word(word, first=1):\n",
    "    \n",
    "    hypo = lambda s: s.hyponyms()\n",
    "    words = []\n",
    "    wsynsets = [x for x in wn.synsets(word) if x.pos()=='n']\n",
    "    clos = lambda s: s.closure(hypo) \n",
    "    \n",
    "    synsets = []\n",
    "    for wsynset in wsynsets:\n",
    "        synsets += clos(wsynset)\n",
    "    for synset in synsets:\n",
    "        words = words + synset.lemma_names()\n",
    "        \n",
    "    return list(set(words))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNkUh9ZbC3YD"
   },
   "outputs": [],
   "source": [
    "def space_to__(a):\n",
    "    return '_'.join(a.split())\n",
    "\n",
    "def __to_space(a):\n",
    "    return ' '.join(a.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "cUTZj7Zl-eIZ",
    "outputId": "35d9d740-d8ae-445e-a7fc-65181ee8fa6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geological_formation\n",
      "land\n",
      "location\n",
      "living_thing\n",
      "natural_object\n",
      "artifact\n",
      "economic_process\n",
      "human_process\n",
      "industrial_process\n",
      "natural_process\n",
      "organic_process\n",
      "cognition\n",
      "motivation\n",
      "event\n",
      "time\n",
      "property\n",
      "quality\n",
      "value\n",
      "volume\n",
      "time_unit\n",
      "time_interval\n"
     ]
    }
   ],
   "source": [
    "dictionary = set()\n",
    "\n",
    "for key in third:\n",
    "    node = third[key]\n",
    "    print(space_to__(key))\n",
    "    words = get_all_hyps_by_word(word=space_to__(key))\n",
    "    for word in words:\n",
    "        word = __to_space(word)\n",
    "        \n",
    "        if word not in dictionary:\n",
    "            Node(word, parent=node)\n",
    "        \n",
    "        dictionary.add(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount of children nodes for a certain hyponym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "zJz5xNonRv8m",
    "outputId": "ae8b8740-52ac-43d6-e928-1106e5ff3ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65082\n",
      "geological formation 271\n",
      "land 199\n",
      "location 1721\n",
      "living thing 30042\n",
      "natural object 1211\n",
      "artifact 13431\n",
      "economic process 22\n",
      "human process 78\n",
      "industrial process 13\n",
      "natural process 410\n",
      "organic process 800\n",
      "cognition 5138\n",
      "motivation 69\n",
      "event 8512\n",
      "time 168\n",
      "property 1492\n",
      "quality 1418\n",
      "value 2\n",
      "volume 0\n",
      "time unit 49\n",
      "time interval 36\n"
     ]
    }
   ],
   "source": [
    "print(len(list(dictionary)))\n",
    "for key in third:\n",
    "    node = third[key]\n",
    "    print(key, len(node.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DrSQ80I7U9Si",
    "outputId": "b9b12333-9f44-4a64-8288-e7180272f562"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo = lambda s: s.hyponyms()\n",
    "list(wn.synsets('time')[1].closure(hypo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "pCbSiHd7V-m1",
    "outputId": "ec2bcf0b-f354-4267-cf80-a39d7356ce87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gloam',\n",
       " 'Pacific_Standard_Time',\n",
       " 'nightfall',\n",
       " 'Last_Judgment',\n",
       " 'June_21',\n",
       " 'upbeat',\n",
       " 'allegro',\n",
       " 'good_old_days',\n",
       " 'twelve_noon',\n",
       " 'Atlantic_Standard_Time']"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_hyps_by_word('time')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nm3vkx-Fgub"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ATBzVSaQFepV",
    "outputId": "115c72aa-6a26-446b-f201-ad112b1cdaf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deeppavlov\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/9d/453d101981b293441be889ba91d6983abdeeb2b3abc070b47a4044f6a64b/deeppavlov-0.7.1-py3-none-any.whl (735kB)\n",
      "\r",
      "\u001b[K     |▌                               | 10kB 21.3MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 20kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 30kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 40kB 2.0MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 51kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 61kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 71kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 81kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 92kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 102kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 112kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 122kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 133kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 143kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 153kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 163kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 174kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 184kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 194kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 204kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 215kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 225kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 235kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 245kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 256kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 266kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 276kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 286kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 296kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 307kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 317kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 327kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 337kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 348kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 358kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 368kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 378kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 389kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 399kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 409kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 419kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 430kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 440kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 450kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 460kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 471kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 481kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 491kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 501kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 512kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 522kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 532kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 542kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 552kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 563kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 573kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 583kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 593kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 604kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 614kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 624kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 634kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 645kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 655kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 665kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 675kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 686kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 696kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 706kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 716kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 727kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 737kB 3.3MB/s \n",
      "\u001b[?25hCollecting overrides==1.9\n",
      "  Downloading https://files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz\n",
      "Collecting fuzzywuzzy==0.17.0\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
      "Collecting requests==2.22.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 8.3MB/s \n",
      "\u001b[?25hCollecting scipy==1.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2MB 96kB/s \n",
      "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
      "\u001b[K     |████████████████████████████████| 8.0MB 14.5MB/s \n",
      "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
      "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
      "Collecting Cython==0.29.12\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/2f/b08ad77c639040baafc891621f0cfdb209e2266404ca13c3167970a6f6d6/Cython-0.29.12-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 25.1MB/s \n",
      "\u001b[?25hCollecting pymorphy2==0.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
      "\u001b[?25hCollecting fastapi==0.38.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/59/1a42dde38f1ae2a7a318947e54fabd1fc02ac423ecc91957c417065e7cc6/fastapi-0.38.1-py3-none-any.whl (160kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 57.7MB/s \n",
      "\u001b[?25hCollecting scikit-learn==0.21.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7MB 50.8MB/s \n",
      "\u001b[?25hCollecting tqdm==4.32.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/3d/7a6b68b631d2ab54975f3a4863f3c4e9b26445353264ef01f465dc9b0208/tqdm-4.32.2-py2.py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
      "\u001b[?25hCollecting pandas==0.24.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1MB 47.6MB/s \n",
      "\u001b[?25hCollecting pyopenssl==19.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/c8/ceb170d81bd3941cbeb9940fc6cc2ef2ca4288d0ca8929ea4db5905d904d/pyOpenSSL-19.0.0-py2.py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
      "\u001b[?25hCollecting keras==2.2.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 57.9MB/s \n",
      "\u001b[?25hCollecting h5py==2.9.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8MB 46.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (3.2.5)\n",
      "Collecting uvicorn==0.9.0\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/a9/2ab492155d9b76cf109c2370e201822ba3c7f4aed85f5a1b4d22907e7206/uvicorn-0.9.0.tar.gz\n",
      "Collecting pytelegrambotapi==3.6.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/5e/9711642455c4e17b1202d4f6403ede0fef37fc145038aee7193f3b24445e/pyTelegramBotAPI-3.6.6.tar.gz (49kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n",
      "\u001b[?25hCollecting numpy==1.16.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3MB 102kB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n",
      "Collecting dawg-python>=0.7\n",
      "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
      "Collecting pymorphy2-dicts<3.0,>=2.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1MB 24.9MB/s \n",
      "\u001b[?25hCollecting pydantic<=0.32.2,>=0.32.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/78/2edcc6e65ec020403ac6ba6deb54c1cf227c49232ce9d98a1ae7ebdfa3a1/pydantic-0.32.2-cp36-cp36m-manylinux1_x86_64.whl (5.1MB)\n",
      "\u001b[K     |████████████████████████████████| 5.1MB 40.7MB/s \n",
      "\u001b[?25hCollecting starlette<=0.12.8,>=0.11.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/4a/90a6a8685fcbdcf544a2293d0d0211ecba3cd7f309b831499d5c895383cb/starlette-0.12.8.tar.gz (45kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov) (0.14.1)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->deeppavlov) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->deeppavlov) (2.6.1)\n",
      "Collecting cryptography>=2.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 48.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from pyopenssl==19.0.0->deeppavlov) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (3.13)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.0.8)\n",
      "Requirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (7.0)\n",
      "Collecting h11==0.8.*\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/f3/8e4cf5fa1a3d8bda942a0b1cf92f87815494216fd439f82eb99073141ba0/h11-0.8.1-py2.py3-none-any.whl (55kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n",
      "\u001b[?25hCollecting websockets==8.*\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 11.8MB/s \n",
      "\u001b[?25hCollecting httptools==0.0.13\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/03/215969db11abe8741e9c266a4cbe803a372bd86dd35fa0084c4df6d4bd00/httptools-0.0.13.tar.gz (104kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 60.9MB/s \n",
      "\u001b[?25hCollecting uvloop==0.*\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9MB 32.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic<=0.32.2,>=0.32.2->fastapi==0.38.1->deeppavlov) (0.7)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.3->pyopenssl==19.0.0->deeppavlov) (1.13.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3->pyopenssl==19.0.0->deeppavlov) (2.19)\n",
      "Building wheels for collected packages: overrides, uvicorn, pytelegrambotapi, starlette, httptools\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for overrides: filename=overrides-1.9-cp36-none-any.whl size=4214 sha256=db698601234f21e5ffe7f171dad421727a40c4984de5f5568a31929c078250f0\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/52/86/e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718\n",
      "  Building wheel for uvicorn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for uvicorn: filename=uvicorn-0.9.0-cp36-none-any.whl size=37118 sha256=9af3c8b29e612d0af24472836ec320d129103840251cdaf1c3be6f22647ca5d6\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/e5/d1/a50d405d3bb18fac538ef9606ed9b6cd5efb6e06b6de834507\n",
      "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.6-cp36-none-any.whl size=44856 sha256=05a9d7bb790a87deeebc72c619a6cbb8202d9b4e194c0bd15a98f3546286bcc4\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/69/d7/26f1fb04ac4d4c95bff643cea765a8e91c4348da25b4744e08\n",
      "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for starlette: filename=starlette-0.12.8-cp36-none-any.whl size=56910 sha256=2156a9a8352233868e3929af24159ddde8434b5fa9f685960d74d066b409f328\n",
      "  Stored in directory: /root/.cache/pip/wheels/fd/a0/1d/17eb20c5742e3236799a7883e56325823d57fcd8ce2a0c9348\n",
      "  Building wheel for httptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for httptools: filename=httptools-0.0.13-cp36-cp36m-linux_x86_64.whl size=212540 sha256=d8e421e9c7280d2205c801c40f668bc6680aecbd56fb761aea08bb2cd47a11f1\n",
      "  Stored in directory: /root/.cache/pip/wheels/e8/3e/2e/013f99b42efc25cf3589730cf380738e46b1e5edaf2f78d525\n",
      "Successfully built overrides uvicorn pytelegrambotapi starlette httptools\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.25.0; python_version >= \"3.0\", but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: overrides, fuzzywuzzy, requests, numpy, scipy, pymorphy2-dicts-ru, rusenttokenize, Cython, dawg-python, pymorphy2-dicts, pymorphy2, pydantic, starlette, fastapi, scikit-learn, tqdm, pandas, cryptography, pyopenssl, h5py, keras, h11, websockets, httptools, uvloop, uvicorn, pytelegrambotapi, deeppavlov\n",
      "  Found existing installation: requests 2.21.0\n",
      "    Uninstalling requests-2.21.0:\n",
      "      Successfully uninstalled requests-2.21.0\n",
      "  Found existing installation: numpy 1.17.4\n",
      "    Uninstalling numpy-1.17.4:\n",
      "      Successfully uninstalled numpy-1.17.4\n",
      "  Found existing installation: scipy 1.3.3\n",
      "    Uninstalling scipy-1.3.3:\n",
      "      Successfully uninstalled scipy-1.3.3\n",
      "  Found existing installation: Cython 0.29.14\n",
      "    Uninstalling Cython-0.29.14:\n",
      "      Successfully uninstalled Cython-0.29.14\n",
      "  Found existing installation: scikit-learn 0.21.3\n",
      "    Uninstalling scikit-learn-0.21.3:\n",
      "      Successfully uninstalled scikit-learn-0.21.3\n",
      "  Found existing installation: tqdm 4.28.1\n",
      "    Uninstalling tqdm-4.28.1:\n",
      "      Successfully uninstalled tqdm-4.28.1\n",
      "  Found existing installation: pandas 0.25.3\n",
      "    Uninstalling pandas-0.25.3:\n",
      "      Successfully uninstalled pandas-0.25.3\n",
      "  Found existing installation: h5py 2.8.0\n",
      "    Uninstalling h5py-2.8.0:\n",
      "      Successfully uninstalled h5py-2.8.0\n",
      "  Found existing installation: Keras 2.2.5\n",
      "    Uninstalling Keras-2.2.5:\n",
      "      Successfully uninstalled Keras-2.2.5\n",
      "Successfully installed Cython-0.29.12 cryptography-2.8 dawg-python-0.7.2 deeppavlov-0.7.1 fastapi-0.38.1 fuzzywuzzy-0.17.0 h11-0.8.1 h5py-2.9.0 httptools-0.0.13 keras-2.2.4 numpy-1.16.4 overrides-1.9 pandas-0.24.2 pydantic-0.32.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.404381.4453942 pyopenssl-19.0.0 pytelegrambotapi-3.6.6 requests-2.22.0 rusenttokenize-0.0.5 scikit-learn-0.21.2 scipy-1.3.0 starlette-0.12.8 tqdm-4.32.2 uvicorn-0.9.0 uvloop-0.14.0 websockets-8.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy",
         "pandas",
         "requests",
         "scipy",
         "sklearn",
         "tqdm"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5G7yzSVRGTEK",
    "outputId": "9362ea01-3335-47f3-f35b-d55639667247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email-validator not installed, email fields will be treated as str.\n",
      "To install, run: pip install email-validator\n",
      "2019-12-18 16:12:25.807 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'ner_ontonotes' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_ontonotes.json'\n",
      "Collecting gensim==3.7.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/4b/19eecdf07d614665fa889857dc56ac965631c7bd816c3476d2f0cac6ea3b/gensim-3.7.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2MB 108kB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.16.4)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.9.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.3.0)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (1.10.36)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (2.22.0)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (1.13.36)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (0.2.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (2.8)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.7.0->gensim==3.7.3) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.7.0->gensim==3.7.3) (0.15.2)\n",
      "Installing collected packages: gensim\n",
      "  Found existing installation: gensim 3.6.0\n",
      "    Uninstalling gensim-3.6.0:\n",
      "      Successfully uninstalled gensim-3.6.0\n",
      "Successfully installed gensim-3.7.3\n",
      "Collecting tensorflow==1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K     |████████████████████████████████| 109.2MB 21kB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 19.7MB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 50.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (42.0.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "  Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "  Found existing installation: tensorflow 1.15.0\n",
      "    Uninstalling tensorflow-1.15.0:\n",
      "      Successfully uninstalled tensorflow-1.15.0\n",
      "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install ner_ontonotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPcXIy-EDXX-"
   },
   "source": [
    "Setting up 3 levels of depht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGSfymeFMxpv"
   },
   "outputs": [],
   "source": [
    "levels = [['entity']]\n",
    "levels.append(['physical entity', 'abstract entity'])\n",
    "levels.append(['physical object', 'physical process', 'psychological feature', 'attribute', 'measure'])\n",
    "levels.append(['geological formation', 'land', 'location', 'living thing', 'natural object', 'artifact'] +\n",
    "        ['economic process', 'human process', 'industrial process', 'natural process', 'organic process'] +\n",
    "        ['cognition', 'motivation', 'event', 'time', 'property', 'quality'] +\n",
    "        ['value', 'volume', 'time unit', 'time interval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjIXBrUvUE8w"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71-CzGL1M2XT"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, synset, parent=None):\n",
    "        self.children = []\n",
    "        if parent:\n",
    "            parent.children.append(self)\n",
    "        self.parent = parent\n",
    "        self.synset = synset\n",
    "       \n",
    "    def __str__(self):\n",
    "        return ', '.join(self.synset.lemma_names() )#[0]\n",
    "    \n",
    "\n",
    "# nodes instead of synset store their parents name in dict,\n",
    "# like names of all of its childrens, childrens of children etc.\n",
    "class Leave:     \n",
    "    def __init__(self, tag_dict, parent):\n",
    "        self.children = []\n",
    "        parent.children = [self]\n",
    "        self.parent = parent\n",
    "        self.dict = tag_dict\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '**leave: ' + str(len(self.dict))#', '.join(list(self.dict))\n",
    "    \n",
    "def hypo_closure(synset):\n",
    "    return synset.closure(hypo)\n",
    "\n",
    "def add_child(parent, synset):\n",
    "    child = Node(synset, parent)\n",
    "    return child\n",
    "\n",
    "def add_dict_child(parent):           \n",
    "    # filling up dict\n",
    "    hypo_clsr = list(hypo_closure(parent.synset))\n",
    "    child_names = []\n",
    "    \n",
    "    for hyponym in hypo_clsr:\n",
    "        child_names += hyponym.lemma_names()\n",
    "        \n",
    "    #adding the name of the parent itself\n",
    "    # dict holds all words corresponding to tag-parent\n",
    "    child_names += parent.synset.lemma_names()\n",
    "    tag_dict = set(child_names)\n",
    "    child = Leave(tag_dict, parent)\n",
    "        \n",
    "    return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2zzKe_2M6KR"
   },
   "outputs": [],
   "source": [
    "hypo = lambda s: s.hyponyms()\n",
    "hyper = lambda s: s.hypernyms()\n",
    "\n",
    "#Hierarchy class\n",
    "class Hierarchy:\n",
    "    \n",
    "    def __init__(self, levels, root_synset):\n",
    "        self.levels = levels\n",
    "        self.leaves = []\n",
    "        self.max_depth = len(levels) - 1\n",
    "        self.root_synset = root_synset\n",
    "        self.root = Node(root_synset)\n",
    "\n",
    "    def build(self, parent=None, depth=1) :\n",
    "        if not parent :\n",
    "            parent = self.root\n",
    "        \n",
    "        if depth > self.max_depth:\n",
    "            child = add_dict_child(parent)\n",
    "            self.leaves.append(child)\n",
    "            return\n",
    "\n",
    "        for synset in hypo(parent.synset):\n",
    "            #print (hypo(parent.synset))\n",
    "            if set(self.levels[depth]) & set([x.replace('_', ' ') for x in synset.lemma_names()]):\n",
    "                child = add_child(parent, synset)\n",
    "                self.build(child, depth+1)\n",
    "\n",
    "        return parent\n",
    "    \n",
    "    def get_tag(self, string):\n",
    "        string = string.replace(' ', '_')\n",
    "        candidates = []\n",
    "        for leave in self.leaves:\n",
    "            if string in leave.dict:\n",
    "                candidates.append(leave.parent.synset.lemma_names()[0])\n",
    "            \n",
    "        return random.choice(candidates) if candidates else 'O'\n",
    "      \n",
    "    def decrease_level(self):\n",
    "        new_leaves = []\n",
    "        new_tags = set()\n",
    "        for leave in self.leaves:\n",
    "            new_tags.add(leave.parent.parent)\n",
    "    \n",
    "        for new_tag in new_tags:\n",
    "            new_tag_dict = set()\n",
    "            for new_tag_child in new_tag.children:\n",
    "                new_tag_dict |= new_tag_child.children[0].dict # tag has just one  child\n",
    "            \n",
    "            new_tag_dict |= set(new_tag.synset.lemma_names())          \n",
    "            new_leaves.append(Leave(new_tag_dict, new_tag))            \n",
    "            \n",
    "        self.max_depth -= 1\n",
    "        self.leaves = new_leaves\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CsRWy88YM9Gj"
   },
   "outputs": [],
   "source": [
    "hierarchy = Hierarchy(levels, wn.synsets('entity')[0])\n",
    "entity = hierarchy.build()\n",
    "\n",
    "#whole = wn.synset('whole.n.02')\n",
    "#malually add artifact, living_thing, synset\n",
    "artifact = wn.synset('artifact.n.01')\n",
    "living_thing = wn.synset('living_thing.n.01')\n",
    "natural_object = wn.synset('natural_object.n.01')\n",
    "\n",
    "\n",
    "for i in entity.children :\n",
    "    if i.__str__() == 'physical_entity':\n",
    "        for j in i.children :\n",
    "            if j.__str__() == 'object, physical_object':\n",
    "                for synset in [artifact, living_thing, natural_object]:\n",
    "                    child = add_child(j, synset)\n",
    "                    hierarchy.leaves.append(add_dict_child(child))\n",
    "for i in entity.children :\n",
    "    if i.__str__() == 'abstraction, abstract_entity':\n",
    "        for j in i.children :\n",
    "            if j.__str__() == 'measure, quantity, amount':\n",
    "                    synset = wn.synset('time_period.n.01')\n",
    "                    child = add_child(j, synset)\n",
    "                    hierarchy.leaves.append(add_dict_child(child))\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "Ct5wDlMuUeOf",
    "outputId": "4899d740-6b97-4dc1-e55c-9f702d33b29d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['living_thing',\n",
       " 'artifact',\n",
       " 'artifact',\n",
       " 'living_thing',\n",
       " 'living_thing',\n",
       " 'artifact',\n",
       " 'artifact']"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hierarchy.get_tag('dog') for _ in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MhC6kgS9-v82",
    "outputId": "866380f8-5af8-49eb-c1b6-323858e3ab67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'living_thing'"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy.get_tag('hedgehog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DC2K22KJOgf8",
    "outputId": "73726894-9543-4e68-e1a5-68548396d407"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time_period'"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy.get_tag('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ELbToJQZ-uVH",
    "outputId": "3bbc6a1f-ae32-4dfb-ed26-6864e3216008"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cognition'"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy.get_tag('pure mathematics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aohlqANjhsli"
   },
   "outputs": [],
   "source": [
    "#hierarchy.decrease_level()\n",
    "#print_tree(hierarchy.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mCIGGtxth3o_",
    "outputId": "42c89695-9890-4d30-ada7-17aa2c64d5df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cognition'"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy.get_tag('pure mathematics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsFyLBZUlCz5"
   },
   "outputs": [],
   "source": [
    "#hierarchy.decrease_level()\n",
    "#hierarchy.get_tag('pure mathematics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "etlx5kT2yTYc",
    "outputId": "60ea4ca8-66e8-4f57-c8c5-b73321d7fe0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-18 16:13:42--  https://github.com/Intelligent-Systems-Phystech/2018-Project-19/raw/master/X.txt\n",
      "Resolving github.com (github.com)... 140.82.113.3\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/Intelligent-Systems-Phystech/2018-Project-19/master/X.txt [following]\n",
      "--2019-12-18 16:13:43--  https://raw.githubusercontent.com/Intelligent-Systems-Phystech/2018-Project-19/master/X.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7965488 (7.6M) [text/plain]\n",
      "Saving to: ‘X.txt’\n",
      "\n",
      "X.txt               100%[===================>]   7.60M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2019-12-18 16:13:43 (79.0 MB/s) - ‘X.txt’ saved [7965488/7965488]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/Intelligent-Systems-Phystech/2018-Project-19/raw/master/X.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9l5JTZerQXKa"
   },
   "outputs": [],
   "source": [
    "#Path to the dataset - WOS5736\n",
    "with open('X.txt') as f:\n",
    "    content = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGBnP86Ucm9p"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "len(content)\n",
    "texts = []\n",
    "for one_text in content:\n",
    "    texts.append(one_text.lower())\n",
    "text = texts[0]\n",
    "texts_array = []\n",
    "for text in texts:\n",
    "    texts_array.append(re.findall(r\"[\\w']+|[.,!?;\\'\\\"]\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpRf5rjrcti9"
   },
   "outputs": [],
   "source": [
    "def tag_text(hierarchy, text):\n",
    "    string = ''\n",
    "    r = 0\n",
    "    for word_number in range(0,len(text)-1):\n",
    "        if r == 1: \n",
    "            r = 0\n",
    "            continue\n",
    "        if text[word_number]=='.':\n",
    "            string += '. O\\n\\n'\n",
    "        else:\n",
    "            if hierarchy.get_tag(text[word_number]+' '+text[word_number+1]) == 'O':\n",
    "                if hierarchy.get_tag(text[word_number]) == 'O':\n",
    "                    string += text[word_number] + ' O\\n'\n",
    "                else:\n",
    "                    string += text[word_number] + ' B-' + hierarchy.get_tag(text[word_number]) + '\\n'\n",
    "            else:\n",
    "                string += text[word_number] + ' B-' + hierarchy.get_tag(text[word_number]) + '\\n'\n",
    "                string += text[word_number+1] + ' I-' + hierarchy.get_tag(text[word_number]) + '\\n'\n",
    "                r = 1\n",
    "    string += '. O\\n\\n'\n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDp_XZVxdDJA"
   },
   "outputs": [],
   "source": [
    "markup_third_lvl = []\n",
    "for text in texts_array[:5]: \n",
    "    markup_third_lvl.append(tag_text(hierarchy, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_maJT-6bPEA"
   },
   "outputs": [],
   "source": [
    "#print(markup_third_lvl[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VlFsxDc34FIc"
   },
   "outputs": [],
   "source": [
    "markup_second_lvl = []\n",
    "hierarchy.decrease_level()\n",
    "for text in texts_array[:5]:\n",
    "    markup_second_lvl.append(tag_text(hierarchy, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SQJRBahU4G6T"
   },
   "outputs": [],
   "source": [
    "markup_first_lvl = []\n",
    "hierarchy.decrease_level()\n",
    "for text in texts_array[:5]:\n",
    "    markup_first_lvl.append(tag_text(hierarchy, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68mmbhNTAwPC"
   },
   "outputs": [],
   "source": [
    "def splitter(markup):\n",
    "    return markup[:3], markup[3:4], markup[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3rkit-_AwCf"
   },
   "outputs": [],
   "source": [
    "markups = [markup_first_lvl, markup_second_lvl, markup_third_lvl]\n",
    "\n",
    "for i, markup in enumerate(markups):\n",
    "    train, test, validation = splitter(markup)\n",
    "    \n",
    "    import os\n",
    "\n",
    "    dest_dir = os.path.join(\"dataset_\" + str(i+1))\n",
    "    try:\n",
    "        os.makedirs(dest_dir)\n",
    "    except OSError:\n",
    "        pass # already exists\n",
    "    \n",
    "    with open(\"dataset_\" + str(i+1) +\"/train.txt\", \"w\") as file:\n",
    "        for j in train:\n",
    "            print(j, file=file)\n",
    "    with open(\"dataset_\" + str(i+1)+ \"/test.txt\", \"w\") as file:\n",
    "        for j in test:\n",
    "            print(j, file=file)\n",
    "    with open(\"dataset_\" + str(i+1) + \"/validation.txt\", \"w\") as file:\n",
    "        for j in validation:\n",
    "            print(j, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "colab_type": "code",
    "id": "ozP_aOQYAv22",
    "outputId": "eb8fa6b6-4bde-41c6-8108-54b3c6b5f580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email-validator not installed, email fields will be treated as str.\n",
      "To install, run: pip install email-validator\n",
      "2019-12-18 16:13:46.255 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'ner_ontonotes' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_ontonotes.json'\n",
      "Requirement already satisfied: gensim==3.7.3 in /usr/local/lib/python3.6/dist-packages (3.7.3)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.9.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.16.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (1.10.36)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (2.49.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (1.13.36)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.7.0->gensim==3.7.3) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.7.0->gensim==3.7.3) (0.15.2)\n",
      "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (42.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install ner_ontonotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "xcSZEyN6gWy8",
    "outputId": "50ceecb8-5f77-42b3-8fa3-b57f12e11003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email-validator not installed, email fields will be treated as str.\n",
      "To install, run: pip install email-validator\n",
      "2019-12-18 16:13:52.691 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'ner_ontonotes' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_ontonotes.json'\n",
      "2019-12-18 16:13:53.484 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz?config=ner_ontonotes to /root/.deeppavlov/ner_ontonotes_v3_cpu_compatible.tar.gz\n",
      "100% 8.13M/8.13M [00:02<00:00, 4.00MB/s]\n",
      "2019-12-18 16:13:55.520 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/ner_ontonotes_v3_cpu_compatible.tar.gz archive into /root/.deeppavlov/models\n",
      "2019-12-18 16:13:56.226 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt?config=ner_ontonotes to /root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
      "347MB [00:54, 6.41MB/s]\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov download ner_ontonotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJhfwxYqANrq"
   },
   "outputs": [],
   "source": [
    "from deeppavlov import configs, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJ2aIk9IUa4c"
   },
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/deepmipt/DeepPavlov/0.1.0/deeppavlov/configs/ner/ner_ontonotes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dL-4LKBZUazn"
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('my_config.json', 'r+') as f:\n",
    "#     data = json.load(f)\n",
    "#     data['dataset_reader']['data_path'] = \"/dataset_1/\"\n",
    "#     f.seek(0)       \n",
    "#     json.dump(data, f, indent=4)\n",
    "#     f.truncate()     \n",
    "    \n",
    "# data = json.load(open('my_config.json', 'r+')) \n",
    "\n",
    "# data['dataset_reader']['data_path'] = \"/dataset_1/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MRxKkJtUanR"
   },
   "outputs": [],
   "source": [
    "from deeppavlov import train_model, configs\n",
    "# ner_model = train_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Vy1JIISUaOk"
   },
   "outputs": [],
   "source": [
    "#ner_few = json.load(open('ner_few.json', 'r+'))\n",
    "#ner_model = train_model(ner_few, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wb-EPSJ7l8lj"
   },
   "outputs": [],
   "source": [
    "#asda = json.load(open('ner_conll2003_pos.json', 'r+'))\n",
    "#ner_model = train_model(configs.ner.ner_conll2003_pos, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-nrCE8661Oe6",
    "outputId": "5221437f-59af-4aed-d848-4d986c44dad2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'physical_entity'"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy.get_tag('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "colab_type": "code",
    "id": "sVr-DeYo2CIS",
    "outputId": "8a2924ad-3bbc-4d8a-a60e-cb7a6b0a1a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email-validator not installed, email fields will be treated as str.\n",
      "To install, run: pip install email-validator\n",
      "2019-12-18 16:14:52.314 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'ner_conll2003' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_conll2003.json'\n",
      "Requirement already satisfied: gensim==3.7.3 in /usr/local/lib/python3.6/dist-packages (3.7.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.16.4)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.9.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (2.22.0)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (1.10.36)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (2.8)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (1.13.36)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (0.2.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.7.0->gensim==3.7.3) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.7.0->gensim==3.7.3) (2.6.1)\n",
      "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (42.0.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install ner_conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRJdjhb9Vhq2"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset_reader\": {\n",
    "        \"class_name\": \"conll2003_reader\",\n",
    "        \"data_path\": \"./onthology_objects_data_new/dataset_1/\",\n",
    "        \"dataset_name\": \"conll2003\",\n",
    "        \"provide_pos\": False\n",
    "    },\n",
    "    \"dataset_iterator\": {\n",
    "        \"class_name\": \"data_learning_iterator\",\n",
    "        \"seed\": 42\n",
    "    },\n",
    "    \"chainer\": {\n",
    "    \"in\": [\"x\"],\n",
    "    \"in_y\": [\"y\"],\n",
    "    \"pipe\": [\n",
    "      {\n",
    "        \"in\": [\"x\"],\n",
    "        \"class_name\": \"lazy_tokenizer\",\n",
    "        \"out\": [\"x_tokens\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"class_name\": \"str_lower\",\n",
    "        \"out\": [\"x_lower\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_lower\"],\n",
    "        \"class_name\": \"sanitizer\",\n",
    "        \"nums\": True,\n",
    "        \"out\": [\"x_san\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_san\"],\n",
    "        \"id\": \"word_vocab\",\n",
    "        \"class_name\": \"simple_vocab\",\n",
    "        \"pad_with_zeros\": True,\n",
    "        \"special_tokens\": [\"<UNK>\"],\n",
    "        \"fit_on\": [\"x_san\"],\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/word.dict\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/word.dict\",\n",
    "        \"out\": [\"x_tok_ind\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"y\"],\n",
    "        \"id\": \"tag_vocab\",\n",
    "        \"class_name\": \"simple_vocab\",\n",
    "        \"pad_with_zeros\": True,\n",
    "        \"fit_on\": [\"y\"],\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/tag.dict\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/tag.dict\",\n",
    "        \"out\": [\"y_ind\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"class_name\": \"char_splitter\",\n",
    "        \"out\": [\"x_char\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_char\"],\n",
    "        \"id\": \"char_vocab\",\n",
    "        \"class_name\": \"simple_vocab\",\n",
    "        \"pad_with_zeros\": True,\n",
    "        \"fit_on\": [\"x_char\"],\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/char.dict\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/char.dict\",\n",
    "        \"out\": [\"x_char_ind\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"class_name\": \"mask\",\n",
    "        \"out\": [\"mask\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_san\"],\n",
    "        \"id\": \"glove_emb\",\n",
    "        \"class_name\": \"glove\",\n",
    "        \"pad_zero\": True,\n",
    "        \"load_path\": \"{DOWNLOADS_PATH}/embeddings/glove.6B.100d.txt\",\n",
    "        \"out\": [\"x_emb\"]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"embeddings\",\n",
    "        \"class_name\": \"emb_mat_assembler\",\n",
    "        \"embedder\": \"#glove_emb\",\n",
    "        \"vocab\": \"#word_vocab\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"embeddings_char\",\n",
    "        \"class_name\": \"emb_mat_assembler\",\n",
    "        \"character_level\": True,\n",
    "        \"emb_dim\": 32,\n",
    "        \"embedder\": \"#glove_emb\",\n",
    "        \"vocab\": \"#char_vocab\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"capitalization\",\n",
    "        \"class_name\": \"capitalization_featurizer\",\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"out\": [\"cap\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_emb\", \"mask\", \"x_char_ind\", \"cap\"],\n",
    "        \"in_y\": [\"y_ind\"],\n",
    "        \"out\": [\"y_predicted\"],\n",
    "        \"class_name\": \"ner\",\n",
    "        \"main\": True,\n",
    "        \"token_emb_dim\": \"#glove_emb.dim\",\n",
    "        \"n_hidden_list\": [128],\n",
    "        \"net_type\": \"rnn\",\n",
    "        \"cell_type\": \"lstm\",\n",
    "        \"use_cudnn_rnn\": True,\n",
    "        \"n_tags\": \"#tag_vocab.len\",\n",
    "        \"capitalization_dim\": \"#capitalization.dim\",\n",
    "        \"char_emb_dim\": \"#embeddings_char.dim\",\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/model_no_pos\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/model_no_pos\",\n",
    "        \"char_emb_mat\": \"#embeddings_char.emb_mat\",\n",
    "        \"two_dense_on_top\": True,\n",
    "        \"use_crf\": True,\n",
    "        \"use_batch_norm\": True,\n",
    "        \"embeddings_dropout\": True,\n",
    "        \"top_dropout\": True,\n",
    "        \"intra_layer_dropout\": True,\n",
    "        \"l2_reg\": 0,\n",
    "        \"learning_rate\": 1e-2,\n",
    "        \"dropout_keep_prob\": 0.5\n",
    "      },\n",
    "      {\n",
    "        \"ref\": \"tag_vocab\",\n",
    "        \"in\": [\"y_predicted\"],\n",
    "        \"out\": [\"tags\"]\n",
    "      }\n",
    "    ],\n",
    "    \"out\": [\"x_tokens\", \"tags\"]\n",
    "  },\n",
    "    \"train\": {\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 64,\n",
    "        \"metrics\": [\n",
    "            {\n",
    "                \"name\": \"ner_f1\",\n",
    "                \"inputs\": [\n",
    "                    \"y\",\n",
    "                    \"tags\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"validation_patience\": 7,\n",
    "        \"val_every_n_epochs\": 1,\n",
    "        \"log_every_n_epochs\": -1,\n",
    "        \"show_examples\": False,\n",
    "        \"validate_best\": True,\n",
    "        \"test_best\": True\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"variables\": {\n",
    "            \"ROOT_PATH\": \".\",\n",
    "            \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\n",
    "            \"MODELS_PATH\": \"{ROOT_PATH}/models\"\n",
    "        },\n",
    "        \"requirements\": [\n",
    "            \"{DEEPPAVLOV_PATH}/requirements/gensim.txt\",\n",
    "            \"{DEEPPAVLOV_PATH}/requirements/tf.txt\"\n",
    "        ],\n",
    "        \"labels\": {\n",
    "            \"telegram_utils\": \"NERCoNLL2003Model\",\n",
    "            \"server_utils\": \"NER\"\n",
    "        },\n",
    "        \"download\": [\n",
    "            {\n",
    "                \"url\": \"http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt\",\n",
    "                \"subdir\": \"{DOWNLOADS_PATH}/embeddings\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "612gA4wcVjnH"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"config.json\", \"w\") as fout:\n",
    "  json.dump(config, fout, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iIYRffx_VnqY",
    "outputId": "3b051fef-8a3b-49d8-a2a6-094a32c1d27b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deeppavlov in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
      "Requirement already satisfied: Cython==0.29.12 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.29.12)\n",
      "Requirement already satisfied: pymorphy2==0.8 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.8)\n",
      "Requirement already satisfied: tqdm==4.32.2 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (4.32.2)\n",
      "Requirement already satisfied: fastapi==0.38.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.38.1)\n",
      "Requirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.24.2)\n",
      "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.2.4)\n",
      "Requirement already satisfied: overrides==1.9 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.9)\n",
      "Requirement already satisfied: scipy==1.3.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.3.0)\n",
      "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.22.0)\n",
      "Requirement already satisfied: uvicorn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.9.0)\n",
      "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.21.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.4.404381.4453942)\n",
      "Requirement already satisfied: h5py==2.9.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.9.0)\n",
      "Requirement already satisfied: pyopenssl==19.0.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (19.0.0)\n",
      "Requirement already satisfied: pytelegrambotapi==3.6.6 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (3.6.6)\n",
      "Requirement already satisfied: rusenttokenize==0.0.5 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.0.5)\n",
      "Requirement already satisfied: fuzzywuzzy==0.17.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.17.0)\n",
      "Requirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (3.2.5)\n",
      "Requirement already satisfied: numpy==1.16.4 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.16.4)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (2.4.393442.3710985)\n",
      "Requirement already satisfied: pydantic<=0.32.2,>=0.32.2 in /usr/local/lib/python3.6/dist-packages (from fastapi==0.38.1->deeppavlov) (0.32.2)\n",
      "Requirement already satisfied: starlette<=0.12.8,>=0.11.1 in /usr/local/lib/python3.6/dist-packages (from fastapi==0.38.1->deeppavlov) (0.12.8)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->deeppavlov) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->deeppavlov) (2.6.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (3.13)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: uvloop==0.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\" in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (0.14.0)\n",
      "Requirement already satisfied: httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\" in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (0.0.13)\n",
      "Requirement already satisfied: websockets==8.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (8.1)\n",
      "Requirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (7.0)\n",
      "Requirement already satisfied: h11==0.8.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (0.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov) (0.14.1)\n",
      "Requirement already satisfied: cryptography>=2.3 in /usr/local/lib/python3.6/dist-packages (from pyopenssl==19.0.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic<=0.32.2,>=0.32.2->fastapi==0.38.1->deeppavlov) (0.7)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.3->pyopenssl==19.0.0->deeppavlov) (1.13.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3->pyopenssl==19.0.0->deeppavlov) (2.19)\n",
      "email-validator not installed, email fields will be treated as str.\n",
      "To install, run: pip install email-validator\n",
      "2019-12-18 16:15:02.357 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt?config=config to /content/downloads/embeddings/glove.6B.100d.txt\n",
      "347MB [00:27, 12.6MB/s]\n",
      "email-validator not installed, email fields will be treated as str.\n",
      "To install, run: pip install email-validator\n",
      "2019-12-18 16:15:31.628 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'ner_conll2003' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_conll2003.json'\n",
      "Requirement already satisfied: gensim==3.7.3 in /usr/local/lib/python3.6/dist-packages (3.7.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.9.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (1.10.36)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (2.49.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (2.22.0)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (1.13.36)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (0.9.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (2.8)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.7.0->gensim==3.7.3) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.7.0->gensim==3.7.3) (2.6.1)\n",
      "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (42.0.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install deeppavlov\n",
    "!python -m deeppavlov download config.json\n",
    "!python -m deeppavlov install ner_conll2003\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzFokT4hVpxX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgmfOHxzY5rm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "f4s3opCqVraZ",
    "outputId": "0aa65a87-2982-4934-f4af-c859c490d4d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-18 16:15:37--  http://files.deeppavlov.ai/datasets/onthology_objects_data_new.zip\n",
      "Resolving files.deeppavlov.ai (files.deeppavlov.ai)... 93.175.29.74\n",
      "Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 346661 (339K) [application/zip]\n",
      "Saving to: ‘onthology_objects_data_new.zip’\n",
      "\n",
      "onthology_objects_d 100%[===================>] 338.54K   578KB/s    in 0.6s    \n",
      "\n",
      "2019-12-18 16:15:38 (578 KB/s) - ‘onthology_objects_data_new.zip’ saved [346661/346661]\n",
      "\n",
      "Archive:  onthology_objects_data_new.zip\n",
      "   creating: onthology_objects_data_new/\n",
      "   creating: onthology_objects_data_new/dataset_1/\n",
      "  inflating: onthology_objects_data_new/dataset_1/test.txt  \n",
      "  inflating: onthology_objects_data_new/dataset_1/train.txt  \n",
      "  inflating: onthology_objects_data_new/dataset_1/valid.txt  \n",
      "   creating: onthology_objects_data_new/dataset_2/\n",
      "  inflating: onthology_objects_data_new/dataset_2/test.txt  \n",
      "  inflating: onthology_objects_data_new/dataset_2/train.txt  \n",
      "  inflating: onthology_objects_data_new/dataset_2/valid.txt  \n",
      "   creating: onthology_objects_data_new/dataset_3/\n",
      "  inflating: onthology_objects_data_new/dataset_3/test.txt  \n",
      "  inflating: onthology_objects_data_new/dataset_3/train.txt  \n",
      "  inflating: onthology_objects_data_new/dataset_3/valid.txt  \n"
     ]
    }
   ],
   "source": [
    "!wget http://files.deeppavlov.ai/datasets/onthology_objects_data_new.zip\n",
    "! unzip onthology_objects_data_new.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6ZRwXQpQWiAZ",
    "outputId": "f7c6b342-20d0-47be-c823-c838811839c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:15:40.84 WARNING in 'deeppavlov.core.commands.train'['train'] at line 108: \"validate_best\" and \"test_best\" parameters are deprecated. Please, use \"evaluation_targets\" list instead\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
      "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "2019-12-18 16:15:41.99 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/models/onthology_objects/word.dict]\n",
      "2019-12-18 16:15:41.122 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/models/onthology_objects/tag.dict]\n",
      "2019-12-18 16:15:41.589 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/models/onthology_objects/char.dict]\n",
      "2019-12-18 16:15:41.773 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/content/downloads/embeddings/glove.6B.100d.txt`]\n",
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:96: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:170: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:405: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:416: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:211: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:16:23.956 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:729: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:733: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:736: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:861: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:16:24.944 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:245: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/crf/python/ops/crf.py:99: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:50: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:16:27.744 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 3849 phrases; correct: 0.\n",
      "\n",
      "precision:  3.30%; recall:  12.38%; FB1:  5.21\n",
      "\n",
      "\tO: precision:  0.24%; recall:  20.00%; F1:  0.48 1634\n",
      "\n",
      "\tabstraction: precision:  0.63%; recall:  0.69%; F1:  0.66 636\n",
      "\n",
      "\tphysical_entity: precision:  7.54%; recall:  27.67%; F1:  11.85 1579\n",
      "\n",
      "\n",
      "2019-12-18 16:16:27.746 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 5.2103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 5.2103}, \"time_spent\": \"0:00:01\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:16:36.870 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 604 phrases; correct: 0.\n",
      "\n",
      "precision:  54.14%; recall:  31.87%; FB1:  40.12\n",
      "\n",
      "\tO: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tabstraction: precision:  53.37%; recall:  52.26%; F1:  52.81 564\n",
      "\n",
      "\tphysical_entity: precision:  65.00%; recall:  6.05%; F1:  11.06 40\n",
      "\n",
      "\n",
      "2019-12-18 16:16:36.872 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 40.1227\n",
      "2019-12-18 16:16:36.873 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:16:36.874 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:77: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 40.1227}, \"time_spent\": \"0:00:10\", \"epochs_done\": 1, \"batches_seen\": 28, \"train_examples_seen\": 1770, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:16:46.119 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 1118 phrases; correct: 0.\n",
      "\n",
      "precision:  52.77%; recall:  57.50%; FB1:  55.04\n",
      "\n",
      "\tO: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tabstraction: precision:  56.28%; recall:  72.40%; F1:  63.33 741\n",
      "\n",
      "\tphysical_entity: precision:  45.89%; recall:  40.23%; F1:  42.87 377\n",
      "\n",
      "\n",
      "2019-12-18 16:16:46.120 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 55.0373\n",
      "2019-12-18 16:16:46.121 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:16:46.122 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 55.0373}, \"time_spent\": \"0:00:20\", \"epochs_done\": 2, \"batches_seen\": 56, \"train_examples_seen\": 3540, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:16:55.478 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 799 phrases; correct: 0.\n",
      "\n",
      "precision:  66.83%; recall:  52.05%; FB1:  58.52\n",
      "\n",
      "\tO: precision:  100.00%; recall:  40.00%; F1:  57.14 8\n",
      "\n",
      "\tabstraction: precision:  72.15%; recall:  57.12%; F1:  63.76 456\n",
      "\n",
      "\tphysical_entity: precision:  58.81%; recall:  45.81%; F1:  51.50 335\n",
      "\n",
      "\n",
      "2019-12-18 16:16:55.480 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 58.5205\n",
      "2019-12-18 16:16:55.480 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:16:55.481 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 58.5205}, \"time_spent\": \"0:00:29\", \"epochs_done\": 3, \"batches_seen\": 84, \"train_examples_seen\": 5310, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:17:05.188 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 915 phrases; correct: 0.\n",
      "\n",
      "precision:  69.84%; recall:  62.28%; FB1:  65.84\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tabstraction: precision:  68.10%; recall:  76.74%; F1:  72.16 649\n",
      "\n",
      "\tphysical_entity: precision:  73.58%; recall:  42.09%; F1:  53.55 246\n",
      "\n",
      "\n",
      "2019-12-18 16:17:05.189 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 65.8423\n",
      "2019-12-18 16:17:05.190 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:17:05.192 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 65.8423}, \"time_spent\": \"0:00:39\", \"epochs_done\": 4, \"batches_seen\": 112, \"train_examples_seen\": 7080, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:17:15.1 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 976 phrases; correct: 0.\n",
      "\n",
      "precision:  70.49%; recall:  67.06%; FB1:  68.73\n",
      "\n",
      "\tO: precision:  100.00%; recall:  75.00%; F1:  85.71 15\n",
      "\n",
      "\tabstraction: precision:  68.48%; recall:  82.99%; F1:  75.04 698\n",
      "\n",
      "\tphysical_entity: precision:  74.14%; recall:  45.35%; F1:  56.28 263\n",
      "\n",
      "\n",
      "2019-12-18 16:17:15.3 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 68.7313\n",
      "2019-12-18 16:17:15.3 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:17:15.4 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 68.7313}, \"time_spent\": \"0:00:49\", \"epochs_done\": 5, \"batches_seen\": 140, \"train_examples_seen\": 8850, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:17:24.744 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 1090 phrases; correct: 0.\n",
      "\n",
      "precision:  66.79%; recall:  70.96%; FB1:  68.81\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tabstraction: precision:  64.92%; recall:  83.85%; F1:  73.18 744\n",
      "\n",
      "\tphysical_entity: precision:  70.25%; recall:  53.26%; F1:  60.58 326\n",
      "\n",
      "\n",
      "2019-12-18 16:17:24.745 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 68.8091\n",
      "2019-12-18 16:17:24.746 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:17:24.748 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 68.8091}, \"time_spent\": \"0:00:58\", \"epochs_done\": 6, \"batches_seen\": 168, \"train_examples_seen\": 10620, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:17:34.453 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 1003 phrases; correct: 0.\n",
      "\n",
      "precision:  71.09%; recall:  69.49%; FB1:  70.28\n",
      "\n",
      "\tO: precision:  94.12%; recall:  80.00%; F1:  86.49 17\n",
      "\n",
      "\tabstraction: precision:  74.96%; recall:  73.78%; F1:  74.37 567\n",
      "\n",
      "\tphysical_entity: precision:  64.92%; recall:  63.26%; F1:  64.08 419\n",
      "\n",
      "\n",
      "2019-12-18 16:17:34.455 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 70.2809\n",
      "2019-12-18 16:17:34.455 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:17:34.456 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 70.2809}, \"time_spent\": \"0:01:08\", \"epochs_done\": 7, \"batches_seen\": 196, \"train_examples_seen\": 12390, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:17:44.512 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 1003 phrases; correct: 0.\n",
      "\n",
      "precision:  70.59%; recall:  69.01%; FB1:  69.79\n",
      "\n",
      "\tO: precision:  100.00%; recall:  70.00%; F1:  82.35 14\n",
      "\n",
      "\tabstraction: precision:  66.62%; recall:  88.37%; F1:  75.97 764\n",
      "\n",
      "\tphysical_entity: precision:  82.22%; recall:  43.02%; F1:  56.49 225\n",
      "\n",
      "\n",
      "2019-12-18 16:17:44.514 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 70.2809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 69.7881}, \"time_spent\": \"0:01:18\", \"epochs_done\": 8, \"batches_seen\": 224, \"train_examples_seen\": 14160, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:17:54.155 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 956 phrases; correct: 0.\n",
      "\n",
      "precision:  74.27%; recall:  69.20%; FB1:  71.64\n",
      "\n",
      "\tO: precision:  94.12%; recall:  80.00%; F1:  86.49 17\n",
      "\n",
      "\tabstraction: precision:  73.87%; recall:  81.94%; F1:  77.70 639\n",
      "\n",
      "\tphysical_entity: precision:  74.00%; recall:  51.63%; F1:  60.82 300\n",
      "\n",
      "\n",
      "2019-12-18 16:17:54.156 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 71.6448\n",
      "2019-12-18 16:17:54.157 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:17:54.158 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 71.6448}, \"time_spent\": \"0:01:28\", \"epochs_done\": 9, \"batches_seen\": 252, \"train_examples_seen\": 15930, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:18:04.224 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 1004 phrases; correct: 0.\n",
      "\n",
      "precision:  73.51%; recall:  71.93%; FB1:  72.71\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tabstraction: precision:  73.08%; recall:  82.47%; F1:  77.49 650\n",
      "\n",
      "\tphysical_entity: precision:  73.08%; recall:  57.44%; F1:  64.32 338\n",
      "\n",
      "\n",
      "2019-12-18 16:18:04.225 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 72.7094\n",
      "2019-12-18 16:18:04.226 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:18:04.227 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 72.7094}, \"time_spent\": \"0:01:38\", \"epochs_done\": 10, \"batches_seen\": 280, \"train_examples_seen\": 17700, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:18:14.990 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 997 phrases; correct: 0.\n",
      "\n",
      "precision:  73.82%; recall:  71.73%; FB1:  72.76\n",
      "\n",
      "\tO: precision:  88.89%; recall:  80.00%; F1:  84.21 18\n",
      "\n",
      "\tabstraction: precision:  71.00%; recall:  87.15%; F1:  78.25 707\n",
      "\n",
      "\tphysical_entity: precision:  80.15%; recall:  50.70%; F1:  62.11 272\n",
      "\n",
      "\n",
      "2019-12-18 16:18:14.991 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 72.7632\n",
      "2019-12-18 16:18:14.992 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:18:14.992 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 72.7632}, \"time_spent\": \"0:01:49\", \"epochs_done\": 11, \"batches_seen\": 308, \"train_examples_seen\": 19470, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:18:24.743 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 1009 phrases; correct: 0.\n",
      "\n",
      "precision:  73.64%; recall:  72.42%; FB1:  73.02\n",
      "\n",
      "\tO: precision:  88.89%; recall:  80.00%; F1:  84.21 18\n",
      "\n",
      "\tabstraction: precision:  70.00%; recall:  89.93%; F1:  78.72 740\n",
      "\n",
      "\tphysical_entity: precision:  83.27%; recall:  48.60%; F1:  61.38 251\n",
      "\n",
      "\n",
      "2019-12-18 16:18:24.744 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 73.0221\n",
      "2019-12-18 16:18:24.745 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:18:24.746 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 73.0221}, \"time_spent\": \"0:01:58\", \"epochs_done\": 12, \"batches_seen\": 336, \"train_examples_seen\": 21240, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:18:34.621 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 958 phrases; correct: 0.\n",
      "\n",
      "precision:  75.89%; recall:  70.86%; FB1:  73.29\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tabstraction: precision:  78.23%; recall:  76.74%; F1:  77.48 565\n",
      "\n",
      "\tphysical_entity: precision:  71.35%; recall:  62.56%; F1:  66.67 377\n",
      "\n",
      "\n",
      "2019-12-18 16:18:34.622 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 73.2863\n",
      "2019-12-18 16:18:34.623 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:18:34.623 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 73.2863}, \"time_spent\": \"0:02:08\", \"epochs_done\": 13, \"batches_seen\": 364, \"train_examples_seen\": 23010, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:18:44.695 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 980 phrases; correct: 0.\n",
      "\n",
      "precision:  75.71%; recall:  72.32%; FB1:  73.98\n",
      "\n",
      "\tO: precision:  88.89%; recall:  80.00%; F1:  84.21 18\n",
      "\n",
      "\tabstraction: precision:  75.86%; recall:  84.55%; F1:  79.97 642\n",
      "\n",
      "\tphysical_entity: precision:  74.69%; recall:  55.58%; F1:  63.73 320\n",
      "\n",
      "\n",
      "2019-12-18 16:18:44.697 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 73.9781\n",
      "2019-12-18 16:18:44.697 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:18:44.698 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 73.9781}, \"time_spent\": \"0:02:18\", \"epochs_done\": 14, \"batches_seen\": 392, \"train_examples_seen\": 24780, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:18:54.584 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 1018 phrases; correct: 0.\n",
      "\n",
      "precision:  73.08%; recall:  72.51%; FB1:  72.80\n",
      "\n",
      "\tO: precision:  90.00%; recall:  90.00%; F1:  90.00 20\n",
      "\n",
      "\tabstraction: precision:  73.68%; recall:  80.21%; F1:  76.81 627\n",
      "\n",
      "\tphysical_entity: precision:  71.16%; recall:  61.40%; F1:  65.92 371\n",
      "\n",
      "\n",
      "2019-12-18 16:18:54.586 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 73.9781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 72.7984}, \"time_spent\": \"0:02:28\", \"epochs_done\": 15, \"batches_seen\": 420, \"train_examples_seen\": 26550, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:19:04.104 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 994 phrases; correct: 0.\n",
      "\n",
      "precision:  74.65%; recall:  72.32%; FB1:  73.47\n",
      "\n",
      "\tO: precision:  88.89%; recall:  80.00%; F1:  84.21 18\n",
      "\n",
      "\tabstraction: precision:  72.61%; recall:  86.98%; F1:  79.15 690\n",
      "\n",
      "\tphysical_entity: precision:  78.67%; recall:  52.33%; F1:  62.85 286\n",
      "\n",
      "\n",
      "2019-12-18 16:19:04.105 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 73.9781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 73.4653}, \"time_spent\": \"0:02:38\", \"epochs_done\": 16, \"batches_seen\": 448, \"train_examples_seen\": 28320, \"impatience\": 2, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:19:13.631 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 914 phrases; correct: 0.\n",
      "\n",
      "precision:  77.46%; recall:  69.01%; FB1:  72.99\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tabstraction: precision:  75.92%; recall:  85.94%; F1:  80.62 652\n",
      "\n",
      "\tphysical_entity: precision:  80.08%; recall:  45.81%; F1:  58.28 246\n",
      "\n",
      "\n",
      "2019-12-18 16:19:13.632 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 73.9781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 72.9897}, \"time_spent\": \"0:02:47\", \"epochs_done\": 17, \"batches_seen\": 476, \"train_examples_seen\": 30090, \"impatience\": 3, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:19:22.924 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 966 phrases; correct: 0.\n",
      "\n",
      "precision:  75.47%; recall:  71.05%; FB1:  73.19\n",
      "\n",
      "\tO: precision:  88.89%; recall:  80.00%; F1:  84.21 18\n",
      "\n",
      "\tabstraction: precision:  78.03%; recall:  77.08%; F1:  77.55 569\n",
      "\n",
      "\tphysical_entity: precision:  70.98%; recall:  62.56%; F1:  66.50 379\n",
      "\n",
      "\n",
      "2019-12-18 16:19:22.926 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 73.9781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 73.1928}, \"time_spent\": \"0:02:56\", \"epochs_done\": 18, \"batches_seen\": 504, \"train_examples_seen\": 31860, \"impatience\": 4, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:19:32.559 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 1006 phrases; correct: 0.\n",
      "\n",
      "precision:  73.96%; recall:  72.51%; FB1:  73.23\n",
      "\n",
      "\tO: precision:  75.00%; recall:  90.00%; F1:  81.82 24\n",
      "\n",
      "\tabstraction: precision:  73.16%; recall:  84.72%; F1:  78.52 667\n",
      "\n",
      "\tphysical_entity: precision:  75.56%; recall:  55.35%; F1:  63.89 315\n",
      "\n",
      "\n",
      "2019-12-18 16:19:32.560 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 73.9781\n",
      "2019-12-18 16:19:32.659 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 73.2283}, \"time_spent\": \"0:03:06\", \"epochs_done\": 19, \"batches_seen\": 532, \"train_examples_seen\": 33630, \"impatience\": 5, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:19:42.406 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 986 phrases; correct: 0.\n",
      "\n",
      "precision:  75.66%; recall:  72.71%; FB1:  74.16\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tabstraction: precision:  75.43%; recall:  84.20%; F1:  79.57 643\n",
      "\n",
      "\tphysical_entity: precision:  75.85%; recall:  56.98%; F1:  65.07 323\n",
      "\n",
      "\n",
      "2019-12-18 16:19:42.407 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 74.1551\n",
      "2019-12-18 16:19:42.408 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:19:42.409 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.1551}, \"time_spent\": \"0:03:16\", \"epochs_done\": 20, \"batches_seen\": 560, \"train_examples_seen\": 35400, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:19:52.421 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 982 phrases; correct: 0.\n",
      "\n",
      "precision:  75.66%; recall:  72.42%; FB1:  74.00\n",
      "\n",
      "\tO: precision:  72.73%; recall:  80.00%; F1:  76.19 22\n",
      "\n",
      "\tabstraction: precision:  76.03%; recall:  83.68%; F1:  79.67 634\n",
      "\n",
      "\tphysical_entity: precision:  75.15%; recall:  56.98%; F1:  64.81 326\n",
      "\n",
      "\n",
      "2019-12-18 16:19:52.422 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 74.1551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.004}, \"time_spent\": \"0:03:26\", \"epochs_done\": 21, \"batches_seen\": 588, \"train_examples_seen\": 37170, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:20:02.213 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 989 phrases; correct: 0.\n",
      "\n",
      "precision:  75.03%; recall:  72.32%; FB1:  73.65\n",
      "\n",
      "\tO: precision:  72.73%; recall:  80.00%; F1:  76.19 22\n",
      "\n",
      "\tabstraction: precision:  76.42%; recall:  81.60%; F1:  78.93 615\n",
      "\n",
      "\tphysical_entity: precision:  72.73%; recall:  59.53%; F1:  65.47 352\n",
      "\n",
      "\n",
      "2019-12-18 16:20:02.215 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 74.1551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 73.6476}, \"time_spent\": \"0:03:36\", \"epochs_done\": 22, \"batches_seen\": 616, \"train_examples_seen\": 38940, \"impatience\": 2, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:20:12.191 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 974 phrases; correct: 0.\n",
      "\n",
      "precision:  75.26%; recall:  71.44%; FB1:  73.30\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tabstraction: precision:  76.78%; recall:  80.38%; F1:  78.54 603\n",
      "\n",
      "\tphysical_entity: precision:  72.36%; recall:  59.07%; F1:  65.04 351\n",
      "\n",
      "\n",
      "2019-12-18 16:20:12.193 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 74.1551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 73.3}, \"time_spent\": \"0:03:46\", \"epochs_done\": 23, \"batches_seen\": 644, \"train_examples_seen\": 40710, \"impatience\": 3, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:20:21.901 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 980 phrases; correct: 0.\n",
      "\n",
      "precision:  75.71%; recall:  72.32%; FB1:  73.98\n",
      "\n",
      "\tO: precision:  72.73%; recall:  80.00%; F1:  76.19 22\n",
      "\n",
      "\tabstraction: precision:  76.87%; recall:  81.94%; F1:  79.33 614\n",
      "\n",
      "\tphysical_entity: precision:  73.84%; recall:  59.07%; F1:  65.63 344\n",
      "\n",
      "\n",
      "2019-12-18 16:20:21.902 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 74.1551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 73.9781}, \"time_spent\": \"0:03:55\", \"epochs_done\": 24, \"batches_seen\": 672, \"train_examples_seen\": 42480, \"impatience\": 4, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:20:31.565 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 978 phrases; correct: 0.\n",
      "\n",
      "precision:  76.18%; recall:  72.61%; FB1:  74.35\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tabstraction: precision:  76.36%; recall:  82.99%; F1:  79.53 626\n",
      "\n",
      "\tphysical_entity: precision:  75.60%; recall:  58.37%; F1:  65.88 332\n",
      "\n",
      "\n",
      "2019-12-18 16:20:31.566 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 74.3513\n",
      "2019-12-18 16:20:31.567 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:20:31.567 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.3513}, \"time_spent\": \"0:04:05\", \"epochs_done\": 25, \"batches_seen\": 700, \"train_examples_seen\": 44250, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:20:41.405 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 989 phrases; correct: 0.\n",
      "\n",
      "precision:  75.94%; recall:  73.20%; FB1:  74.54\n",
      "\n",
      "\tO: precision:  72.73%; recall:  80.00%; F1:  76.19 22\n",
      "\n",
      "\tabstraction: precision:  76.02%; recall:  84.20%; F1:  79.90 638\n",
      "\n",
      "\tphysical_entity: precision:  75.99%; recall:  58.14%; F1:  65.88 329\n",
      "\n",
      "\n",
      "2019-12-18 16:20:41.406 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 74.5409\n",
      "2019-12-18 16:20:41.407 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:20:41.408 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.5409}, \"time_spent\": \"0:04:15\", \"epochs_done\": 26, \"batches_seen\": 728, \"train_examples_seen\": 46020, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:20:51.329 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 977 phrases; correct: 0.\n",
      "\n",
      "precision:  76.77%; recall:  73.10%; FB1:  74.89\n",
      "\n",
      "\tO: precision:  72.73%; recall:  80.00%; F1:  76.19 22\n",
      "\n",
      "\tabstraction: precision:  77.12%; recall:  83.68%; F1:  80.27 625\n",
      "\n",
      "\tphysical_entity: precision:  76.36%; recall:  58.60%; F1:  66.32 330\n",
      "\n",
      "\n",
      "2019-12-18 16:20:51.330 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 74.8877\n",
      "2019-12-18 16:20:51.331 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:20:51.332 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.8877}, \"time_spent\": \"0:04:25\", \"epochs_done\": 27, \"batches_seen\": 756, \"train_examples_seen\": 47790, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:21:01.540 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 988 phrases; correct: 0.\n",
      "\n",
      "precision:  76.11%; recall:  73.29%; FB1:  74.68\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tabstraction: precision:  77.74%; recall:  81.25%; F1:  79.46 602\n",
      "\n",
      "\tphysical_entity: precision:  73.22%; recall:  62.33%; F1:  67.34 366\n",
      "\n",
      "\n",
      "2019-12-18 16:21:01.541 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 74.8877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.6773}, \"time_spent\": \"0:04:35\", \"epochs_done\": 28, \"batches_seen\": 784, \"train_examples_seen\": 49560, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:21:11.372 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 995 phrases; correct: 0.\n",
      "\n",
      "precision:  76.08%; recall:  73.78%; FB1:  74.91\n",
      "\n",
      "\tO: precision:  72.73%; recall:  80.00%; F1:  76.19 22\n",
      "\n",
      "\tabstraction: precision:  76.40%; recall:  83.16%; F1:  79.63 627\n",
      "\n",
      "\tphysical_entity: precision:  75.72%; recall:  60.93%; F1:  67.53 346\n",
      "\n",
      "\n",
      "2019-12-18 16:21:11.373 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 74.9134\n",
      "2019-12-18 16:21:11.374 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:21:11.375 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.9134}, \"time_spent\": \"0:04:45\", \"epochs_done\": 29, \"batches_seen\": 812, \"train_examples_seen\": 51330, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:21:21.402 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 985 phrases; correct: 0.\n",
      "\n",
      "precision:  76.85%; recall:  73.78%; FB1:  75.29\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tabstraction: precision:  78.00%; recall:  82.47%; F1:  80.17 609\n",
      "\n",
      "\tphysical_entity: precision:  74.72%; recall:  61.86%; F1:  67.68 356\n",
      "\n",
      "\n",
      "2019-12-18 16:21:21.403 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 75.2859\n",
      "2019-12-18 16:21:21.404 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:21:21.405 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 75.2859}, \"time_spent\": \"0:04:55\", \"epochs_done\": 30, \"batches_seen\": 840, \"train_examples_seen\": 53100, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:21:31.345 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 988 phrases; correct: 0.\n",
      "\n",
      "precision:  76.52%; recall:  73.68%; FB1:  75.07\n",
      "\n",
      "\tO: precision:  72.73%; recall:  80.00%; F1:  76.19 22\n",
      "\n",
      "\tabstraction: precision:  77.70%; recall:  82.29%; F1:  79.93 610\n",
      "\n",
      "\tphysical_entity: precision:  74.72%; recall:  61.86%; F1:  67.68 356\n",
      "\n",
      "\n",
      "2019-12-18 16:21:31.346 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 75.2859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 75.0745}, \"time_spent\": \"0:05:05\", \"epochs_done\": 31, \"batches_seen\": 868, \"train_examples_seen\": 54870, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:21:41.203 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 991 phrases; correct: 0.\n",
      "\n",
      "precision:  76.59%; recall:  73.98%; FB1:  75.26\n",
      "\n",
      "\tO: precision:  75.00%; recall:  90.00%; F1:  81.82 24\n",
      "\n",
      "\tabstraction: precision:  77.01%; recall:  83.16%; F1:  79.97 622\n",
      "\n",
      "\tphysical_entity: precision:  75.94%; recall:  60.93%; F1:  67.61 345\n",
      "\n",
      "\n",
      "2019-12-18 16:21:41.204 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 75.2859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 75.2603}, \"time_spent\": \"0:05:15\", \"epochs_done\": 32, \"batches_seen\": 896, \"train_examples_seen\": 56640, \"impatience\": 2, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:21:50.914 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 991 phrases; correct: 0.\n",
      "\n",
      "precision:  76.89%; recall:  74.27%; FB1:  75.56\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tabstraction: precision:  76.77%; recall:  84.90%; F1:  80.63 637\n",
      "\n",
      "\tphysical_entity: precision:  76.95%; recall:  59.77%; F1:  67.28 334\n",
      "\n",
      "\n",
      "2019-12-18 16:21:50.915 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 75.5578\n",
      "2019-12-18 16:21:50.916 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:21:50.917 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 75.5578}, \"time_spent\": \"0:05:24\", \"epochs_done\": 33, \"batches_seen\": 924, \"train_examples_seen\": 58410, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:22:00.920 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 986 phrases; correct: 0.\n",
      "\n",
      "precision:  76.47%; recall:  73.49%; FB1:  74.95\n",
      "\n",
      "\tO: precision:  72.73%; recall:  80.00%; F1:  76.19 22\n",
      "\n",
      "\tabstraction: precision:  77.13%; recall:  83.16%; F1:  80.03 621\n",
      "\n",
      "\tphysical_entity: precision:  75.51%; recall:  60.23%; F1:  67.01 343\n",
      "\n",
      "\n",
      "2019-12-18 16:22:00.921 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 75.5578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.9503}, \"time_spent\": \"0:05:34\", \"epochs_done\": 34, \"batches_seen\": 952, \"train_examples_seen\": 60180, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:22:10.532 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 996 phrases; correct: 0.\n",
      "\n",
      "precision:  76.00%; recall:  73.78%; FB1:  74.88\n",
      "\n",
      "\tO: precision:  69.23%; recall:  90.00%; F1:  78.26 26\n",
      "\n",
      "\tabstraction: precision:  77.24%; recall:  82.47%; F1:  79.76 615\n",
      "\n",
      "\tphysical_entity: precision:  74.37%; recall:  61.40%; F1:  67.26 355\n",
      "\n",
      "\n",
      "2019-12-18 16:22:10.534 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 75.5578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.8764}, \"time_spent\": \"0:05:44\", \"epochs_done\": 35, \"batches_seen\": 980, \"train_examples_seen\": 61950, \"impatience\": 2, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:22:20.349 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 994 phrases; correct: 0.\n",
      "\n",
      "precision:  76.16%; recall:  73.78%; FB1:  74.95\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tabstraction: precision:  77.31%; recall:  82.81%; F1:  79.97 617\n",
      "\n",
      "\tphysical_entity: precision:  73.95%; recall:  61.40%; F1:  67.09 357\n",
      "\n",
      "\n",
      "2019-12-18 16:22:20.350 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 75.5578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.9505}, \"time_spent\": \"0:05:54\", \"epochs_done\": 36, \"batches_seen\": 1008, \"train_examples_seen\": 63720, \"impatience\": 3, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:22:30.116 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 987 phrases; correct: 0.\n",
      "\n",
      "precision:  76.19%; recall:  73.29%; FB1:  74.71\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tabstraction: precision:  77.85%; recall:  81.77%; F1:  79.76 605\n",
      "\n",
      "\tphysical_entity: precision:  73.20%; recall:  61.63%; F1:  66.92 362\n",
      "\n",
      "\n",
      "2019-12-18 16:22:30.118 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 75.5578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.7144}, \"time_spent\": \"0:06:04\", \"epochs_done\": 37, \"batches_seen\": 1036, \"train_examples_seen\": 65490, \"impatience\": 4, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:22:39.726 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 992 phrases; correct: 0.\n",
      "\n",
      "precision:  75.81%; recall:  73.29%; FB1:  74.53\n",
      "\n",
      "\tO: precision:  71.43%; recall:  100.00%; F1:  83.33 28\n",
      "\n",
      "\tabstraction: precision:  78.08%; recall:  80.38%; F1:  79.21 593\n",
      "\n",
      "\tphysical_entity: precision:  72.51%; recall:  62.56%; F1:  67.17 371\n",
      "\n",
      "\n",
      "2019-12-18 16:22:39.727 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 75.5578\n",
      "2019-12-18 16:22:39.843 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.5292}, \"time_spent\": \"0:06:13\", \"epochs_done\": 38, \"batches_seen\": 1064, \"train_examples_seen\": 67260, \"impatience\": 5, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:22:49.582 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 991 phrases; correct: 0.\n",
      "\n",
      "precision:  75.98%; recall:  73.39%; FB1:  74.67\n",
      "\n",
      "\tO: precision:  71.43%; recall:  100.00%; F1:  83.33 28\n",
      "\n",
      "\tabstraction: precision:  77.41%; recall:  82.12%; F1:  79.70 611\n",
      "\n",
      "\tphysical_entity: precision:  73.86%; recall:  60.47%; F1:  66.50 352\n",
      "\n",
      "\n",
      "2019-12-18 16:22:49.583 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 75.5578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 74.6653}, \"time_spent\": \"0:06:23\", \"epochs_done\": 39, \"batches_seen\": 1092, \"train_examples_seen\": 69030, \"impatience\": 6, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:22:59.366 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 987 phrases; correct: 0.\n",
      "\n",
      "precision:  76.49%; recall:  73.59%; FB1:  75.01\n",
      "\n",
      "\tO: precision:  76.92%; recall:  100.00%; F1:  86.96 26\n",
      "\n",
      "\tabstraction: precision:  77.10%; recall:  82.99%; F1:  79.93 620\n",
      "\n",
      "\tphysical_entity: precision:  75.37%; recall:  59.77%; F1:  66.67 341\n",
      "\n",
      "\n",
      "2019-12-18 16:22:59.368 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 75.5578\n",
      "2019-12-18 16:22:59.475 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 328: Ran out of patience\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 75.0124}, \"time_spent\": \"0:06:33\", \"epochs_done\": 40, \"batches_seen\": 1120, \"train_examples_seen\": 70800, \"impatience\": 7, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:22:59.755 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/models/onthology_objects/word.dict]\n",
      "2019-12-18 16:22:59.765 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/models/onthology_objects/tag.dict]\n",
      "2019-12-18 16:22:59.766 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/models/onthology_objects/char.dict]\n",
      "2019-12-18 16:22:59.767 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/content/downloads/embeddings/glove.6B.100d.txt`]\n",
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "2019-12-18 16:23:41.188 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:23:41.288 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:23:43.525 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/models/onthology_objects/model_no_pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:23:44.365 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1026 phrases; found: 991 phrases; correct: 0.\n",
      "\n",
      "precision:  76.89%; recall:  74.27%; FB1:  75.56\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tabstraction: precision:  76.77%; recall:  84.90%; F1:  80.63 637\n",
      "\n",
      "\tphysical_entity: precision:  76.95%; recall:  59.77%; F1:  67.28 334\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 75.5578}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:23:44.962 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 4290 tokens with 969 phrases; found: 936 phrases; correct: 0.\n",
      "\n",
      "precision:  74.25%; recall:  71.72%; FB1:  72.97\n",
      "\n",
      "\tO: precision:  81.82%; recall:  52.94%; F1:  64.29 22\n",
      "\n",
      "\tabstraction: precision:  75.08%; recall:  80.00%; F1:  77.46 618\n",
      "\n",
      "\tphysical_entity: precision:  71.96%; recall:  60.00%; F1:  65.44 296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"test\": {\"eval_examples_count\": 222, \"metrics\": {\"ner_f1\": 72.9659}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:23:45.227 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/models/onthology_objects/word.dict]\n",
      "2019-12-18 16:23:45.238 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/models/onthology_objects/tag.dict]\n",
      "2019-12-18 16:23:45.240 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/models/onthology_objects/char.dict]\n",
      "2019-12-18 16:23:45.241 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/content/downloads/embeddings/glove.6B.100d.txt`]\n",
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "2019-12-18 16:24:25.986 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:24:26.86 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:24:28.360 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/models/onthology_objects/model_no_pos]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/models/onthology_objects/model_no_pos\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model, train_model\n",
    "model = train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "WoJS74AbWt2-",
    "outputId": "71c4c700-349b-4616-e960-b88141d5445b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Wikipedia', 'O'],\n",
       " ['is', 'O'],\n",
       " ['a', 'O'],\n",
       " ['free', 'O'],\n",
       " ['online', 'O'],\n",
       " ['encyclopedia', 'B-abstraction'],\n",
       " [',', 'O'],\n",
       " ['created', 'O'],\n",
       " ['and', 'O'],\n",
       " ['edited', 'O'],\n",
       " ['by', 'O'],\n",
       " ['volunteers', 'O'],\n",
       " ['around', 'O'],\n",
       " ['the', 'O'],\n",
       " ['world', 'B-abstraction'],\n",
       " ['and', 'O'],\n",
       " ['hosted', 'O'],\n",
       " ['by', 'O'],\n",
       " ['the', 'O'],\n",
       " ['Wikimedia', 'O'],\n",
       " ['Foundation', 'B-abstraction'],\n",
       " ['.', 'O']]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str = 'Wikipedia is a free online encyclopedia, created and edited by volunteers around the world and hosted by the Wikimedia Foundation.'\n",
    "res = model.compute([test_str])\n",
    "res = [res[0][0], res[1][0]]\n",
    "readable = []\n",
    "for i in range(len(res[0])):\n",
    "  readable.append([res[0][i], res[1][i]])\n",
    "readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "fugpEKxEXtUa",
    "outputId": "741a332b-3d9e-4650-fd41-7ef243f01b01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wikipedia O',\n",
       " 'is O',\n",
       " 'a O',\n",
       " 'free O',\n",
       " 'online O',\n",
       " 'encyclopedia B-physical_entity',\n",
       " ', O',\n",
       " 'created O',\n",
       " 'and O',\n",
       " 'edited O',\n",
       " 'by O',\n",
       " 'volunteers O',\n",
       " 'around O',\n",
       " 'the O',\n",
       " 'world B-abstraction',\n",
       " 'and O',\n",
       " 'hosted O',\n",
       " 'by O',\n",
       " 'the O',\n",
       " 'Wikimedia O',\n",
       " 'Foundation O',\n",
       " '. O',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_text(hierarchy, re.findall(r\"[\\w']+|[.,!?;\\'\\\"]\", test_str)).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vxRLW3aopjcU",
    "outputId": "b5befb7f-8c30-4123-be30-a239f644b173"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'physical_entity'"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy.get_tag('volunteer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4EQ73XeSql0b",
    "outputId": "cd8624a1-dff4-4fd2-d143-e68a6aa12fe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'volunteer'"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.morphy('volunteers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrtzbIHTQDvn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1qJD1xQSQEOg"
   },
   "source": [
    "** GLUBINA 2 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "colab_type": "code",
    "id": "GXAHosiVSaP-",
    "outputId": "8e2d7c36-8d15-4e4e-d159-317f58997bbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deeppavlov in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
      "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.2.4)\n",
      "Requirement already satisfied: pyopenssl==19.0.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (19.0.0)\n",
      "Requirement already satisfied: tqdm==4.32.2 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (4.32.2)\n",
      "Requirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.24.2)\n",
      "Requirement already satisfied: pytelegrambotapi==3.6.6 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (3.6.6)\n",
      "Requirement already satisfied: rusenttokenize==0.0.5 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.0.5)\n",
      "Requirement already satisfied: fastapi==0.38.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.38.1)\n",
      "Requirement already satisfied: Cython==0.29.12 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.29.12)\n",
      "Requirement already satisfied: numpy==1.16.4 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.16.4)\n",
      "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.22.0)\n",
      "Requirement already satisfied: scipy==1.3.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.3.0)\n",
      "Requirement already satisfied: uvicorn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.9.0)\n",
      "Requirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (3.2.5)\n",
      "Requirement already satisfied: pymorphy2==0.8 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.8)\n",
      "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.21.2)\n",
      "Requirement already satisfied: h5py==2.9.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.9.0)\n",
      "Requirement already satisfied: overrides==1.9 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.9)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.4.404381.4453942)\n",
      "Requirement already satisfied: fuzzywuzzy==0.17.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.17.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (3.13)\n",
      "Requirement already satisfied: cryptography>=2.3 in /usr/local/lib/python3.6/dist-packages (from pyopenssl==19.0.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->deeppavlov) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->deeppavlov) (2018.9)\n",
      "Requirement already satisfied: starlette<=0.12.8,>=0.11.1 in /usr/local/lib/python3.6/dist-packages (from fastapi==0.38.1->deeppavlov) (0.12.8)\n",
      "Requirement already satisfied: pydantic<=0.32.2,>=0.32.2 in /usr/local/lib/python3.6/dist-packages (from fastapi==0.38.1->deeppavlov) (0.32.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n",
      "Requirement already satisfied: uvloop==0.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\" in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (0.14.0)\n",
      "Requirement already satisfied: httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\" in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (0.0.13)\n",
      "Requirement already satisfied: h11==0.8.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (0.8.1)\n",
      "Requirement already satisfied: websockets==8.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (8.1)\n",
      "Requirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (7.0)\n",
      "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (2.4.393442.3710985)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov) (0.14.1)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.3->pyopenssl==19.0.0->deeppavlov) (1.13.2)\n",
      "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic<=0.32.2,>=0.32.2->fastapi==0.38.1->deeppavlov) (0.7)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3->pyopenssl==19.0.0->deeppavlov) (2.19)\n"
     ]
    }
   ],
   "source": [
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "colab_type": "code",
    "id": "ZvAzPYGiSgiH",
    "outputId": "0b6cc668-8387-4c5d-9a3a-f6a5808f7942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email-validator not installed, email fields will be treated as str.\n",
      "To install, run: pip install email-validator\n",
      "2019-12-18 16:24:32.860 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'ner_conll2003' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_conll2003.json'\n",
      "Requirement already satisfied: gensim==3.7.3 in /usr/local/lib/python3.6/dist-packages (3.7.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.16.4)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.9.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.7.3) (1.3.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (1.10.36)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (2.22.0)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim==3.7.3) (2.49.0)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim==3.7.3) (1.13.36)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim==3.7.3) (3.0.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.7.0->gensim==3.7.3) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.7.0->gensim==3.7.3) (2.6.1)\n",
      "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (42.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install ner_conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "colab_type": "code",
    "id": "fk5k9aAlSirT",
    "outputId": "38a6451f-671a-4491-fd57-2f41bcd2409e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email-validator not installed, email fields will be treated as str.\n",
      "To install, run: pip install email-validator\n",
      "2019-12-18 16:24:39.470 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'intents_dstc2_big' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/classifiers/intents_dstc2_big.json'\n",
      "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (42.0.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
      "Collecting pybind11==2.2.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/90/0f92a575dc60c8fba6d0c91d6b45abdb1058da9ebed40400cbcfad2ac0a7/pybind11-2.2.3-py2.py3-none-any.whl (144kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 3.5MB/s \n",
      "\u001b[?25hInstalling collected packages: pybind11\n",
      "Successfully installed pybind11-2.2.3\n",
      "Collecting fastText==0.8.22\n",
      "  Cloning https://github.com/deepmipt/fastText.git to /tmp/pip-install-uyycg_x4/fastText\n",
      "  Running command git clone -q https://github.com/deepmipt/fastText.git /tmp/pip-install-uyycg_x4/fastText\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fastText==0.8.22) (2.2.3)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fastText==0.8.22) (42.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastText==0.8.22) (1.16.4)\n",
      "Building wheels for collected packages: fastText\n",
      "  Building wheel for fastText (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fastText: filename=fasttext-0.8.22-cp36-cp36m-linux_x86_64.whl size=2138880 sha256=b1f74e1adab46b2474657b8da7bbaf82f539d0c70f116621fa05eea68e947a65\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0rhuxvcg/wheels/19/a8/8d/f2d5f95a573a8bbf7e818c1914e80d72899233bfb111c04539\n",
      "Successfully built fastText\n",
      "Installing collected packages: fastText\n",
      "Successfully installed fastText-0.8.22\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install intents_dstc2_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmdelvZkSk7H"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset_reader\": {\n",
    "        \"class_name\": \"conll2003_reader\",\n",
    "        \"data_path\": \"./onthology_objects_data_new/dataset_2/\",\n",
    "        \"dataset_name\": \"conll2003\",\n",
    "        \"provide_pos\": False\n",
    "    },\n",
    "    \"dataset_iterator\": {\n",
    "        \"class_name\": \"data_learning_iterator\",\n",
    "        \"seed\": 42\n",
    "    },\n",
    "    \"chainer\": {\n",
    "    \"in\": [\"x\"],\n",
    "    \"in_y\": [\"y\"],\n",
    "    \"pipe\": [\n",
    "      {\n",
    "        \"in\": [\"x\"],\n",
    "        \"class_name\": \"lazy_tokenizer\",\n",
    "        \"out\": [\"x_tokens\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"class_name\": \"str_lower\",\n",
    "        \"out\": [\"x_lower\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_lower\"],\n",
    "        \"class_name\": \"sanitizer\",\n",
    "        \"nums\": True,\n",
    "        \"out\": [\"x_san\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_san\"],\n",
    "        \"id\": \"word_vocab\",\n",
    "        \"class_name\": \"simple_vocab\",\n",
    "        \"pad_with_zeros\": True,\n",
    "        \"special_tokens\": [\"<UNK>\"],\n",
    "        \"fit_on\": [\"x_san\"],\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/word_2_ft.dict\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/word_2_ft.dict\",\n",
    "        \"out\": [\"x_tok_ind\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"y\"],\n",
    "        \"id\": \"tag_vocab\",\n",
    "        \"class_name\": \"simple_vocab\",\n",
    "        \"pad_with_zeros\": True,\n",
    "        \"fit_on\": [\"y\"],\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/tag_2_ft.dict\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/tag_2_ft.dict\",\n",
    "        \"out\": [\"y_ind\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"class_name\": \"char_splitter\",\n",
    "        \"out\": [\"x_char\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_char\"],\n",
    "        \"id\": \"char_vocab\",\n",
    "        \"class_name\": \"simple_vocab\",\n",
    "        \"pad_with_zeros\": True,\n",
    "        \"fit_on\": [\"x_char\"],\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/char_2_ft.dict\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/char_2_ft.dict\",\n",
    "        \"out\": [\"x_char_ind\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"class_name\": \"mask\",\n",
    "        \"out\": [\"mask\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_san\"],\n",
    "        \"id\": \"glove_emb\",\n",
    "        \"class_name\": \"fasttext\",\n",
    "        \"pad_zero\": True,\n",
    "        \"dim\": 300,\n",
    "        \"load_path\": \"{DOWNLOADS_PATH}/embeddings/wiki.en.bin\",\n",
    "        \"out\": [\"x_emb\"]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"embeddings\",\n",
    "        \"class_name\": \"emb_mat_assembler\",\n",
    "        \"embedder\": \"#glove_emb\",\n",
    "        \"vocab\": \"#word_vocab\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"embeddings_char\",\n",
    "        \"class_name\": \"emb_mat_assembler\",\n",
    "        \"character_level\": True,\n",
    "        \"emb_dim\": 32,\n",
    "        \"embedder\": \"#glove_emb\",\n",
    "        \"vocab\": \"#char_vocab\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"capitalization\",\n",
    "        \"class_name\": \"capitalization_featurizer\",\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"out\": [\"cap\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_emb\", \"mask\", \"x_char_ind\", \"cap\"],\n",
    "        \"in_y\": [\"y_ind\"],\n",
    "        \"out\": [\"y_predicted\"],\n",
    "        \"class_name\": \"ner\",\n",
    "        \"main\": True,\n",
    "        \"token_emb_dim\": \"#glove_emb.dim\",\n",
    "        \"n_hidden_list\": [128],\n",
    "        \"net_type\": \"rnn\",\n",
    "        \"cell_type\": \"lstm\",\n",
    "        \"use_cudnn_rnn\": True,\n",
    "        \"n_tags\": \"#tag_vocab.len\",\n",
    "        \"capitalization_dim\": \"#capitalization.dim\",\n",
    "        \"char_emb_dim\": \"#embeddings_char.dim\",\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/model_no_pos_2_ft\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/model_no_pos_2_ft\",\n",
    "        \"char_emb_mat\": \"#embeddings_char.emb_mat\",\n",
    "        \"two_dense_on_top\": True,\n",
    "        \"use_crf\": True,\n",
    "        \"use_batch_norm\": True,\n",
    "        \"embeddings_dropout\": True,\n",
    "        \"top_dropout\": True,\n",
    "        \"intra_layer_dropout\": True,\n",
    "        \"l2_reg\": 0,\n",
    "        \"learning_rate\": 1e-2,\n",
    "        \"dropout_keep_prob\": 0.5\n",
    "      },\n",
    "      {\n",
    "        \"ref\": \"tag_vocab\",\n",
    "        \"in\": [\"y_predicted\"],\n",
    "        \"out\": [\"tags\"]\n",
    "      }\n",
    "    ],\n",
    "    \"out\": [\"x_tokens\", \"tags\"]\n",
    "  },\n",
    "    \"train\": {\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 64,\n",
    "        \"metrics\": [\n",
    "            {\n",
    "                \"name\": \"ner_f1\",\n",
    "                \"inputs\": [\n",
    "                    \"y\",\n",
    "                    \"tags\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"validation_patience\": 7,\n",
    "        \"val_every_n_epochs\": 1,\n",
    "        \"log_every_n_epochs\": -1,\n",
    "        \"show_examples\": False,\n",
    "        \"validate_best\": True,\n",
    "        \"test_best\": True\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"variables\": {\n",
    "            \"ROOT_PATH\": \"~/.deeppavlov\",\n",
    "            \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\n",
    "            \"MODELS_PATH\": \"{ROOT_PATH}/models\"\n",
    "        },\n",
    "        \"requirements\": [\n",
    "            \"{DEEPPAVLOV_PATH}/requirements/fasttext.txt\",\n",
    "            \"{DEEPPAVLOV_PATH}/requirements/tf.txt\"\n",
    "        ],\n",
    "        \"labels\": {\n",
    "            \"telegram_utils\": \"NERCoNLL2003Model\",\n",
    "            \"server_utils\": \"NER\"\n",
    "        },\n",
    "        \"download\": [\n",
    "            {\n",
    "                \"url\": \"http://files.deeppavlov.ai/deeppavlov_data/embeddings/wiki.en.bin\",\n",
    "                \"subdir\": \"{DOWNLOADS_PATH}/embeddings\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9c_r_0pSoRA"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"config.json\", \"w\") as fout:\n",
    "  json.dump(config, fout, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dpABkP6qSqP_",
    "outputId": "2e306fbb-f92c-4c73-9514-12646d561a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './downloads/embeddings/wiki.en.bin': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! rm ./downloads/embeddings/wiki.en.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "llcxJ0NwSs0Z",
    "outputId": "a028d271-5f5b-49da-8798-7af7ed67aea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email-validator not installed, email fields will be treated as str.\n",
      "To install, run: pip install email-validator\n",
      "2019-12-18 16:25:22.595 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/embeddings/wiki.en.bin?config=config to /root/.deeppavlov/downloads/embeddings/wiki.en.bin\n",
      "100% 8.49G/8.49G [23:09<00:00, 6.11MB/s]\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov download config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HRIor2G0SvEm",
    "outputId": "dc42581e-e1da-446e-f579-17ff38813420"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:48:32.378 WARNING in 'deeppavlov.core.commands.train'['train'] at line 108: \"validate_best\" and \"test_best\" parameters are deprecated. Please, use \"evaluation_targets\" list instead\n",
      "2019-12-18 16:48:32.667 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/onthology_objects/word_2_ft.dict]\n",
      "2019-12-18 16:48:32.690 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/onthology_objects/tag_2_ft.dict]\n",
      "2019-12-18 16:48:34.66 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/onthology_objects/char_2_ft.dict]\n",
      "2019-12-18 16:48:34.75 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 67: [loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/wiki.en.bin`]\n",
      "2019-12-18 16:48:50.209 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:48:50.307 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:48:52.931 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 1039 phrases; correct: 0.\n",
      "\n",
      "precision:  3.56%; recall:  3.60%; FB1:  3.58\n",
      "\n",
      "\tO: precision:  0.63%; recall:  10.00%; F1:  1.19 317\n",
      "\n",
      "\tattribute: precision:  0.00%; recall:  0.00%; F1:  0.00 24\n",
      "\n",
      "\tmeasure: precision:  0.93%; recall:  11.11%; F1:  1.71 324\n",
      "\n",
      "\tobject: precision:  8.09%; recall:  7.20%; F1:  7.62 309\n",
      "\n",
      "\tprocess: precision:  0.00%; recall:  0.00%; F1:  0.00 4\n",
      "\n",
      "\tpsychological_feature: precision:  11.48%; recall:  1.72%; F1:  2.99 61\n",
      "\n",
      "\n",
      "2019-12-18 16:48:52.932 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 3.5801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 3.5801}, \"time_spent\": \"0:00:01\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:49:04.432 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 432 phrases; correct: 0.\n",
      "\n",
      "precision:  45.14%; recall:  18.97%; FB1:  26.71\n",
      "\n",
      "\tO: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tattribute: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tmeasure: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tobject: precision:  100.00%; recall:  2.02%; F1:  3.95 7\n",
      "\n",
      "\tprocess: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tpsychological_feature: precision:  44.24%; recall:  46.19%; F1:  45.19 425\n",
      "\n",
      "\n",
      "2019-12-18 16:49:04.434 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 26.7123\n",
      "2019-12-18 16:49:04.434 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:49:04.435 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 26.7123}, \"time_spent\": \"0:00:13\", \"epochs_done\": 1, \"batches_seen\": 28, \"train_examples_seen\": 1770, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:49:16.434 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 833 phrases; correct: 0.\n",
      "\n",
      "precision:  51.98%; recall:  42.12%; FB1:  46.53\n",
      "\n",
      "\tO: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tattribute: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tmeasure: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tobject: precision:  62.16%; recall:  39.77%; F1:  48.51 222\n",
      "\n",
      "\tprocess: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tpsychological_feature: precision:  48.36%; recall:  72.48%; F1:  58.01 610\n",
      "\n",
      "\n",
      "2019-12-18 16:49:16.436 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 46.5341\n",
      "2019-12-18 16:49:16.436 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:49:16.437 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 46.5341}, \"time_spent\": \"0:00:25\", \"epochs_done\": 2, \"batches_seen\": 56, \"train_examples_seen\": 3540, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:49:27.363 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 826 phrases; correct: 0.\n",
      "\n",
      "precision:  59.20%; recall:  47.57%; FB1:  52.75\n",
      "\n",
      "\tO: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tattribute: precision:  57.69%; recall:  19.48%; F1:  29.13 52\n",
      "\n",
      "\tmeasure: precision:  35.00%; recall:  25.93%; F1:  29.79 20\n",
      "\n",
      "\tobject: precision:  68.48%; recall:  50.72%; F1:  58.28 257\n",
      "\n",
      "\tprocess: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tpsychological_feature: precision:  55.53%; recall:  67.81%; F1:  61.06 497\n",
      "\n",
      "\n",
      "2019-12-18 16:49:27.364 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 52.7508\n",
      "2019-12-18 16:49:27.365 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:49:27.366 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 52.7508}, \"time_spent\": \"0:00:36\", \"epochs_done\": 3, \"batches_seen\": 84, \"train_examples_seen\": 5310, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:49:38.338 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 908 phrases; correct: 0.\n",
      "\n",
      "precision:  59.91%; recall:  52.92%; FB1:  56.20\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tattribute: precision:  49.46%; recall:  29.87%; F1:  37.25 93\n",
      "\n",
      "\tmeasure: precision:  66.67%; recall:  29.63%; F1:  41.03 12\n",
      "\n",
      "\tobject: precision:  67.18%; recall:  50.72%; F1:  57.80 262\n",
      "\n",
      "\tprocess: precision:  60.00%; recall:  8.22%; F1:  14.46 10\n",
      "\n",
      "\tpsychological_feature: precision:  56.70%; recall:  71.74%; F1:  63.34 515\n",
      "\n",
      "\n",
      "2019-12-18 16:49:38.340 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 56.1983\n",
      "2019-12-18 16:49:38.340 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:49:38.342 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 56.1983}, \"time_spent\": \"0:00:47\", \"epochs_done\": 4, \"batches_seen\": 112, \"train_examples_seen\": 7080, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:49:49.301 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 948 phrases; correct: 0.\n",
      "\n",
      "precision:  62.97%; recall:  58.07%; FB1:  60.43\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tattribute: precision:  54.90%; recall:  36.36%; F1:  43.75 102\n",
      "\n",
      "\tmeasure: precision:  66.67%; recall:  29.63%; F1:  41.03 12\n",
      "\n",
      "\tobject: precision:  68.81%; recall:  58.50%; F1:  63.24 295\n",
      "\n",
      "\tprocess: precision:  64.29%; recall:  24.66%; F1:  35.64 28\n",
      "\n",
      "\tpsychological_feature: precision:  59.80%; recall:  72.73%; F1:  65.63 495\n",
      "\n",
      "\n",
      "2019-12-18 16:49:49.302 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 60.4251\n",
      "2019-12-18 16:49:49.303 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:49:49.304 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 60.4251}, \"time_spent\": \"0:00:58\", \"epochs_done\": 5, \"batches_seen\": 140, \"train_examples_seen\": 8850, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:50:00.279 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 912 phrases; correct: 0.\n",
      "\n",
      "precision:  63.27%; recall:  56.13%; FB1:  59.48\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tattribute: precision:  48.45%; recall:  50.65%; F1:  49.52 161\n",
      "\n",
      "\tmeasure: precision:  64.29%; recall:  33.33%; F1:  43.90 14\n",
      "\n",
      "\tobject: precision:  77.06%; recall:  51.30%; F1:  61.59 231\n",
      "\n",
      "\tprocess: precision:  57.14%; recall:  16.44%; F1:  25.53 21\n",
      "\n",
      "\tpsychological_feature: precision:  60.55%; recall:  69.78%; F1:  64.84 469\n",
      "\n",
      "\n",
      "2019-12-18 16:50:00.280 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 60.4251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 59.4845}, \"time_spent\": \"0:01:09\", \"epochs_done\": 6, \"batches_seen\": 168, \"train_examples_seen\": 10620, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:50:11.90 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 951 phrases; correct: 0.\n",
      "\n",
      "precision:  67.72%; recall:  62.65%; FB1:  65.08\n",
      "\n",
      "\tO: precision:  84.21%; recall:  80.00%; F1:  82.05 19\n",
      "\n",
      "\tattribute: precision:  55.97%; recall:  48.70%; F1:  52.08 134\n",
      "\n",
      "\tmeasure: precision:  56.52%; recall:  48.15%; F1:  52.00 23\n",
      "\n",
      "\tobject: precision:  76.01%; recall:  64.84%; F1:  69.98 296\n",
      "\n",
      "\tprocess: precision:  56.10%; recall:  31.51%; F1:  40.35 41\n",
      "\n",
      "\tpsychological_feature: precision:  66.67%; recall:  71.74%; F1:  69.11 438\n",
      "\n",
      "\n",
      "2019-12-18 16:50:11.91 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 65.0834\n",
      "2019-12-18 16:50:11.92 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:50:11.93 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 65.0834}, \"time_spent\": \"0:01:19\", \"epochs_done\": 7, \"batches_seen\": 196, \"train_examples_seen\": 12390, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:50:22.166 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 939 phrases; correct: 0.\n",
      "\n",
      "precision:  65.60%; recall:  59.92%; FB1:  62.63\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tattribute: precision:  54.89%; recall:  47.40%; F1:  50.87 133\n",
      "\n",
      "\tmeasure: precision:  53.85%; recall:  25.93%; F1:  35.00 13\n",
      "\n",
      "\tobject: precision:  77.02%; recall:  55.04%; F1:  64.20 248\n",
      "\n",
      "\tprocess: precision:  73.91%; recall:  23.29%; F1:  35.42 23\n",
      "\n",
      "\tpsychological_feature: precision:  61.66%; recall:  76.66%; F1:  68.35 506\n",
      "\n",
      "\n",
      "2019-12-18 16:50:22.167 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 65.0834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 62.6335}, \"time_spent\": \"0:01:31\", \"epochs_done\": 8, \"batches_seen\": 224, \"train_examples_seen\": 14160, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:50:32.958 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 885 phrases; correct: 0.\n",
      "\n",
      "precision:  67.23%; recall:  57.88%; FB1:  62.21\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tattribute: precision:  56.59%; recall:  47.40%; F1:  51.59 129\n",
      "\n",
      "\tmeasure: precision:  56.25%; recall:  33.33%; F1:  41.86 16\n",
      "\n",
      "\tobject: precision:  74.46%; recall:  59.65%; F1:  66.24 278\n",
      "\n",
      "\tprocess: precision:  54.05%; recall:  27.40%; F1:  36.36 37\n",
      "\n",
      "\tpsychological_feature: precision:  66.01%; recall:  66.34%; F1:  66.18 409\n",
      "\n",
      "\n",
      "2019-12-18 16:50:32.960 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 65.0834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 62.206}, \"time_spent\": \"0:01:41\", \"epochs_done\": 9, \"batches_seen\": 252, \"train_examples_seen\": 15930, \"impatience\": 2, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:50:43.955 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 920 phrases; correct: 0.\n",
      "\n",
      "precision:  70.00%; recall:  62.65%; FB1:  66.12\n",
      "\n",
      "\tO: precision:  88.89%; recall:  80.00%; F1:  84.21 18\n",
      "\n",
      "\tattribute: precision:  62.73%; recall:  44.81%; F1:  52.27 110\n",
      "\n",
      "\tmeasure: precision:  72.22%; recall:  48.15%; F1:  57.78 18\n",
      "\n",
      "\tobject: precision:  75.34%; recall:  64.27%; F1:  69.36 296\n",
      "\n",
      "\tprocess: precision:  47.78%; recall:  58.90%; F1:  52.76 90\n",
      "\n",
      "\tpsychological_feature: precision:  72.16%; recall:  68.80%; F1:  70.44 388\n",
      "\n",
      "\n",
      "2019-12-18 16:50:43.957 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 66.1191\n",
      "2019-12-18 16:50:43.958 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:50:43.959 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 66.1191}, \"time_spent\": \"0:01:52\", \"epochs_done\": 10, \"batches_seen\": 280, \"train_examples_seen\": 17700, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:50:55.14 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 975 phrases; correct: 0.\n",
      "\n",
      "precision:  67.49%; recall:  64.01%; FB1:  65.70\n",
      "\n",
      "\tO: precision:  88.89%; recall:  80.00%; F1:  84.21 18\n",
      "\n",
      "\tattribute: precision:  55.07%; recall:  49.35%; F1:  52.05 138\n",
      "\n",
      "\tmeasure: precision:  65.00%; recall:  48.15%; F1:  55.32 20\n",
      "\n",
      "\tobject: precision:  73.65%; recall:  66.86%; F1:  70.09 315\n",
      "\n",
      "\tprocess: precision:  47.78%; recall:  58.90%; F1:  52.76 90\n",
      "\n",
      "\tpsychological_feature: precision:  70.56%; recall:  68.30%; F1:  69.41 394\n",
      "\n",
      "\n",
      "2019-12-18 16:50:55.16 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 66.1191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 65.7014}, \"time_spent\": \"0:02:03\", \"epochs_done\": 11, \"batches_seen\": 308, \"train_examples_seen\": 19470, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:51:05.405 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 950 phrases; correct: 0.\n",
      "\n",
      "precision:  66.11%; recall:  61.09%; FB1:  63.50\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tattribute: precision:  60.00%; recall:  44.81%; F1:  51.30 115\n",
      "\n",
      "\tmeasure: precision:  65.38%; recall:  62.96%; F1:  64.15 26\n",
      "\n",
      "\tobject: precision:  77.91%; recall:  55.91%; F1:  65.10 249\n",
      "\n",
      "\tprocess: precision:  54.55%; recall:  24.66%; F1:  33.96 33\n",
      "\n",
      "\tpsychological_feature: precision:  61.93%; recall:  77.15%; F1:  68.71 507\n",
      "\n",
      "\n",
      "2019-12-18 16:51:05.406 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 66.1191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 63.4985}, \"time_spent\": \"0:02:14\", \"epochs_done\": 12, \"batches_seen\": 336, \"train_examples_seen\": 21240, \"impatience\": 2, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:51:15.972 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 980 phrases; correct: 0.\n",
      "\n",
      "precision:  67.35%; recall:  64.20%; FB1:  65.74\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tattribute: precision:  57.60%; recall:  46.75%; F1:  51.61 125\n",
      "\n",
      "\tmeasure: precision:  70.59%; recall:  44.44%; F1:  54.55 17\n",
      "\n",
      "\tobject: precision:  71.81%; recall:  69.74%; F1:  70.76 337\n",
      "\n",
      "\tprocess: precision:  44.04%; recall:  65.75%; F1:  52.75 109\n",
      "\n",
      "\tpsychological_feature: precision:  71.81%; recall:  66.34%; F1:  68.97 376\n",
      "\n",
      "\n",
      "2019-12-18 16:51:15.973 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 66.1191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 65.7371}, \"time_spent\": \"0:02:24\", \"epochs_done\": 13, \"batches_seen\": 364, \"train_examples_seen\": 23010, \"impatience\": 3, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:51:26.703 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 960 phrases; correct: 0.\n",
      "\n",
      "precision:  69.38%; recall:  64.79%; FB1:  67.00\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tattribute: precision:  68.93%; recall:  46.10%; F1:  55.25 103\n",
      "\n",
      "\tmeasure: precision:  62.50%; recall:  37.04%; F1:  46.51 16\n",
      "\n",
      "\tobject: precision:  76.53%; recall:  64.84%; F1:  70.20 294\n",
      "\n",
      "\tprocess: precision:  60.61%; recall:  27.40%; F1:  37.74 33\n",
      "\n",
      "\tpsychological_feature: precision:  65.59%; recall:  79.61%; F1:  71.92 494\n",
      "\n",
      "\n",
      "2019-12-18 16:51:26.704 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 67.002\n",
      "2019-12-18 16:51:26.705 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:51:26.706 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 67.002}, \"time_spent\": \"0:02:35\", \"epochs_done\": 14, \"batches_seen\": 392, \"train_examples_seen\": 24780, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:51:37.580 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 993 phrases; correct: 0.\n",
      "\n",
      "precision:  69.79%; recall:  67.41%; FB1:  68.58\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tattribute: precision:  58.70%; recall:  52.60%; F1:  55.48 138\n",
      "\n",
      "\tmeasure: precision:  61.90%; recall:  48.15%; F1:  54.17 21\n",
      "\n",
      "\tobject: precision:  73.93%; recall:  69.45%; F1:  71.62 326\n",
      "\n",
      "\tprocess: precision:  53.12%; recall:  69.86%; F1:  60.36 96\n",
      "\n",
      "\tpsychological_feature: precision:  73.48%; recall:  71.50%; F1:  72.48 396\n",
      "\n",
      "\n",
      "2019-12-18 16:51:37.582 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 68.5799\n",
      "2019-12-18 16:51:37.583 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:51:37.584 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 68.5799}, \"time_spent\": \"0:02:46\", \"epochs_done\": 15, \"batches_seen\": 420, \"train_examples_seen\": 26550, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:51:48.519 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 1004 phrases; correct: 0.\n",
      "\n",
      "precision:  67.43%; recall:  65.86%; FB1:  66.63\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tattribute: precision:  60.66%; recall:  48.05%; F1:  53.62 122\n",
      "\n",
      "\tmeasure: precision:  56.00%; recall:  51.85%; F1:  53.85 25\n",
      "\n",
      "\tobject: precision:  70.32%; recall:  70.32%; F1:  70.32 347\n",
      "\n",
      "\tprocess: precision:  48.67%; recall:  75.34%; F1:  59.14 113\n",
      "\n",
      "\tpsychological_feature: precision:  72.68%; recall:  67.32%; F1:  69.90 377\n",
      "\n",
      "\n",
      "2019-12-18 16:51:48.520 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 68.5799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 66.6339}, \"time_spent\": \"0:02:57\", \"epochs_done\": 16, \"batches_seen\": 448, \"train_examples_seen\": 28320, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:51:59.278 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 959 phrases; correct: 0.\n",
      "\n",
      "precision:  68.61%; recall:  64.01%; FB1:  66.23\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tattribute: precision:  57.45%; recall:  52.60%; F1:  54.92 141\n",
      "\n",
      "\tmeasure: precision:  62.50%; recall:  37.04%; F1:  46.51 16\n",
      "\n",
      "\tobject: precision:  76.16%; recall:  66.28%; F1:  70.88 302\n",
      "\n",
      "\tprocess: precision:  46.43%; recall:  53.42%; F1:  49.68 84\n",
      "\n",
      "\tpsychological_feature: precision:  70.50%; recall:  69.29%; F1:  69.89 400\n",
      "\n",
      "\n",
      "2019-12-18 16:51:59.279 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 68.5799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 66.2305}, \"time_spent\": \"0:03:08\", \"epochs_done\": 17, \"batches_seen\": 476, \"train_examples_seen\": 30090, \"impatience\": 2, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:52:10.425 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 958 phrases; correct: 0.\n",
      "\n",
      "precision:  68.89%; recall:  64.20%; FB1:  66.47\n",
      "\n",
      "\tO: precision:  88.89%; recall:  80.00%; F1:  84.21 18\n",
      "\n",
      "\tattribute: precision:  65.42%; recall:  45.45%; F1:  53.64 107\n",
      "\n",
      "\tmeasure: precision:  50.00%; recall:  33.33%; F1:  40.00 18\n",
      "\n",
      "\tobject: precision:  75.73%; recall:  67.44%; F1:  71.34 309\n",
      "\n",
      "\tprocess: precision:  55.56%; recall:  34.25%; F1:  42.37 45\n",
      "\n",
      "\tpsychological_feature: precision:  66.38%; recall:  75.18%; F1:  70.51 461\n",
      "\n",
      "\n",
      "2019-12-18 16:52:10.426 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 68.5799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 66.4653}, \"time_spent\": \"0:03:19\", \"epochs_done\": 18, \"batches_seen\": 504, \"train_examples_seen\": 31860, \"impatience\": 3, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:52:21.97 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 981 phrases; correct: 0.\n",
      "\n",
      "precision:  67.89%; recall:  64.79%; FB1:  66.30\n",
      "\n",
      "\tO: precision:  90.00%; recall:  90.00%; F1:  90.00 20\n",
      "\n",
      "\tattribute: precision:  60.00%; recall:  50.65%; F1:  54.93 130\n",
      "\n",
      "\tmeasure: precision:  64.71%; recall:  40.74%; F1:  50.00 17\n",
      "\n",
      "\tobject: precision:  75.08%; recall:  67.72%; F1:  71.21 313\n",
      "\n",
      "\tprocess: precision:  51.72%; recall:  41.10%; F1:  45.80 58\n",
      "\n",
      "\tpsychological_feature: precision:  66.37%; recall:  72.24%; F1:  69.18 443\n",
      "\n",
      "\n",
      "2019-12-18 16:52:21.99 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 68.5799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 66.3016}, \"time_spent\": \"0:03:29\", \"epochs_done\": 19, \"batches_seen\": 532, \"train_examples_seen\": 33630, \"impatience\": 4, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:52:31.691 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 980 phrases; correct: 0.\n",
      "\n",
      "precision:  68.06%; recall:  64.88%; FB1:  66.43\n",
      "\n",
      "\tO: precision:  90.00%; recall:  90.00%; F1:  90.00 20\n",
      "\n",
      "\tattribute: precision:  52.97%; recall:  63.64%; F1:  57.82 185\n",
      "\n",
      "\tmeasure: precision:  56.25%; recall:  66.67%; F1:  61.02 32\n",
      "\n",
      "\tobject: precision:  77.56%; recall:  67.72%; F1:  72.31 303\n",
      "\n",
      "\tprocess: precision:  47.92%; recall:  31.51%; F1:  38.02 48\n",
      "\n",
      "\tpsychological_feature: precision:  70.15%; recall:  67.57%; F1:  68.84 392\n",
      "\n",
      "\n",
      "2019-12-18 16:52:31.692 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 68.5799\n",
      "2019-12-18 16:52:31.794 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 66.4343}, \"time_spent\": \"0:03:40\", \"epochs_done\": 20, \"batches_seen\": 560, \"train_examples_seen\": 35400, \"impatience\": 5, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:52:42.469 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 993 phrases; correct: 0.\n",
      "\n",
      "precision:  67.47%; recall:  65.18%; FB1:  66.30\n",
      "\n",
      "\tO: precision:  90.00%; recall:  90.00%; F1:  90.00 20\n",
      "\n",
      "\tattribute: precision:  59.12%; recall:  52.60%; F1:  55.67 137\n",
      "\n",
      "\tmeasure: precision:  66.67%; recall:  59.26%; F1:  62.75 24\n",
      "\n",
      "\tobject: precision:  75.32%; recall:  68.59%; F1:  71.79 316\n",
      "\n",
      "\tprocess: precision:  45.00%; recall:  36.99%; F1:  40.60 60\n",
      "\n",
      "\tpsychological_feature: precision:  66.51%; recall:  71.25%; F1:  68.80 436\n",
      "\n",
      "\n",
      "2019-12-18 16:52:42.471 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 68.5799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 66.3038}, \"time_spent\": \"0:03:51\", \"epochs_done\": 21, \"batches_seen\": 588, \"train_examples_seen\": 37170, \"impatience\": 6, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:52:53.150 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 994 phrases; correct: 0.\n",
      "\n",
      "precision:  67.20%; recall:  64.98%; FB1:  66.07\n",
      "\n",
      "\tO: precision:  90.00%; recall:  90.00%; F1:  90.00 20\n",
      "\n",
      "\tattribute: precision:  56.08%; recall:  53.90%; F1:  54.97 148\n",
      "\n",
      "\tmeasure: precision:  65.00%; recall:  48.15%; F1:  55.32 20\n",
      "\n",
      "\tobject: precision:  74.77%; recall:  69.16%; F1:  71.86 321\n",
      "\n",
      "\tprocess: precision:  46.15%; recall:  32.88%; F1:  38.40 52\n",
      "\n",
      "\tpsychological_feature: precision:  66.97%; recall:  71.25%; F1:  69.05 433\n",
      "\n",
      "\n",
      "2019-12-18 16:52:53.152 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 68.5799\n",
      "2019-12-18 16:52:53.254 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 328: Ran out of patience\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 66.0732}, \"time_spent\": \"0:04:02\", \"epochs_done\": 22, \"batches_seen\": 616, \"train_examples_seen\": 38940, \"impatience\": 7, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:52:54.46 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/word_2_ft.dict]\n",
      "2019-12-18 16:52:54.55 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/tag_2_ft.dict]\n",
      "2019-12-18 16:52:54.57 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/char_2_ft.dict]\n",
      "2019-12-18 16:52:54.59 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 67: [loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/wiki.en.bin`]\n",
      "2019-12-18 16:53:05.930 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:53:06.28 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:53:07.869 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:53:08.836 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 993 phrases; correct: 0.\n",
      "\n",
      "precision:  69.79%; recall:  67.41%; FB1:  68.58\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tattribute: precision:  58.70%; recall:  52.60%; F1:  55.48 138\n",
      "\n",
      "\tmeasure: precision:  61.90%; recall:  48.15%; F1:  54.17 21\n",
      "\n",
      "\tobject: precision:  73.93%; recall:  69.45%; F1:  71.62 326\n",
      "\n",
      "\tprocess: precision:  53.12%; recall:  69.86%; F1:  60.36 96\n",
      "\n",
      "\tpsychological_feature: precision:  73.48%; recall:  71.50%; F1:  72.48 396\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 68.5799}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:53:09.562 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 4290 tokens with 971 phrases; found: 968 phrases; correct: 0.\n",
      "\n",
      "precision:  66.53%; recall:  66.32%; FB1:  66.43\n",
      "\n",
      "\tO: precision:  69.23%; recall:  52.94%; F1:  60.00 26\n",
      "\n",
      "\tattribute: precision:  46.94%; recall:  45.54%; F1:  46.23 98\n",
      "\n",
      "\tmeasure: precision:  71.88%; recall:  63.89%; F1:  67.65 32\n",
      "\n",
      "\tobject: precision:  69.35%; recall:  75.42%; F1:  72.26 323\n",
      "\n",
      "\tprocess: precision:  47.22%; recall:  36.17%; F1:  40.96 36\n",
      "\n",
      "\tpsychological_feature: precision:  69.76%; recall:  69.30%; F1:  69.53 453\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"test\": {\"eval_examples_count\": 222, \"metrics\": {\"ner_f1\": 66.426}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:53:10.2 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/word_2_ft.dict]\n",
      "2019-12-18 16:53:10.12 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/tag_2_ft.dict]\n",
      "2019-12-18 16:53:10.13 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/char_2_ft.dict]\n",
      "2019-12-18 16:53:10.15 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 67: [loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/wiki.en.bin`]\n",
      "2019-12-18 16:53:20.944 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:53:21.43 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:53:22.844 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft\n"
     ]
    }
   ],
   "source": [
    "model1 = train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dRz7UymWS1Kf",
    "outputId": "c3b96340-f7d9-48b3-f9fe-ddcc8645c194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email-validator not installed, email fields will be treated as str.\n",
      "To install, run: pip install email-validator\n",
      "2019-12-18 16:53:24.544 WARNING in 'deeppavlov.core.commands.train'['train'] at line 108: \"validate_best\" and \"test_best\" parameters are deprecated. Please, use \"evaluation_targets\" list instead\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "2019-12-18 16:53:25.207 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/word_2_ft.dict]\n",
      "2019-12-18 16:53:25.216 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/tag_2_ft.dict]\n",
      "2019-12-18 16:53:25.217 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/char_2_ft.dict]\n",
      "2019-12-18 16:53:25.221 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 67: [loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/wiki.en.bin`]\n",
      "tcmalloc: large alloc 5423251456 bytes == 0x2ff7e000 @  0x7f4768014887 0x7f46fb0669b3 0x7f46fb05ad4c 0x7f46fb05b6b1 0x7f46fb032de3 0x7f46fb04e566 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x5096b7 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5a067e 0x50d966 0x508245\n",
      "tcmalloc: large alloc 3023249408 bytes == 0x173bd6000 @  0x7f4768014887 0x7f46fb0669b3 0x7f46fb05aae3 0x7f46fb05b6b1 0x7f46fb032de3 0x7f46fb04e566 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x5096b7 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5a067e 0x50d966 0x508245\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:96: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:170: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:405: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:416: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:211: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2019-12-18 16:53:45.219175: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-18 16:53:45.223888: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-12-18 16:53:45.225418: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3be0bc0 executing computations on platform Host. Devices:\n",
      "2019-12-18 16:53:45.225454: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-12-18 16:53:45.227 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:729: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:733: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:736: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:861: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "2019-12-18 16:53:46.922 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:245: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/crf/python/ops/crf.py:99: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2019-12-18 16:53:48.999810: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:50: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2019-12-18 16:53:49.14 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "2019-12-18 16:53:49.276464: W tensorflow/core/framework/allocator.cc:107] Allocation of 33619968 exceeds 10% of system memory.\n",
      "2019-12-18 16:53:49.454977: W tensorflow/core/framework/allocator.cc:107] Allocation of 39911424 exceeds 10% of system memory.\n",
      "2019-12-18 16:53:49.640895: W tensorflow/core/framework/allocator.cc:107] Allocation of 31195136 exceeds 10% of system memory.\n",
      "2019-12-18 16:53:49.899 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 993 phrases; correct: 0.\n",
      "\n",
      "precision:  69.79%; recall:  67.41%; FB1:  68.58\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tattribute: precision:  58.70%; recall:  52.60%; F1:  55.48 138\n",
      "\n",
      "\tmeasure: precision:  61.90%; recall:  48.15%; F1:  54.17 21\n",
      "\n",
      "\tobject: precision:  73.93%; recall:  69.45%; F1:  71.62 326\n",
      "\n",
      "\tprocess: precision:  53.12%; recall:  69.86%; F1:  60.36 96\n",
      "\n",
      "\tpsychological_feature: precision:  73.48%; recall:  71.50%; F1:  72.48 396\n",
      "\n",
      "\n",
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 68.5799}, \"time_spent\": \"0:00:01\"}}\n",
      "2019-12-18 16:53:49.949035: W tensorflow/core/framework/allocator.cc:107] Allocation of 60751872 exceeds 10% of system memory.\n",
      "2019-12-18 16:53:50.153746: W tensorflow/core/framework/allocator.cc:107] Allocation of 27852800 exceeds 10% of system memory.\n",
      "2019-12-18 16:53:50.524 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 4290 tokens with 971 phrases; found: 968 phrases; correct: 0.\n",
      "\n",
      "precision:  66.53%; recall:  66.32%; FB1:  66.43\n",
      "\n",
      "\tO: precision:  69.23%; recall:  52.94%; F1:  60.00 26\n",
      "\n",
      "\tattribute: precision:  46.94%; recall:  45.54%; F1:  46.23 98\n",
      "\n",
      "\tmeasure: precision:  71.88%; recall:  63.89%; F1:  67.65 32\n",
      "\n",
      "\tobject: precision:  69.35%; recall:  75.42%; F1:  72.26 323\n",
      "\n",
      "\tprocess: precision:  47.22%; recall:  36.17%; F1:  40.96 36\n",
      "\n",
      "\tpsychological_feature: precision:  69.76%; recall:  69.30%; F1:  69.53 453\n",
      "\n",
      "\n",
      "{\"test\": {\"eval_examples_count\": 222, \"metrics\": {\"ner_f1\": 66.426}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov evaluate config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "colab_type": "code",
    "id": "vGwds2VrVhfn",
    "outputId": "4e2328de-1504-4e5f-a6e7-cea38c973ab4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:53:52.553 WARNING in 'deeppavlov.core.commands.train'['train'] at line 108: \"validate_best\" and \"test_best\" parameters are deprecated. Please, use \"evaluation_targets\" list instead\n",
      "2019-12-18 16:53:52.755 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/word_2_ft.dict]\n",
      "2019-12-18 16:53:52.765 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/tag_2_ft.dict]\n",
      "2019-12-18 16:53:52.767 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/char_2_ft.dict]\n",
      "2019-12-18 16:53:52.768 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 67: [loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/wiki.en.bin`]\n",
      "2019-12-18 16:54:06.496 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:54:06.595 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:54:09.96 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/onthology_objects/model_no_pos_2_ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:54:10.78 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1028 phrases; found: 993 phrases; correct: 0.\n",
      "\n",
      "precision:  69.79%; recall:  67.41%; FB1:  68.58\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tattribute: precision:  58.70%; recall:  52.60%; F1:  55.48 138\n",
      "\n",
      "\tmeasure: precision:  61.90%; recall:  48.15%; F1:  54.17 21\n",
      "\n",
      "\tobject: precision:  73.93%; recall:  69.45%; F1:  71.62 326\n",
      "\n",
      "\tprocess: precision:  53.12%; recall:  69.86%; F1:  60.36 96\n",
      "\n",
      "\tpsychological_feature: precision:  73.48%; recall:  71.50%; F1:  72.48 396\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 68.5799}, \"time_spent\": \"0:00:01\", \"examples\": [{\"x\": [\"the\", \"key\", \"consideration\", \"is\", \"whether\", \"and\", \"to\", \"what\", \"extent\", \"the\", \"administrative\", \"record\", \"data\", \"re\", \"examined\", \"retroactively\", \"a\", \"decade\", \"later\", \"for\", \"the\", \"original\", \"study's\", \"time\", \"period\", \"would\", \"yield\", \"comparable\", \"results\", \"to\", \"those\", \"based\", \"on\", \"data\", \"acquired\", \"at\", \"the\", \"time\", \"of\", \"the\", \"study\", \".\"], \"y_predicted\": [[\"O\", \"B-object\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"B-object\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-measure\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"B-measure\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-measure\", \"O\", \"O\", \"B-object\", \"O\"], [\"the\", \"key\", \"consideration\", \"is\", \"whether\", \"and\", \"to\", \"what\", \"extent\", \"the\", \"administrative\", \"record\", \"data\", \"re\", \"examined\", \"retroactively\", \"a\", \"decade\", \"later\", \"for\", \"the\", \"original\", \"study's\", \"time\", \"period\", \"would\", \"yield\", \"comparable\", \"results\", \"to\", \"those\", \"based\", \"on\", \"data\", \"acquired\", \"at\", \"the\", \"time\", \"of\", \"the\", \"study\", \".\"]], \"y_true\": [\"O\", \"B-psychological_feature\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-measure\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"I-attribute\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"B-psychological_feature\", \"O\"]}, {\"x\": [\"the\", \"results\", \"indicated\", \"that\", \"despite\", \"small\", \"changes\", \"over\", \"time\", \",\", \"the\", \"same\", \"data\", \"patterns\", \"and\", \"statistical\", \"effects\", \"were\", \"reproducible\", \"for\", \"the\", \"two\", \"archival\", \"outcome\", \"variables\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-attribute\", \"O\", \"B-psychological_feature\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\"], [\"the\", \"results\", \"indicated\", \"that\", \"despite\", \"small\", \"changes\", \"over\", \"time\", \",\", \"the\", \"same\", \"data\", \"patterns\", \"and\", \"statistical\", \"effects\", \"were\", \"reproducible\", \"for\", \"the\", \"two\", \"archival\", \"outcome\", \"variables\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-attribute\", \"O\", \"B-psychological_feature\", \"B-measure\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\"]}, {\"x\": [\"for\", \"substantiated\", \"cm\", \",\", \"the\", \"reproduced\", \"analyses\", \"reflected\", \"higher\", \"effect\", \"sizes\", \"and\", \"a\", \"clear\", \"pattern\", \"of\", \"reduction\", \"as\", \"a\", \"function\", \"of\", \"intervention\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-object\", \"B-psychological_feature\", \"O\", \"B-process\", \"O\", \"O\", \"B-attribute\", \"O\", \"B-psychological_feature\", \"O\"], [\"for\", \"substantiated\", \"cm\", \",\", \"the\", \"reproduced\", \"analyses\", \"reflected\", \"higher\", \"effect\", \"sizes\", \"and\", \"a\", \"clear\", \"pattern\", \"of\", \"reduction\", \"as\", \"a\", \"function\", \"of\", \"intervention\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"B-object\", \"B-psychological_feature\", \"O\", \"B-process\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"O\"]}, {\"x\": [\"for\", \"out\", \"of\", \"home\", \"placements\", \",\", \"effect\", \"sizes\", \"were\", \"quite\", \"comparable\", \"to\", \"the\", \"original\", \"ones\", \",\", \"reflecting\", \"preventive\", \"impact\", \".\"], \"y_predicted\": [[\"O\", \"B-psychological_feature\", \"O\", \"B-object\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\"], [\"for\", \"out\", \"of\", \"home\", \"placements\", \",\", \"effect\", \"sizes\", \"were\", \"quite\", \"comparable\", \"to\", \"the\", \"original\", \"ones\", \",\", \"reflecting\", \"preventive\", \"impact\", \".\"]], \"y_true\": [\"O\", \"B-psychological_feature\", \"O\", \"B-object\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-object\", \"B-psychological_feature\", \"O\"]}, {\"x\": [\"overall\", \",\", \"this\", \"case\", \"study\", \"illustrated\", \"the\", \"verifiability\", \"of\", \"data\", \"reproducibility\", \"in\", \"the\", \"context\", \"of\", \"a\", \"population\", \"outcome\", \"evaluation\", \",\", \"which\", \"underscores\", \"the\", \"importance\", \"of\", \"reliable\", \"population\", \"prevalence\", \"measurement\", \"as\", \"an\", \"essential\", \"part\", \"of\", \"a\", \"comprehensive\", \"public\", \"health\", \"strategy\", \"aimed\", \"at\", \"the\", \"prevention\", \"of\", \"cm\", \".\"], \"y_predicted\": [[\"B-object\", \"O\", \"O\", \"B-object\", \"B-psychological_feature\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"B-psychological_feature\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"B-psychological_feature\", \"B-attribute\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\"], [\"overall\", \",\", \"this\", \"case\", \"study\", \"illustrated\", \"the\", \"verifiability\", \"of\", \"data\", \"reproducibility\", \"in\", \"the\", \"context\", \"of\", \"a\", \"population\", \"outcome\", \"evaluation\", \",\", \"which\", \"underscores\", \"the\", \"importance\", \"of\", \"reliable\", \"population\", \"prevalence\", \"measurement\", \"as\", \"an\", \"essential\", \"part\", \"of\", \"a\", \"comprehensive\", \"public\", \"health\", \"strategy\", \"aimed\", \"at\", \"the\", \"prevention\", \"of\", \"cm\", \".\"]], \"y_true\": [\"B-object\", \"O\", \"O\", \"B-object\", \"I-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-psychological_feature\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"B-psychological_feature\", \"B-attribute\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\"]}, {\"x\": [\"c\", \"2016\", \"elsevier\", \"ltd\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\"], [\"c\", \"2016\", \"elsevier\", \"ltd\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"all\", \"rights\", \"reserved\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\"], [\"all\", \"rights\", \"reserved\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"aims\", \"ancient\", \"dna\", \"adna\", \"extracted\", \"from\", \"historical\", \"bones\", \"is\", \"damaged\", \"and\", \"fragmented\", \"into\", \"short\", \"segments\", \",\", \"present\", \"in\", \"low\", \"quantity\", \",\", \"and\", \"usually\", \"copurified\", \"with\", \"microbial\", \"dna\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-attribute\", \"O\", \"B-object\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"aims\", \"ancient\", \"dna\", \"adna\", \"extracted\", \"from\", \"historical\", \"bones\", \"is\", \"damaged\", \"and\", \"fragmented\", \"into\", \"short\", \"segments\", \",\", \"present\", \"in\", \"low\", \"quantity\", \",\", \"and\", \"usually\", \"copurified\", \"with\", \"microbial\", \"dna\", \".\"]], \"y_true\": [\"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-attribute\", \"O\", \"B-object\", \"B-measure\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"a\", \"wide\", \"range\", \"of\", \"dna\", \"quantification\", \"methods\", \"are\", \"available\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\"], [\"a\", \"wide\", \"range\", \"of\", \"dna\", \"quantification\", \"methods\", \"are\", \"available\", \".\"]], \"y_true\": [\"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"the\", \"aim\", \"of\", \"this\", \"study\", \"was\", \"to\", \"compare\", \"the\", \"five\", \"most\", \"common\", \"dna\", \"quantification\", \"methods\", \"for\", \"adna\", \".\"], \"y_predicted\": [[\"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-attribute\", \"O\", \"B-object\", \"O\", \"B-object\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"aim\", \"of\", \"this\", \"study\", \"was\", \"to\", \"compare\", \"the\", \"five\", \"most\", \"common\", \"dna\", \"quantification\", \"methods\", \"for\", \"adna\", \".\"]], \"y_true\": [\"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-attribute\", \"O\", \"B-object\", \"O\", \"B-object\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"materials\", \"and\", \"methods\", \"quantification\", \"methods\", \"were\", \"tested\", \"on\", \"dna\", \"extracted\", \"from\", \"skeletal\", \"material\", \"originating\", \"from\", \"an\", \"early\", \"medieval\", \"burial\", \"site\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\"], [\"materials\", \"and\", \"methods\", \"quantification\", \"methods\", \"were\", \"tested\", \"on\", \"dna\", \"extracted\", \"from\", \"skeletal\", \"material\", \"originating\", \"from\", \"an\", \"early\", \"medieval\", \"burial\", \"site\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"I-psychological_feature\", \"O\"]}, {\"x\": [\"the\", \"tested\", \"methods\", \"included\", \"ultraviolet\", \"uv\", \"absorbance\", \",\", \"real\", \"time\", \"quantitative\", \"polymerase\", \"chain\", \"reaction\", \"qpcr\", \"based\", \"on\", \"sybr\", \"r\", \"green\", \"detection\", \",\", \"real\", \"time\", \"qpcr\", \"based\", \"on\", \"a\", \"forensic\", \"kit\", \",\", \"quantification\", \"via\", \"fluorescent\", \"dyes\", \"bonded\", \"to\", \"dna\", \",\", \"and\", \"fragmentary\", \"analysis\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"B-object\", \"I-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"B-object\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\"], [\"the\", \"tested\", \"methods\", \"included\", \"ultraviolet\", \"uv\", \"absorbance\", \",\", \"real\", \"time\", \"quantitative\", \"polymerase\", \"chain\", \"reaction\", \"qpcr\", \"based\", \"on\", \"sybr\", \"r\", \"green\", \"detection\", \",\", \"real\", \"time\", \"qpcr\", \"based\", \"on\", \"a\", \"forensic\", \"kit\", \",\", \"quantification\", \"via\", \"fluorescent\", \"dyes\", \"bonded\", \"to\", \"dna\", \",\", \"and\", \"fragmentary\", \"analysis\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"B-object\", \"I-object\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"B-object\", \"B-object\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"B-psychological_feature\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\"]}, {\"x\": [\"differences\", \"between\", \"groups\", \"were\", \"tested\", \"using\", \"a\", \"paired\", \"t\", \"test\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\"], [\"differences\", \"between\", \"groups\", \"were\", \"tested\", \"using\", \"a\", \"paired\", \"t\", \"test\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-object\", \"O\"]}, {\"x\": [\"results\", \"methods\", \"that\", \"measure\", \"total\", \"dna\", \"present\", \"in\", \"the\", \"sample\", \"nanodrop\", \"tm\", \"uv\", \"spectrophotometer\", \"and\", \"qubit\", \"r\", \"fluorometer\", \"showed\", \"the\", \"highest\", \"concentrations\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-psychological_feature\", \"O\", \"B-attribute\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"results\", \"methods\", \"that\", \"measure\", \"total\", \"dna\", \"present\", \"in\", \"the\", \"sample\", \"nanodrop\", \"tm\", \"uv\", \"spectrophotometer\", \"and\", \"qubit\", \"r\", \"fluorometer\", \"showed\", \"the\", \"highest\", \"concentrations\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-psychological_feature\", \"O\", \"B-attribute\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"methods\", \"based\", \"on\", \"real\", \"time\", \"qpcr\", \"underestimated\", \"the\", \"quantity\", \"of\", \"adna\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\"], [\"methods\", \"based\", \"on\", \"real\", \"time\", \"qpcr\", \"underestimated\", \"the\", \"quantity\", \"of\", \"adna\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"B-measure\", \"O\", \"O\", \"O\"]}, {\"x\": [\"the\", \"most\", \"accurate\", \"method\", \"of\", \"adna\", \"quantification\", \"was\", \"fragmentary\", \"analysis\", \",\", \"which\", \"also\", \"allows\", \"dna\", \"quantification\", \"of\", \"the\", \"desired\", \"length\", \"and\", \"is\", \"not\", \"affected\", \"by\", \"pcr\", \"inhibitors\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"most\", \"accurate\", \"method\", \"of\", \"adna\", \"quantification\", \"was\", \"fragmentary\", \"analysis\", \",\", \"which\", \"also\", \"allows\", \"dna\", \"quantification\", \"of\", \"the\", \"desired\", \"length\", \"and\", \"is\", \"not\", \"affected\", \"by\", \"pcr\", \"inhibitors\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"conclusions\", \"methods\", \"based\", \"on\", \"the\", \"quantification\", \"of\", \"the\", \"total\", \"amount\", \"of\", \"dna\", \"in\", \"samples\", \"are\", \"unsuitable\", \"for\", \"ancient\", \"samples\", \"as\", \"they\", \"overestimate\", \"the\", \"amount\", \"of\", \"dna\", \"presumably\", \"due\", \"to\", \"the\", \"presence\", \"of\", \"microbial\", \"dna\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\"], [\"conclusions\", \"methods\", \"based\", \"on\", \"the\", \"quantification\", \"of\", \"the\", \"total\", \"amount\", \"of\", \"dna\", \"in\", \"samples\", \"are\", \"unsuitable\", \"for\", \"ancient\", \"samples\", \"as\", \"they\", \"overestimate\", \"the\", \"amount\", \"of\", \"dna\", \"presumably\", \"due\", \"to\", \"the\", \"presence\", \"of\", \"microbial\", \"dna\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"real\", \"time\", \"qpcr\", \"methods\", \"give\", \"undervalued\", \"results\", \"due\", \"to\", \"dna\", \"damage\", \"and\", \"the\", \"presence\", \"of\", \"pcr\", \"inhibitors\", \".\"], \"y_predicted\": [[\"B-O\", \"I-O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\"], [\"real\", \"time\", \"qpcr\", \"methods\", \"give\", \"undervalued\", \"results\", \"due\", \"to\", \"dna\", \"damage\", \"and\", \"the\", \"presence\", \"of\", \"pcr\", \"inhibitors\", \".\"]], \"y_true\": [\"B-O\", \"I-O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"dna\", \"quantification\", \"methods\", \"based\", \"on\", \"fragment\", \"analysis\", \"show\", \"not\", \"only\", \"the\", \"quantity\", \"of\", \"dna\", \"but\", \"also\", \"fragment\", \"length\", \".\"], \"y_predicted\": [[\"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-psychological_feature\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-attribute\", \"O\"], [\"dna\", \"quantification\", \"methods\", \"based\", \"on\", \"fragment\", \"analysis\", \"show\", \"not\", \"only\", \"the\", \"quantity\", \"of\", \"dna\", \"but\", \"also\", \"fragment\", \"length\", \".\"]], \"y_true\": [\"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-object\", \"B-psychological_feature\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"B-attribute\", \"O\"]}, {\"x\": [\"considerable\", \"evidence\", \"suggests\", \"that\", \"adolescent\", \"exposure\", \"to\", \"delta\", \"9\", \"tetrahydrocanabinol\", \"thc\", \",\", \"the\", \"psychoactive\", \"component\", \"in\", \"marijuana\", \",\", \"increases\", \"the\", \"risk\", \"of\", \"developing\", \"schizophrenia\", \"related\", \"symptoms\", \"in\", \"early\", \"adulthood\", \".\"], \"y_predicted\": [[\"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-measure\", \"O\"], [\"considerable\", \"evidence\", \"suggests\", \"that\", \"adolescent\", \"exposure\", \"to\", \"delta\", \"9\", \"tetrahydrocanabinol\", \"thc\", \",\", \"the\", \"psychoactive\", \"component\", \"in\", \"marijuana\", \",\", \"increases\", \"the\", \"risk\", \"of\", \"developing\", \"schizophrenia\", \"related\", \"symptoms\", \"in\", \"early\", \"adulthood\", \".\"]], \"y_true\": [\"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-object\", \"B-object\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-measure\", \"O\"]}, {\"x\": [\"in\", \"the\", \"present\", \"study\", \",\", \"we\", \"used\", \"a\", \"combination\", \"of\", \"behavioral\", \"and\", \"molecular\", \"analyses\", \"with\", \"in\", \"vivo\", \"neuronal\", \"electrophysiology\", \"to\", \"compare\", \"the\", \"long\", \"termeffects\", \"of\", \"adolescent\", \"versus\", \"adulthood\", \"thc\", \"exposure\", \"in\", \"rats\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"B-attribute\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\"], [\"in\", \"the\", \"present\", \"study\", \",\", \"we\", \"used\", \"a\", \"combination\", \"of\", \"behavioral\", \"and\", \"molecular\", \"analyses\", \"with\", \"in\", \"vivo\", \"neuronal\", \"electrophysiology\", \"to\", \"compare\", \"the\", \"long\", \"termeffects\", \"of\", \"adolescent\", \"versus\", \"adulthood\", \"thc\", \"exposure\", \"in\", \"rats\", \".\"]], \"y_true\": [\"O\", \"O\", \"B-attribute\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"B-measure\", \"O\", \"B-object\", \"O\", \"O\", \"O\"]}, {\"x\": [\"we\", \"report\", \"that\", \"adolescent\", \",\", \"but\", \"not\", \"adult\", \",\", \"thc\", \"exposure\", \"induces\", \"long\", \"term\", \"neuropsychiatric\", \"like\", \"phenotypes\", \"similar\", \"to\", \"those\", \"observed\", \"in\", \"clinical\", \"populations\", \".\"], \"y_predicted\": [[\"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"we\", \"report\", \"that\", \"adolescent\", \",\", \"but\", \"not\", \"adult\", \",\", \"thc\", \"exposure\", \"induces\", \"long\", \"term\", \"neuropsychiatric\", \"like\", \"phenotypes\", \"similar\", \"to\", \"those\", \"observed\", \"in\", \"clinical\", \"populations\", \".\"]], \"y_true\": [\"O\", \"B-psychological_feature\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-measure\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"thus\", \",\", \"adolescent\", \"thc\", \"exposure\", \"induced\", \"behavioral\", \"abnormalities\", \"resembling\", \"positive\", \"and\", \"negative\", \"schizophrenia\", \"related\", \"endophenotypes\", \"and\", \"a\", \"state\", \"of\", \"neuronal\", \"hyperactivity\", \"in\", \"the\", \"mesocorticolimbic\", \"dopamine\", \"da\", \"pathway\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\"], [\"thus\", \",\", \"adolescent\", \"thc\", \"exposure\", \"induced\", \"behavioral\", \"abnormalities\", \"resembling\", \"positive\", \"and\", \"negative\", \"schizophrenia\", \"related\", \"endophenotypes\", \"and\", \"a\", \"state\", \"of\", \"neuronal\", \"hyperactivity\", \"in\", \"the\", \"mesocorticolimbic\", \"dopamine\", \"da\", \"pathway\", \".\"]], \"y_true\": [\"O\", \"O\", \"B-object\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\"]}, {\"x\": [\"furthermore\", \",\", \"we\", \"observed\", \"profound\", \"alterations\", \"in\", \"several\", \"prefrontal\", \"cortical\", \"molecular\", \"pathways\", \"consistent\", \"with\", \"sub\", \"cortical\", \"daergic\", \"dysregulation\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\"], [\"furthermore\", \",\", \"we\", \"observed\", \"profound\", \"alterations\", \"in\", \"several\", \"prefrontal\", \"cortical\", \"molecular\", \"pathways\", \"consistent\", \"with\", \"sub\", \"cortical\", \"daergic\", \"dysregulation\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"our\", \"findings\", \"demonstrate\", \"a\", \"profound\", \"dissociation\", \"in\", \"relative\", \"risk\", \"profiles\", \"for\", \"adolescent\", \"versus\", \"adulthood\", \"exposure\", \"to\", \"thc\", \"in\", \"terms\", \"of\", \"neuronal\", \",\", \"behavioral\", \",\", \"and\", \"molecular\", \"markers\", \"resembling\", \"neuropsychiatric\", \"pathology\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"B-object\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\"], [\"our\", \"findings\", \"demonstrate\", \"a\", \"profound\", \"dissociation\", \"in\", \"relative\", \"risk\", \"profiles\", \"for\", \"adolescent\", \"versus\", \"adulthood\", \"exposure\", \"to\", \"thc\", \"in\", \"terms\", \"of\", \"neuronal\", \",\", \"behavioral\", \",\", \"and\", \"molecular\", \"markers\", \"resembling\", \"neuropsychiatric\", \"pathology\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"B-object\", \"B-psychological_feature\", \"O\", \"O\", \"B-object\", \"O\", \"B-measure\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\"]}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:54:10.795 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 4290 tokens with 971 phrases; found: 968 phrases; correct: 0.\n",
      "\n",
      "precision:  66.53%; recall:  66.32%; FB1:  66.43\n",
      "\n",
      "\tO: precision:  69.23%; recall:  52.94%; F1:  60.00 26\n",
      "\n",
      "\tattribute: precision:  46.94%; recall:  45.54%; F1:  46.23 98\n",
      "\n",
      "\tmeasure: precision:  71.88%; recall:  63.89%; F1:  67.65 32\n",
      "\n",
      "\tobject: precision:  69.35%; recall:  75.42%; F1:  72.26 323\n",
      "\n",
      "\tprocess: precision:  47.22%; recall:  36.17%; F1:  40.96 36\n",
      "\n",
      "\tpsychological_feature: precision:  69.76%; recall:  69.30%; F1:  69.53 453\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"test\": {\"eval_examples_count\": 222, \"metrics\": {\"ner_f1\": 66.426}, \"time_spent\": \"0:00:01\", \"examples\": [{\"x\": [\"ber\", \"ep4\", \"and\", \"cd44v6\", \"were\", \"shown\", \"to\", \"be\", \"great\", \"markers\", \"for\", \"detecting\", \"lnmm\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"ber\", \"ep4\", \"and\", \"cd44v6\", \"were\", \"shown\", \"to\", \"be\", \"great\", \"markers\", \"for\", \"detecting\", \"lnmm\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\"]}, {\"x\": [\"aims\", \"human\", \"papillomavirus\", \"hpv\", \"is\", \"known\", \"as\", \"causative\", \"for\", \"squamous\", \"cell\", \"carcinoma\", \"scc\", \"of\", \"the\", \"oropharynx\", \",\", \"but\", \"is\", \"also\", \"found\", \"not\", \"infrequently\", \"in\", \"carcinomas\", \"of\", \"the\", \"sinonasal\", \"tract\", \".\"], \"y_predicted\": [[\"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\"], [\"aims\", \"human\", \"papillomavirus\", \"hpv\", \"is\", \"known\", \"as\", \"causative\", \"for\", \"squamous\", \"cell\", \"carcinoma\", \"scc\", \"of\", \"the\", \"oropharynx\", \",\", \"but\", \"is\", \"also\", \"found\", \"not\", \"infrequently\", \"in\", \"carcinomas\", \"of\", \"the\", \"sinonasal\", \"tract\", \".\"]], \"y_true\": [\"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\"]}, {\"x\": [\"recently\", \",\", \"a\", \"subset\", \"of\", \"these\", \"carcinomas\", \"was\", \"recognized\", \"to\", \"harbour\", \"hpv33\", \"and\", \"have\", \"a\", \"significant\", \"morphological\", \"overlap\", \"with\", \"adenoid\", \"cystic\", \"carcinoma\", \"acc\", \",\", \"a\", \"rare\", \"and\", \"aggressive\", \"carcinoma\", \"originating\", \"in\", \"the\", \"minor\", \"salivary\", \"glands\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\"], [\"recently\", \",\", \"a\", \"subset\", \"of\", \"these\", \"carcinomas\", \"was\", \"recognized\", \"to\", \"harbour\", \"hpv33\", \"and\", \"have\", \"a\", \"significant\", \"morphological\", \"overlap\", \"with\", \"adenoid\", \"cystic\", \"carcinoma\", \"acc\", \",\", \"a\", \"rare\", \"and\", \"aggressive\", \"carcinoma\", \"originating\", \"in\", \"the\", \"minor\", \"salivary\", \"glands\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\"]}, {\"x\": [\"termed\", \"'hpv\", \"related\", \"carcinoma\", \"with\", \"acc\", \"like\", \"features'\", \",\", \"only\", \"nine\", \"cases\", \"have\", \"been\", \"reported\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\"], [\"termed\", \"'hpv\", \"related\", \"carcinoma\", \"with\", \"acc\", \"like\", \"features'\", \",\", \"only\", \"nine\", \"cases\", \"have\", \"been\", \"reported\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\"]}, {\"x\": [\"to\", \"clarify\", \"the\", \"occurrence\", \"of\", \"these\", \"tumours\", \"we\", \"screened\", \"a\", \"large\", \"material\", \"for\", \"the\", \"presence\", \"of\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"B-object\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\"], [\"to\", \"clarify\", \"the\", \"occurrence\", \"of\", \"these\", \"tumours\", \"we\", \"screened\", \"a\", \"large\", \"material\", \"for\", \"the\", \"presence\", \"of\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"B-object\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\"]}, {\"x\": [\"the\", \"identified\", \"tumours\", \"were\", \"characterized\", \"immunohistochemically\", \"and\", \"with\", \"fluorescence\", \"in\", \"situ\", \"hybridization\", \",\", \"and\", \"clinicopathological\", \"information\", \"for\", \"all\", \"cases\", \"is\", \"presented\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"identified\", \"tumours\", \"were\", \"characterized\", \"immunohistochemically\", \"and\", \"with\", \"fluorescence\", \"in\", \"situ\", \"hybridization\", \",\", \"and\", \"clinicopathological\", \"information\", \"for\", \"all\", \"cases\", \"is\", \"presented\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"methods\", \"and\", \"results\", \"forty\", \"seven\", \"candidate\", \"cases\", \"were\", \"screened\", \"for\", \"presence\", \"of\", \"hpv\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\"], [\"methods\", \"and\", \"results\", \"forty\", \"seven\", \"candidate\", \"cases\", \"were\", \"screened\", \"for\", \"presence\", \"of\", \"hpv\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\"]}, {\"x\": [\"six\", \"cases\", \"were\", \"identified\", \"and\", \"genotyped\", \"as\", \"hpv\", \"types\", \"33\", \",\", \"35\", \",\", \"and\", \"56\", \".\"], \"y_predicted\": [[\"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"six\", \"cases\", \"were\", \"identified\", \"and\", \"genotyped\", \"as\", \"hpv\", \"types\", \"33\", \",\", \"35\", \",\", \"and\", \"56\", \".\"]], \"y_true\": [\"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"all\", \"six\", \"cases\", \"had\", \"areas\", \"of\", \"dysplastic\", \"mucosal\", \"lining\", \"and\", \"showed\", \"remarkable\", \"heterogeneous\", \"morphologies\", \".\"], \"y_predicted\": [[\"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"all\", \"six\", \"cases\", \"had\", \"areas\", \"of\", \"dysplastic\", \"mucosal\", \"lining\", \"and\", \"showed\", \"remarkable\", \"heterogeneous\", \"morphologies\", \".\"]], \"y_true\": [\"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"myb\", \",\", \"mybl1\", \",\", \"and\", \"nfib\", \"genes\", \"were\", \"intact\", \"and\", \",\", \"interestingly\", \",\", \"staining\", \"for\", \"myb\", \"protein\", \"was\", \"largely\", \"negative\", \"in\", \"contrast\", \"to\", \"what\", \"was\", \"found\", \"in\", \"acc\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"myb\", \",\", \"mybl1\", \",\", \"and\", \"nfib\", \"genes\", \"were\", \"intact\", \"and\", \",\", \"interestingly\", \",\", \"staining\", \"for\", \"myb\", \"protein\", \"was\", \"largely\", \"negative\", \"in\", \"contrast\", \"to\", \"what\", \"was\", \"found\", \"in\", \"acc\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"one\", \"patient\", \"experienced\", \"a\", \"local\", \"recurrence\", \"11\", \"years\", \"after\", \"initial\", \"treatment\", \"and\", \"the\", \"remaining\", \"five\", \"patients\", \"were\", \"alive\", \"without\", \"evidence\", \"of\", \"disease\", \".\"], \"y_predicted\": [[\"B-psychological_feature\", \"B-object\", \"O\", \"O\", \"B-object\", \"B-psychological_feature\", \"O\", \"B-measure\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-object\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\"], [\"one\", \"patient\", \"experienced\", \"a\", \"local\", \"recurrence\", \"11\", \"years\", \"after\", \"initial\", \"treatment\", \"and\", \"the\", \"remaining\", \"five\", \"patients\", \"were\", \"alive\", \"without\", \"evidence\", \"of\", \"disease\", \".\"]], \"y_true\": [\"B-psychological_feature\", \"B-object\", \"O\", \"O\", \"B-object\", \"B-psychological_feature\", \"O\", \"B-measure\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\"]}, {\"x\": [\"conclusion\", \"we\", \"report\", \"six\", \"new\", \"cases\", \"of\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \"and\", \"found\", \"that\", \",\", \"although\", \"in\", \"a\", \"small\", \"material\", \",\", \"the\", \"prognosis\", \"for\", \"these\", \"patients\", \"seems\", \"more\", \"favourable\", \"than\", \"for\", \"acc\", \".\"], \"y_predicted\": [[\"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"B-object\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"conclusion\", \"we\", \"report\", \"six\", \"new\", \"cases\", \"of\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \"and\", \"found\", \"that\", \",\", \"although\", \"in\", \"a\", \"small\", \"material\", \",\", \"the\", \"prognosis\", \"for\", \"these\", \"patients\", \"seems\", \"more\", \"favourable\", \"than\", \"for\", \"acc\", \".\"]], \"y_true\": [\"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"B-object\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"for\", \"the\", \"distinction\", \"between\", \"acc\", \"and\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \",\", \"p16\", \",\", \"myb\", \"immunohistochemistry\", \"or\", \"investigation\", \"of\", \"myb\", \",\", \"mybl1\", \"and\", \"nfib\", \"gene\", \"status\", \"are\", \"valuable\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"for\", \"the\", \"distinction\", \"between\", \"acc\", \"and\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \",\", \"p16\", \",\", \"myb\", \"immunohistochemistry\", \"or\", \"investigation\", \"of\", \"myb\", \",\", \"mybl1\", \"and\", \"nfib\", \"gene\", \"status\", \"are\", \"valuable\", \".\"]], \"y_true\": [\"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"the\", \"aim\", \"of\", \"the\", \"present\", \"study\", \"was\", \"to\", \"investigate\", \"the\", \"role\", \"of\", \"chemokine\", \"c\", \"x\", \"c\", \"motif\", \"ligand\", \"12\", \"cxcl12\", \"and\", \"its\", \"receptor\", \",\", \"chemokine\", \"c\", \"x\", \"c\", \"motif\", \"receptor\", \"4\", \"cxcr4\", \"in\", \"the\", \"pathogenesis\", \"of\", \"adenomyosis\", \"ad\", \".\"], \"y_predicted\": [[\"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-attribute\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"aim\", \"of\", \"the\", \"present\", \"study\", \"was\", \"to\", \"investigate\", \"the\", \"role\", \"of\", \"chemokine\", \"c\", \"x\", \"c\", \"motif\", \"ligand\", \"12\", \"cxcl12\", \"and\", \"its\", \"receptor\", \",\", \"chemokine\", \"c\", \"x\", \"c\", \"motif\", \"receptor\", \"4\", \"cxcr4\", \"in\", \"the\", \"pathogenesis\", \"of\", \"adenomyosis\", \"ad\", \".\"]], \"y_true\": [\"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-attribute\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"immunohistochemistry\", \"and\", \"reverse\", \"transcription\", \"quantitative\", \"polymerase\", \"chain\", \"reaction\", \"analysis\", \"were\", \"used\", \"to\", \"measure\", \"the\", \"protein\", \"and\", \"mrna\", \"expression\", \"of\", \"cxcl12\", \"and\", \"cxcr4\", \"in\", \"eutopic\", \"endometrial\", \"and\", \"ectopic\", \"foci\", \"tissue\", \"samples\", \".\"], \"y_predicted\": [[\"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"B-object\", \"O\", \"O\", \"B-object\", \"I-object\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"immunohistochemistry\", \"and\", \"reverse\", \"transcription\", \"quantitative\", \"polymerase\", \"chain\", \"reaction\", \"analysis\", \"were\", \"used\", \"to\", \"measure\", \"the\", \"protein\", \"and\", \"mrna\", \"expression\", \"of\", \"cxcl12\", \"and\", \"cxcr4\", \"in\", \"eutopic\", \"endometrial\", \"and\", \"ectopic\", \"foci\", \"tissue\", \"samples\", \".\"]], \"y_true\": [\"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"B-psychological_feature\", \"O\", \"O\", \"B-object\", \"I-object\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"samples\", \"from\", \"a\", \"total\", \"of\", \"36\", \"patients\", \"with\", \"ad\", \"study\", \"group\", \"were\", \"compared\", \"with\", \"endometrial\", \"tissue\", \"samples\", \"from\", \"33\", \"patients\", \"who\", \"underwent\", \"uterine\", \"fibroids\", \"surgery\", \"control\", \"group\", \"during\", \"the\", \"same\", \"period\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-measure\", \"O\"], [\"samples\", \"from\", \"a\", \"total\", \"of\", \"36\", \"patients\", \"with\", \"ad\", \"study\", \"group\", \"were\", \"compared\", \"with\", \"endometrial\", \"tissue\", \"samples\", \"from\", \"33\", \"patients\", \"who\", \"underwent\", \"uterine\", \"fibroids\", \"surgery\", \"control\", \"group\", \"during\", \"the\", \"same\", \"period\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"B-measure\", \"O\"]}, {\"x\": [\"all\", \"data\", \"are\", \"presented\", \"as\", \"the\", \"mean\", \"standard\", \"deviation\", \"and\", \"were\", \"analyzed\", \"with\", \"spss\", \"software\", \"version\", \"16\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-object\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\"], [\"all\", \"data\", \"are\", \"presented\", \"as\", \"the\", \"mean\", \"standard\", \"deviation\", \"and\", \"were\", \"analyzed\", \"with\", \"spss\", \"software\", \"version\", \"16\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-attribute\", \"I-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\"]}, {\"x\": [\"0\", \".\"], \"y_predicted\": [[\"O\", \"O\"], [\"0\", \".\"]], \"y_true\": [\"O\", \"O\"]}, {\"x\": [\"analysis\", \"of\", \"variance\", \"was\", \"used\", \"for\", \"between\", \"group\", \"analysis\", \"and\", \"pairwise\", \"comparison\", \"was\", \"performed\", \"using\", \"fisher's\", \"least\", \"significant\", \"difference\", \"post\", \"hoc\", \"test\", \".\"], \"y_predicted\": [[\"B-psychological_feature\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"O\"], [\"analysis\", \"of\", \"variance\", \"was\", \"used\", \"for\", \"between\", \"group\", \"analysis\", \"and\", \"pairwise\", \"comparison\", \"was\", \"performed\", \"using\", \"fisher's\", \"least\", \"significant\", \"difference\", \"post\", \"hoc\", \"test\", \".\"]], \"y_true\": [\"B-psychological_feature\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"B-object\", \"I-psychological_feature\", \"B-psychological_feature\", \"O\"]}, {\"x\": [\"the\", \"results\", \"of\", \"the\", \"present\", \"study\", \"revealed\", \"that\", \"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"was\", \"significantly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"compared\", \"with\", \"eutopic\", \"endometrial\", \"tissue\", \"samples\", \"from\", \"patients\", \"with\", \"ad\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"results\", \"of\", \"the\", \"present\", \"study\", \"revealed\", \"that\", \"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"was\", \"significantly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"compared\", \"with\", \"eutopic\", \"endometrial\", \"tissue\", \"samples\", \"from\", \"patients\", \"with\", \"ad\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"in\", \"ectopic\", \"foci\", \"and\", \"eutopic\", \"endometrial\", \"tissue\", \"samples\", \"were\", \"significantly\", \"increased\", \"compared\", \"with\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\"], [\"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"in\", \"ectopic\", \"foci\", \"and\", \"eutopic\", \"endometrial\", \"tissue\", \"samples\", \"were\", \"significantly\", \"increased\", \"compared\", \"with\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"no\", \"significant\", \"differences\", \"were\", \"identified\", \"in\", \"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"between\", \"the\", \"proliferative\", \"and\", \"secretory\", \"phases\", \"within\", \"each\", \"group\", \".\"], \"y_predicted\": [[\"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"no\", \"significant\", \"differences\", \"were\", \"identified\", \"in\", \"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"between\", \"the\", \"proliferative\", \"and\", \"secretory\", \"phases\", \"within\", \"each\", \"group\", \".\"]], \"y_true\": [\"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"furthermore\", \",\", \"cxcl12\", \"and\", \"cxcr4\", \"mrna\", \"expression\", \"was\", \"significantly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"and\", \"eutopic\", \"endometrial\", \"tissue\", \"compared\", \"with\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\"], [\"furthermore\", \",\", \"cxcl12\", \"and\", \"cxcr4\", \"mrna\", \"expression\", \"was\", \"significantly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"and\", \"eutopic\", \"endometrial\", \"tissue\", \"compared\", \"with\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"cxcl12\", \"mrna\", \"expression\", \"was\", \"markedly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"compared\", \"with\", \"eutopic\", \"endometrial\", \"tissue\", \"of\", \"patients\", \"with\", \"ad\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"cxcl12\", \"mrna\", \"expression\", \"was\", \"markedly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"compared\", \"with\", \"eutopic\", \"endometrial\", \"tissue\", \"of\", \"patients\", \"with\", \"ad\", \".\"]], \"y_true\": [\"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"the\", \"expression\", \"of\", \"cxcr4\", \"mrna\", \"was\", \"significantly\", \"increased\", \"in\", \"eutopic\", \"endometrial\", \"tissue\", \"compared\", \"with\", \"ectopic\", \"foci\", \"tissue\", \"and\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"], \"y_predicted\": [[\"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"expression\", \"of\", \"cxcr4\", \"mrna\", \"was\", \"significantly\", \"increased\", \"in\", \"eutopic\", \"endometrial\", \"tissue\", \"compared\", \"with\", \"ectopic\", \"foci\", \"tissue\", \"and\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"]], \"y_true\": [\"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"no\", \"significant\", \"differences\", \"were\", \"identified\", \"in\", \"cxcl12\", \"and\", \"cxcr4\", \"mrna\", \"expression\", \"between\", \"proliferative\", \"and\", \"secretory\", \"phase\", \"within\", \"each\", \"group\", \".\"], \"y_predicted\": [[\"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"B-measure\", \"O\", \"O\", \"O\", \"O\"], [\"no\", \"significant\", \"differences\", \"were\", \"identified\", \"in\", \"cxcl12\", \"and\", \"cxcr4\", \"mrna\", \"expression\", \"between\", \"proliferative\", \"and\", \"secretory\", \"phase\", \"within\", \"each\", \"group\", \".\"]], \"y_true\": [\"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"in\", \"conclusion\", \",\", \"cxcl12\", \"and\", \"cxcr4\", \"may\", \"induce\", \"the\", \"ectopia\", \",\", \"and\", \"promote\", \"the\", \"spread\", \"and\", \"localized\", \"growth\", \"of\", \"endometrial\", \"cells\", \"in\", \"the\", \"development\", \"of\", \"ad\", \".\"], \"y_predicted\": [[\"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-psychological_feature\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\"], [\"in\", \"conclusion\", \",\", \"cxcl12\", \"and\", \"cxcr4\", \"may\", \"induce\", \"the\", \"ectopia\", \",\", \"and\", \"promote\", \"the\", \"spread\", \"and\", \"localized\", \"growth\", \"of\", \"endometrial\", \"cells\", \"in\", \"the\", \"development\", \"of\", \"ad\", \".\"]], \"y_true\": [\"O\", \"B-psychological_feature\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"O\", \"O\", \"B-attribute\", \"O\", \"O\", \"B-process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-object\", \"O\", \"O\", \"O\"]}]}}\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.commands.train import train_evaluate_model_from_config\n",
    "\n",
    "config[\"train\"][\"show_examples\"] = True\n",
    "model1 = train_evaluate_model_from_config(config, to_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pTx1Tn0iVkAm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrincb9YVk2r"
   },
   "source": [
    "**GLUBINA 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFwXV9SdVm_f"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset_reader\": {\n",
    "        \"class_name\": \"conll2003_reader\",\n",
    "        \"data_path\": \"./onthology_objects_data_new/dataset_3/\",\n",
    "        \"dataset_name\": \"conll2003\",\n",
    "        \"provide_pos\": False\n",
    "    },\n",
    "    \"dataset_iterator\": {\n",
    "        \"class_name\": \"data_learning_iterator\",\n",
    "        \"seed\": 42\n",
    "    },\n",
    "    \"chainer\": {\n",
    "    \"in\": [\"x\"],\n",
    "    \"in_y\": [\"y\"],\n",
    "    \"pipe\": [\n",
    "      {\n",
    "        \"in\": [\"x\"],\n",
    "        \"class_name\": \"lazy_tokenizer\",\n",
    "        \"out\": [\"x_tokens\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"class_name\": \"str_lower\",\n",
    "        \"out\": [\"x_lower\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_lower\"],\n",
    "        \"class_name\": \"sanitizer\",\n",
    "        \"nums\": True,\n",
    "        \"out\": [\"x_san\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_san\"],\n",
    "        \"id\": \"word_vocab\",\n",
    "        \"class_name\": \"simple_vocab\",\n",
    "        \"pad_with_zeros\": True,\n",
    "        \"special_tokens\": [\"<UNK>\"],\n",
    "        \"fit_on\": [\"x_san\"],\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/word_3_ft.dict\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/word_3_ft.dict\",\n",
    "        \"out\": [\"x_tok_ind\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"y\"],\n",
    "        \"id\": \"tag_vocab\",\n",
    "        \"class_name\": \"simple_vocab\",\n",
    "        \"pad_with_zeros\": True,\n",
    "        \"fit_on\": [\"y\"],\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/tag_3_ft.dict\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/tag_3_ft.dict\",\n",
    "        \"out\": [\"y_ind\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"class_name\": \"char_splitter\",\n",
    "        \"out\": [\"x_char\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_char\"],\n",
    "        \"id\": \"char_vocab\",\n",
    "        \"class_name\": \"simple_vocab\",\n",
    "        \"pad_with_zeros\": True,\n",
    "        \"fit_on\": [\"x_char\"],\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/char_3_ft.dict\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/char_3_ft.dict\",\n",
    "        \"out\": [\"x_char_ind\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"class_name\": \"mask\",\n",
    "        \"out\": [\"mask\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_san\"],\n",
    "        \"id\": \"glove_emb\",\n",
    "        \"class_name\": \"fasttext\",\n",
    "        \"pad_zero\": True,\n",
    "        \"dim\": 300,\n",
    "        \"load_path\": \"{DOWNLOADS_PATH}/embeddings/wiki.en.bin\",\n",
    "        \"out\": [\"x_emb\"]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"embeddings\",\n",
    "        \"class_name\": \"emb_mat_assembler\",\n",
    "        \"embedder\": \"#glove_emb\",\n",
    "        \"vocab\": \"#word_vocab\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"embeddings_char\",\n",
    "        \"class_name\": \"emb_mat_assembler\",\n",
    "        \"character_level\": True,\n",
    "        \"emb_dim\": 32,\n",
    "        \"embedder\": \"#glove_emb\",\n",
    "        \"vocab\": \"#char_vocab\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"capitalization\",\n",
    "        \"class_name\": \"capitalization_featurizer\",\n",
    "        \"in\": [\"x_tokens\"],\n",
    "        \"out\": [\"cap\"]\n",
    "      },\n",
    "      {\n",
    "        \"in\": [\"x_emb\", \"mask\", \"x_char_ind\", \"cap\"],\n",
    "        \"in_y\": [\"y_ind\"],\n",
    "        \"out\": [\"y_predicted\"],\n",
    "        \"class_name\": \"ner\",\n",
    "        \"main\": True,\n",
    "        \"token_emb_dim\": \"#glove_emb.dim\",\n",
    "        \"n_hidden_list\": [128],\n",
    "        \"net_type\": \"rnn\",\n",
    "        \"cell_type\": \"lstm\",\n",
    "        \"use_cudnn_rnn\": True,\n",
    "        \"n_tags\": \"#tag_vocab.len\",\n",
    "        \"capitalization_dim\": \"#capitalization.dim\",\n",
    "        \"char_emb_dim\": \"#embeddings_char.dim\",\n",
    "        \"save_path\": \"{MODELS_PATH}/onthology_objects/model_no_pos_3_ft\",\n",
    "        \"load_path\": \"{MODELS_PATH}/onthology_objects/model_no_pos_3_ft\",\n",
    "        \"char_emb_mat\": \"#embeddings_char.emb_mat\",\n",
    "        \"two_dense_on_top\": True,\n",
    "        \"use_crf\": True,\n",
    "        \"use_batch_norm\": True,\n",
    "        \"embeddings_dropout\": True,\n",
    "        \"top_dropout\": True,\n",
    "        \"intra_layer_dropout\": True,\n",
    "        \"l2_reg\": 0,\n",
    "        \"learning_rate\": 1e-2,\n",
    "        \"dropout_keep_prob\": 0.5\n",
    "      },\n",
    "      {\n",
    "        \"ref\": \"tag_vocab\",\n",
    "        \"in\": [\"y_predicted\"],\n",
    "        \"out\": [\"tags\"]\n",
    "      }\n",
    "    ],\n",
    "    \"out\": [\"x_tokens\", \"tags\"]\n",
    "  },\n",
    "    \"train\": {\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 64,\n",
    "        \"metrics\": [\n",
    "            {\n",
    "                \"name\": \"ner_f1\",\n",
    "                \"inputs\": [\n",
    "                    \"y\",\n",
    "                    \"tags\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"validation_patience\": 7,\n",
    "        \"val_every_n_epochs\": 1,\n",
    "        \"log_every_n_epochs\": -1,\n",
    "        \"show_examples\": False,\n",
    "        \"validate_best\": True,\n",
    "        \"test_best\": True\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"variables\": {\n",
    "            \"ROOT_PATH\": \"~/.deeppavlov\",\n",
    "            \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\n",
    "            \"MODELS_PATH\": \"{ROOT_PATH}/models\"\n",
    "        },\n",
    "        \"requirements\": [\n",
    "            \"{DEEPPAVLOV_PATH}/requirements/fasttext.txt\",\n",
    "            \"{DEEPPAVLOV_PATH}/requirements/tf.txt\"\n",
    "        ],\n",
    "        \"labels\": {\n",
    "            \"telegram_utils\": \"NERCoNLL2003Model\",\n",
    "            \"server_utils\": \"NER\"\n",
    "        },\n",
    "        \"download\": [\n",
    "            {\n",
    "                \"url\": \"http://files.deeppavlov.ai/deeppavlov_data/embeddings/wiki.en.bin\",\n",
    "                \"subdir\": \"{DOWNLOADS_PATH}/embeddings\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "35A5oNqSV2Zm"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"config.json\", \"w\") as fout:\n",
    "  json.dump(config, fout, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NvM8iQ7dV68m",
    "outputId": "59e2e139-7e3f-4957-bfe7-9027b5ede5cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:54:11.994 WARNING in 'deeppavlov.core.commands.train'['train'] at line 108: \"validate_best\" and \"test_best\" parameters are deprecated. Please, use \"evaluation_targets\" list instead\n",
      "2019-12-18 16:54:12.279 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/onthology_objects/word_3_ft.dict]\n",
      "2019-12-18 16:54:12.304 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/onthology_objects/tag_3_ft.dict]\n",
      "2019-12-18 16:54:12.427 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/onthology_objects/char_3_ft.dict]\n",
      "2019-12-18 16:54:12.429 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 67: [loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/wiki.en.bin`]\n",
      "2019-12-18 16:54:24.440 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:54:24.540 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 16:54:27.498 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 5023 phrases; correct: 0.\n",
      "\n",
      "precision:  0.90%; recall:  4.36%; FB1:  1.49\n",
      "\n",
      "\tO: precision:  0.00%; recall:  0.00%; F1:  0.00 53\n",
      "\n",
      "\tartifact: precision:  0.00%; recall:  0.00%; F1:  0.00 8\n",
      "\n",
      "\tcognition: precision:  3.51%; recall:  1.23%; F1:  1.82 57\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 13\n",
      "\n",
      "\tevent: precision:  5.10%; recall:  4.07%; F1:  4.52 196\n",
      "\n",
      "\tgeological_formation: precision:  0.00%; recall:  0.00%; F1:  0.00 16\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  4.23%; recall:  2.40%; F1:  3.06 71\n",
      "\n",
      "\tlocation: precision:  0.50%; recall:  11.43%; F1:  0.95 804\n",
      "\n",
      "\tmotivation: precision:  0.00%; recall:  0.00%; F1:  0.00 40\n",
      "\n",
      "\tnatural_object: precision:  0.00%; recall:  0.00%; F1:  0.00 68\n",
      "\n",
      "\tnatural_process: precision:  0.00%; recall:  0.00%; F1:  0.00 6\n",
      "\n",
      "\torganic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tproperty: precision:  1.74%; recall:  20.00%; F1:  3.20 979\n",
      "\n",
      "\tquality: precision:  25.00%; recall:  1.49%; F1:  2.82 4\n",
      "\n",
      "\ttime: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 6\n",
      "\n",
      "\ttime_period: precision:  0.82%; recall:  34.78%; F1:  1.61 972\n",
      "\n",
      "\ttime_unit: precision:  0.00%; recall:  0.00%; F1:  0.00 1614\n",
      "\n",
      "\tvalue: precision:  0.00%; recall:  0.00%; F1:  0.00 84\n",
      "\n",
      "\tvolume: precision:  0.00%; recall:  0.00%; F1:  0.00 32\n",
      "\n",
      "\n",
      "2019-12-18 16:54:27.499 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 1.4864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 1.4864}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:54:40.675 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 112 phrases; correct: 0.\n",
      "\n",
      "precision:  33.04%; recall:  3.59%; FB1:  6.47\n",
      "\n",
      "\tO: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tartifact: precision:  35.71%; recall:  3.05%; F1:  5.62 14\n",
      "\n",
      "\tcognition: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tevent: precision:  32.65%; recall:  13.01%; F1:  18.60 98\n",
      "\n",
      "\tgeological_formation: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tlocation: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tmotivation: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tnatural_object: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tnatural_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\torganic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tproperty: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tquality: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_period: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\n",
      "2019-12-18 16:54:40.677 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 6.4685\n",
      "2019-12-18 16:54:40.677 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:54:40.679 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 6.4685}, \"time_spent\": \"0:00:15\", \"epochs_done\": 1, \"batches_seen\": 28, \"train_examples_seen\": 1770, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:54:52.676 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 622 phrases; correct: 0.\n",
      "\n",
      "precision:  37.46%; recall:  22.58%; FB1:  28.17\n",
      "\n",
      "\tO: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tartifact: precision:  42.70%; recall:  23.17%; F1:  30.04 89\n",
      "\n",
      "\tcognition: precision:  33.93%; recall:  11.66%; F1:  17.35 56\n",
      "\n",
      "\tevent: precision:  35.64%; recall:  67.07%; F1:  46.54 463\n",
      "\n",
      "\tgeological_formation: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  78.57%; recall:  8.80%; F1:  15.83 14\n",
      "\n",
      "\tlocation: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tmotivation: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tnatural_object: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tnatural_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\torganic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tproperty: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tquality: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_period: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\n",
      "2019-12-18 16:54:52.677 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 28.1741\n",
      "2019-12-18 16:54:52.678 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:54:52.679 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 28.1741}, \"time_spent\": \"0:00:27\", \"epochs_done\": 2, \"batches_seen\": 56, \"train_examples_seen\": 3540, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:55:04.813 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 652 phrases; correct: 0.\n",
      "\n",
      "precision:  46.93%; recall:  29.65%; FB1:  36.34\n",
      "\n",
      "\tO: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tartifact: precision:  61.73%; recall:  30.49%; F1:  40.82 81\n",
      "\n",
      "\tcognition: precision:  46.94%; recall:  14.11%; F1:  21.70 49\n",
      "\n",
      "\tevent: precision:  43.50%; recall:  58.54%; F1:  49.91 331\n",
      "\n",
      "\tgeological_formation: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  90.00%; recall:  36.00%; F1:  51.43 50\n",
      "\n",
      "\tlocation: precision:  26.92%; recall:  20.00%; F1:  22.95 26\n",
      "\n",
      "\tmotivation: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tnatural_object: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tnatural_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\torganic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tproperty: precision:  40.68%; recall:  28.24%; F1:  33.33 59\n",
      "\n",
      "\tquality: precision:  25.00%; recall:  8.96%; F1:  13.19 24\n",
      "\n",
      "\ttime: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_period: precision:  21.88%; recall:  30.43%; F1:  25.45 32\n",
      "\n",
      "\n",
      "2019-12-18 16:55:04.814 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 36.342\n",
      "2019-12-18 16:55:04.815 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:55:04.816 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 36.342}, \"time_spent\": \"0:00:39\", \"epochs_done\": 3, \"batches_seen\": 84, \"train_examples_seen\": 5310, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:55:16.880 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 745 phrases; correct: 0.\n",
      "\n",
      "precision:  55.03%; recall:  39.73%; FB1:  46.15\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tartifact: precision:  60.83%; recall:  44.51%; F1:  51.41 120\n",
      "\n",
      "\tcognition: precision:  48.95%; recall:  42.94%; F1:  45.75 143\n",
      "\n",
      "\tevent: precision:  54.62%; recall:  55.28%; F1:  54.95 249\n",
      "\n",
      "\tgeological_formation: precision:  14.29%; recall:  5.26%; F1:  7.69 7\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  85.25%; recall:  41.60%; F1:  55.91 61\n",
      "\n",
      "\tlocation: precision:  50.00%; recall:  40.00%; F1:  44.44 28\n",
      "\n",
      "\tmotivation: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tnatural_object: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tnatural_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\torganic_process: precision:  16.67%; recall:  2.44%; F1:  4.26 6\n",
      "\n",
      "\tproperty: precision:  50.00%; recall:  22.35%; F1:  30.89 38\n",
      "\n",
      "\tquality: precision:  32.76%; recall:  28.36%; F1:  30.40 58\n",
      "\n",
      "\ttime: precision:  100.00%; recall:  37.50%; F1:  54.55 3\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_period: precision:  37.50%; recall:  26.09%; F1:  30.77 16\n",
      "\n",
      "\n",
      "2019-12-18 16:55:16.881 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 46.1452\n",
      "2019-12-18 16:55:16.882 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:55:16.883 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 46.1452}, \"time_spent\": \"0:00:51\", \"epochs_done\": 4, \"batches_seen\": 112, \"train_examples_seen\": 7080, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:55:28.661 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 908 phrases; correct: 0.\n",
      "\n",
      "precision:  54.07%; recall:  47.58%; FB1:  50.62\n",
      "\n",
      "\tO: precision:  94.12%; recall:  80.00%; F1:  86.49 17\n",
      "\n",
      "\tartifact: precision:  64.62%; recall:  51.22%; F1:  57.14 130\n",
      "\n",
      "\tcognition: precision:  58.26%; recall:  41.10%; F1:  48.20 115\n",
      "\n",
      "\tevent: precision:  52.27%; recall:  65.45%; F1:  58.12 308\n",
      "\n",
      "\tgeological_formation: precision:  22.22%; recall:  10.53%; F1:  14.29 9\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  58.33%; recall:  50.40%; F1:  54.08 108\n",
      "\n",
      "\tlocation: precision:  42.50%; recall:  48.57%; F1:  45.33 40\n",
      "\n",
      "\tmotivation: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tnatural_object: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tnatural_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\torganic_process: precision:  35.71%; recall:  24.39%; F1:  28.99 28\n",
      "\n",
      "\tproperty: precision:  40.00%; recall:  37.65%; F1:  38.79 80\n",
      "\n",
      "\tquality: precision:  46.81%; recall:  32.84%; F1:  38.60 47\n",
      "\n",
      "\ttime: precision:  100.00%; recall:  75.00%; F1:  85.71 6\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_period: precision:  55.00%; recall:  47.83%; F1:  51.16 20\n",
      "\n",
      "\n",
      "2019-12-18 16:55:28.662 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 50.6186\n",
      "2019-12-18 16:55:28.663 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:55:28.664 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 50.6186}, \"time_spent\": \"0:01:03\", \"epochs_done\": 5, \"batches_seen\": 140, \"train_examples_seen\": 8850, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:55:40.418 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 927 phrases; correct: 0.\n",
      "\n",
      "precision:  55.02%; recall:  49.42%; FB1:  52.07\n",
      "\n",
      "\tO: precision:  61.54%; recall:  80.00%; F1:  69.57 26\n",
      "\n",
      "\tartifact: precision:  61.54%; recall:  48.78%; F1:  54.42 130\n",
      "\n",
      "\tcognition: precision:  53.85%; recall:  47.24%; F1:  50.33 143\n",
      "\n",
      "\tevent: precision:  53.42%; recall:  69.92%; F1:  60.56 322\n",
      "\n",
      "\tgeological_formation: precision:  22.22%; recall:  10.53%; F1:  14.29 9\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  68.04%; recall:  52.80%; F1:  59.46 97\n",
      "\n",
      "\tlocation: precision:  43.33%; recall:  37.14%; F1:  40.00 30\n",
      "\n",
      "\tmotivation: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tnatural_object: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tnatural_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\torganic_process: precision:  33.33%; recall:  17.07%; F1:  22.58 21\n",
      "\n",
      "\tproperty: precision:  46.05%; recall:  41.18%; F1:  43.48 76\n",
      "\n",
      "\tquality: precision:  52.08%; recall:  37.31%; F1:  43.48 48\n",
      "\n",
      "\ttime: precision:  100.00%; recall:  75.00%; F1:  85.71 6\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_period: precision:  61.11%; recall:  47.83%; F1:  53.66 18\n",
      "\n",
      "\n",
      "2019-12-18 16:55:40.419 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 52.0674\n",
      "2019-12-18 16:55:40.420 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:55:40.422 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 52.0674}, \"time_spent\": \"0:01:15\", \"epochs_done\": 6, \"batches_seen\": 168, \"train_examples_seen\": 10620, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:55:52.674 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 946 phrases; correct: 0.\n",
      "\n",
      "precision:  56.24%; recall:  51.55%; FB1:  53.79\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tartifact: precision:  57.65%; recall:  59.76%; F1:  58.68 170\n",
      "\n",
      "\tcognition: precision:  65.91%; recall:  35.58%; F1:  46.22 88\n",
      "\n",
      "\tevent: precision:  52.96%; recall:  69.11%; F1:  59.96 321\n",
      "\n",
      "\tgeological_formation: precision:  61.54%; recall:  42.11%; F1:  50.00 13\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  72.22%; recall:  62.40%; F1:  66.95 108\n",
      "\n",
      "\tlocation: precision:  66.67%; recall:  22.86%; F1:  34.04 12\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  66.67%; F1:  80.00 2\n",
      "\n",
      "\tnatural_object: precision:  16.67%; recall:  5.56%; F1:  8.33 6\n",
      "\n",
      "\tnatural_process: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\torganic_process: precision:  22.41%; recall:  31.71%; F1:  26.26 58\n",
      "\n",
      "\tproperty: precision:  49.25%; recall:  38.82%; F1:  43.42 67\n",
      "\n",
      "\tquality: precision:  50.00%; recall:  41.79%; F1:  45.53 56\n",
      "\n",
      "\ttime: precision:  85.71%; recall:  75.00%; F1:  80.00 7\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\ttime_period: precision:  65.00%; recall:  56.52%; F1:  60.47 20\n",
      "\n",
      "\n",
      "2019-12-18 16:55:52.675 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 53.7917\n",
      "2019-12-18 16:55:52.676 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:55:52.677 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 53.7917}, \"time_spent\": \"0:01:27\", \"epochs_done\": 7, \"batches_seen\": 196, \"train_examples_seen\": 12390, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:56:04.722 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 874 phrases; correct: 0.\n",
      "\n",
      "precision:  56.75%; recall:  48.06%; FB1:  52.05\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tartifact: precision:  69.30%; recall:  48.17%; F1:  56.83 114\n",
      "\n",
      "\tcognition: precision:  51.28%; recall:  49.08%; F1:  50.16 156\n",
      "\n",
      "\tevent: precision:  58.95%; recall:  54.88%; F1:  56.84 229\n",
      "\n",
      "\tgeological_formation: precision:  50.00%; recall:  36.84%; F1:  42.42 14\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  82.28%; recall:  52.00%; F1:  63.73 79\n",
      "\n",
      "\tlocation: precision:  42.42%; recall:  40.00%; F1:  41.18 33\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  25.00%; recall:  11.11%; F1:  15.38 8\n",
      "\n",
      "\tnatural_process: precision:  20.00%; recall:  8.33%; F1:  11.76 5\n",
      "\n",
      "\torganic_process: precision:  25.81%; recall:  39.02%; F1:  31.07 62\n",
      "\n",
      "\tproperty: precision:  50.00%; recall:  34.12%; F1:  40.56 58\n",
      "\n",
      "\tquality: precision:  43.42%; recall:  49.25%; F1:  46.15 76\n",
      "\n",
      "\ttime: precision:  77.78%; recall:  87.50%; F1:  82.35 9\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\ttime_period: precision:  81.82%; recall:  39.13%; F1:  52.94 11\n",
      "\n",
      "\n",
      "2019-12-18 16:56:04.724 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 53.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 52.0462}, \"time_spent\": \"0:01:39\", \"epochs_done\": 8, \"batches_seen\": 224, \"train_examples_seen\": 14160, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:56:16.190 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 834 phrases; correct: 0.\n",
      "\n",
      "precision:  58.63%; recall:  47.38%; FB1:  52.41\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tartifact: precision:  63.49%; recall:  48.78%; F1:  55.17 126\n",
      "\n",
      "\tcognition: precision:  60.91%; recall:  41.10%; F1:  49.08 110\n",
      "\n",
      "\tevent: precision:  55.94%; recall:  59.35%; F1:  57.59 261\n",
      "\n",
      "\tgeological_formation: precision:  63.16%; recall:  63.16%; F1:  63.16 19\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  77.65%; recall:  52.80%; F1:  62.86 85\n",
      "\n",
      "\tlocation: precision:  51.35%; recall:  54.29%; F1:  52.78 37\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  25.00%; recall:  11.11%; F1:  15.38 8\n",
      "\n",
      "\tnatural_process: precision:  25.00%; recall:  8.33%; F1:  12.50 4\n",
      "\n",
      "\torganic_process: precision:  18.42%; recall:  17.07%; F1:  17.72 38\n",
      "\n",
      "\tproperty: precision:  50.77%; recall:  38.82%; F1:  44.00 65\n",
      "\n",
      "\tquality: precision:  51.35%; recall:  28.36%; F1:  36.54 37\n",
      "\n",
      "\ttime: precision:  85.71%; recall:  75.00%; F1:  80.00 7\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_period: precision:  66.67%; recall:  52.17%; F1:  58.54 18\n",
      "\n",
      "\n",
      "2019-12-18 16:56:16.191 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 53.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 52.4116}, \"time_spent\": \"0:01:50\", \"epochs_done\": 9, \"batches_seen\": 252, \"train_examples_seen\": 15930, \"impatience\": 2, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:56:27.479 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 943 phrases; correct: 0.\n",
      "\n",
      "precision:  56.20%; recall:  51.36%; FB1:  53.67\n",
      "\n",
      "\tO: precision:  80.00%; recall:  80.00%; F1:  80.00 20\n",
      "\n",
      "\tartifact: precision:  60.29%; recall:  50.00%; F1:  54.67 136\n",
      "\n",
      "\tcognition: precision:  56.39%; recall:  46.01%; F1:  50.68 133\n",
      "\n",
      "\tevent: precision:  53.79%; recall:  63.41%; F1:  58.21 290\n",
      "\n",
      "\tgeological_formation: precision:  63.16%; recall:  63.16%; F1:  63.16 19\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  78.65%; recall:  56.00%; F1:  65.42 89\n",
      "\n",
      "\tlocation: precision:  45.24%; recall:  54.29%; F1:  49.35 42\n",
      "\n",
      "\tmotivation: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
      "\n",
      "\tnatural_object: precision:  42.86%; recall:  33.33%; F1:  37.50 14\n",
      "\n",
      "\tnatural_process: precision:  20.00%; recall:  8.33%; F1:  11.76 5\n",
      "\n",
      "\torganic_process: precision:  29.63%; recall:  19.51%; F1:  23.53 27\n",
      "\n",
      "\tproperty: precision:  59.57%; recall:  32.94%; F1:  42.42 47\n",
      "\n",
      "\tquality: precision:  40.00%; recall:  53.73%; F1:  45.86 90\n",
      "\n",
      "\ttime: precision:  60.00%; recall:  75.00%; F1:  66.67 10\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_period: precision:  70.59%; recall:  52.17%; F1:  60.00 17\n",
      "\n",
      "\n",
      "2019-12-18 16:56:27.480 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 53.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 53.6709}, \"time_spent\": \"0:02:02\", \"epochs_done\": 10, \"batches_seen\": 280, \"train_examples_seen\": 17700, \"impatience\": 3, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:56:39.57 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 971 phrases; correct: 0.\n",
      "\n",
      "precision:  55.51%; recall:  52.23%; FB1:  53.82\n",
      "\n",
      "\tO: precision:  72.73%; recall:  80.00%; F1:  76.19 22\n",
      "\n",
      "\tartifact: precision:  72.22%; recall:  47.56%; F1:  57.35 108\n",
      "\n",
      "\tcognition: precision:  63.30%; recall:  42.33%; F1:  50.74 109\n",
      "\n",
      "\tevent: precision:  51.78%; recall:  65.04%; F1:  57.66 309\n",
      "\n",
      "\tgeological_formation: precision:  70.00%; recall:  73.68%; F1:  71.79 20\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  67.27%; recall:  59.20%; F1:  62.98 110\n",
      "\n",
      "\tlocation: precision:  43.24%; recall:  45.71%; F1:  44.44 37\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  40.00%; recall:  22.22%; F1:  28.57 10\n",
      "\n",
      "\tnatural_process: precision:  33.33%; recall:  8.33%; F1:  13.33 3\n",
      "\n",
      "\torganic_process: precision:  29.09%; recall:  39.02%; F1:  33.33 55\n",
      "\n",
      "\tproperty: precision:  42.86%; recall:  42.35%; F1:  42.60 84\n",
      "\n",
      "\tquality: precision:  45.95%; recall:  50.75%; F1:  48.23 74\n",
      "\n",
      "\ttime: precision:  77.78%; recall:  87.50%; F1:  82.35 9\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_period: precision:  61.11%; recall:  47.83%; F1:  53.66 18\n",
      "\n",
      "\n",
      "2019-12-18 16:56:39.58 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 53.8193\n",
      "2019-12-18 16:56:39.59 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:56:39.59 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 53.8193}, \"time_spent\": \"0:02:13\", \"epochs_done\": 11, \"batches_seen\": 308, \"train_examples_seen\": 19470, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:56:50.764 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 1026 phrases; correct: 0.\n",
      "\n",
      "precision:  54.97%; recall:  54.65%; FB1:  54.81\n",
      "\n",
      "\tO: precision:  56.25%; recall:  90.00%; F1:  69.23 32\n",
      "\n",
      "\tartifact: precision:  75.44%; recall:  52.44%; F1:  61.87 114\n",
      "\n",
      "\tcognition: precision:  62.28%; recall:  43.56%; F1:  51.26 114\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  48.13%; recall:  73.17%; F1:  58.06 374\n",
      "\n",
      "\tgeological_formation: precision:  65.00%; recall:  68.42%; F1:  66.67 20\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  66.37%; recall:  60.00%; F1:  63.03 113\n",
      "\n",
      "\tlocation: precision:  44.12%; recall:  42.86%; F1:  43.48 34\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  50.00%; recall:  50.00%; F1:  50.00 18\n",
      "\n",
      "\tnatural_process: precision:  20.00%; recall:  8.33%; F1:  11.76 5\n",
      "\n",
      "\torganic_process: precision:  40.00%; recall:  14.63%; F1:  21.43 15\n",
      "\n",
      "\tproperty: precision:  50.00%; recall:  41.18%; F1:  45.16 70\n",
      "\n",
      "\tquality: precision:  40.96%; recall:  50.75%; F1:  45.33 83\n",
      "\n",
      "\ttime: precision:  63.64%; recall:  87.50%; F1:  73.68 11\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_period: precision:  61.11%; recall:  47.83%; F1:  53.66 18\n",
      "\n",
      "\n",
      "2019-12-18 16:56:50.766 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 54.8105\n",
      "2019-12-18 16:56:50.767 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:56:50.768 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 54.8105}, \"time_spent\": \"0:02:25\", \"epochs_done\": 12, \"batches_seen\": 336, \"train_examples_seen\": 21240, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:57:02.638 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 902 phrases; correct: 0.\n",
      "\n",
      "precision:  58.54%; recall:  51.16%; FB1:  54.60\n",
      "\n",
      "\tO: precision:  100.00%; recall:  80.00%; F1:  88.89 16\n",
      "\n",
      "\tartifact: precision:  66.67%; recall:  47.56%; F1:  55.52 117\n",
      "\n",
      "\tcognition: precision:  57.24%; recall:  50.92%; F1:  53.90 145\n",
      "\n",
      "\tevent: precision:  56.64%; recall:  58.94%; F1:  57.77 256\n",
      "\n",
      "\tgeological_formation: precision:  68.75%; recall:  57.89%; F1:  62.86 16\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  78.02%; recall:  56.80%; F1:  65.74 91\n",
      "\n",
      "\tlocation: precision:  45.00%; recall:  51.43%; F1:  48.00 40\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  33.33%; recall:  22.22%; F1:  26.67 12\n",
      "\n",
      "\tnatural_process: precision:  50.00%; recall:  16.67%; F1:  25.00 4\n",
      "\n",
      "\torganic_process: precision:  23.21%; recall:  31.71%; F1:  26.80 56\n",
      "\n",
      "\tproperty: precision:  57.69%; recall:  35.29%; F1:  43.80 52\n",
      "\n",
      "\tquality: precision:  54.10%; recall:  49.25%; F1:  51.56 61\n",
      "\n",
      "\ttime: precision:  85.71%; recall:  75.00%; F1:  80.00 7\n",
      "\n",
      "\ttime_interval: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\ttime_period: precision:  57.69%; recall:  65.22%; F1:  61.22 26\n",
      "\n",
      "\n",
      "2019-12-18 16:57:02.639 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 54.8105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 54.6019}, \"time_spent\": \"0:02:37\", \"epochs_done\": 13, \"batches_seen\": 364, \"train_examples_seen\": 23010, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:57:14.154 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 927 phrases; correct: 0.\n",
      "\n",
      "precision:  59.33%; recall:  53.29%; FB1:  56.15\n",
      "\n",
      "\tO: precision:  88.89%; recall:  80.00%; F1:  84.21 18\n",
      "\n",
      "\tartifact: precision:  65.08%; recall:  50.00%; F1:  56.55 126\n",
      "\n",
      "\tcognition: precision:  73.91%; recall:  41.72%; F1:  53.33 92\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  61.41%; recall:  60.16%; F1:  60.78 241\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  73.58%; recall:  62.40%; F1:  67.53 106\n",
      "\n",
      "\tlocation: precision:  47.37%; recall:  51.43%; F1:  49.32 38\n",
      "\n",
      "\tmotivation: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
      "\n",
      "\tnatural_object: precision:  37.04%; recall:  55.56%; F1:  44.44 27\n",
      "\n",
      "\tnatural_process: precision:  50.00%; recall:  33.33%; F1:  40.00 8\n",
      "\n",
      "\torganic_process: precision:  27.54%; recall:  46.34%; F1:  34.55 69\n",
      "\n",
      "\tproperty: precision:  45.74%; recall:  50.59%; F1:  48.04 94\n",
      "\n",
      "\tquality: precision:  49.21%; recall:  46.27%; F1:  47.69 63\n",
      "\n",
      "\ttime: precision:  100.00%; recall:  62.50%; F1:  76.92 5\n",
      "\n",
      "\ttime_interval: precision:  33.33%; recall:  100.00%; F1:  50.00 3\n",
      "\n",
      "\ttime_period: precision:  84.62%; recall:  47.83%; F1:  61.11 13\n",
      "\n",
      "\n",
      "2019-12-18 16:57:14.155 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 56.1511\n",
      "2019-12-18 16:57:14.156 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:57:14.157 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 56.1511}, \"time_spent\": \"0:02:48\", \"epochs_done\": 14, \"batches_seen\": 392, \"train_examples_seen\": 24780, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:57:25.792 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 982 phrases; correct: 0.\n",
      "\n",
      "precision:  57.84%; recall:  55.04%; FB1:  56.41\n",
      "\n",
      "\tO: precision:  88.89%; recall:  80.00%; F1:  84.21 18\n",
      "\n",
      "\tartifact: precision:  64.29%; recall:  49.39%; F1:  55.86 126\n",
      "\n",
      "\tcognition: precision:  61.70%; recall:  53.37%; F1:  57.24 141\n",
      "\n",
      "\tevent: precision:  52.96%; recall:  72.76%; F1:  61.30 338\n",
      "\n",
      "\tgeological_formation: precision:  62.50%; recall:  52.63%; F1:  57.14 16\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  84.27%; recall:  60.00%; F1:  70.09 89\n",
      "\n",
      "\tlocation: precision:  40.43%; recall:  54.29%; F1:  46.34 47\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  50.00%; recall:  33.33%; F1:  40.00 12\n",
      "\n",
      "\tnatural_process: precision:  25.00%; recall:  8.33%; F1:  12.50 4\n",
      "\n",
      "\torganic_process: precision:  30.00%; recall:  7.32%; F1:  11.76 10\n",
      "\n",
      "\tproperty: precision:  48.53%; recall:  38.82%; F1:  43.14 68\n",
      "\n",
      "\tquality: precision:  43.75%; recall:  52.24%; F1:  47.62 80\n",
      "\n",
      "\ttime: precision:  85.71%; recall:  75.00%; F1:  80.00 7\n",
      "\n",
      "\ttime_interval: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
      "\n",
      "\ttime_period: precision:  59.09%; recall:  56.52%; F1:  57.78 22\n",
      "\n",
      "\n",
      "2019-12-18 16:57:25.793 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 56.4052\n",
      "2019-12-18 16:57:25.794 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:57:25.795 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 56.4052}, \"time_spent\": \"0:03:00\", \"epochs_done\": 15, \"batches_seen\": 420, \"train_examples_seen\": 26550, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:57:37.782 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 968 phrases; correct: 0.\n",
      "\n",
      "precision:  58.88%; recall:  55.23%; FB1:  57.00\n",
      "\n",
      "\tO: precision:  75.00%; recall:  90.00%; F1:  81.82 24\n",
      "\n",
      "\tartifact: precision:  66.67%; recall:  52.44%; F1:  58.70 129\n",
      "\n",
      "\tcognition: precision:  64.44%; recall:  53.37%; F1:  58.39 135\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  56.43%; recall:  55.28%; F1:  55.85 241\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  80.00%; recall:  60.80%; F1:  69.09 95\n",
      "\n",
      "\tlocation: precision:  41.46%; recall:  48.57%; F1:  44.74 41\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  58.82%; recall:  55.56%; F1:  57.14 17\n",
      "\n",
      "\tnatural_process: precision:  37.50%; recall:  25.00%; F1:  30.00 8\n",
      "\n",
      "\torganic_process: precision:  26.56%; recall:  41.46%; F1:  32.38 64\n",
      "\n",
      "\tproperty: precision:  64.62%; recall:  49.41%; F1:  56.00 65\n",
      "\n",
      "\tquality: precision:  42.86%; recall:  58.21%; F1:  49.37 91\n",
      "\n",
      "\ttime: precision:  87.50%; recall:  87.50%; F1:  87.50 8\n",
      "\n",
      "\ttime_interval: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
      "\n",
      "\ttime_period: precision:  57.69%; recall:  65.22%; F1:  61.22 26\n",
      "\n",
      "\n",
      "2019-12-18 16:57:37.783 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 57.0\n",
      "2019-12-18 16:57:37.784 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:57:37.785 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 57.0}, \"time_spent\": \"0:03:12\", \"epochs_done\": 16, \"batches_seen\": 448, \"train_examples_seen\": 28320, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:57:49.862 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 967 phrases; correct: 0.\n",
      "\n",
      "precision:  58.12%; recall:  54.46%; FB1:  56.23\n",
      "\n",
      "\tO: precision:  60.00%; recall:  90.00%; F1:  72.00 30\n",
      "\n",
      "\tartifact: precision:  68.50%; recall:  53.05%; F1:  59.79 127\n",
      "\n",
      "\tcognition: precision:  57.31%; recall:  60.12%; F1:  58.68 171\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  60.85%; recall:  52.44%; F1:  56.33 212\n",
      "\n",
      "\tgeological_formation: precision:  77.78%; recall:  73.68%; F1:  75.68 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  74.76%; recall:  61.60%; F1:  67.54 103\n",
      "\n",
      "\tlocation: precision:  48.57%; recall:  48.57%; F1:  48.57 35\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  45.00%; recall:  50.00%; F1:  47.37 20\n",
      "\n",
      "\tnatural_process: precision:  40.00%; recall:  16.67%; F1:  23.53 5\n",
      "\n",
      "\torganic_process: precision:  29.03%; recall:  43.90%; F1:  34.95 62\n",
      "\n",
      "\tproperty: precision:  54.55%; recall:  42.35%; F1:  47.68 66\n",
      "\n",
      "\tquality: precision:  39.77%; recall:  52.24%; F1:  45.16 88\n",
      "\n",
      "\ttime: precision:  77.78%; recall:  87.50%; F1:  82.35 9\n",
      "\n",
      "\ttime_interval: precision:  50.00%; recall:  100.00%; F1:  66.67 2\n",
      "\n",
      "\ttime_period: precision:  78.57%; recall:  47.83%; F1:  59.46 14\n",
      "\n",
      "\n",
      "2019-12-18 16:57:49.863 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 57.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 56.2281}, \"time_spent\": \"0:03:24\", \"epochs_done\": 17, \"batches_seen\": 476, \"train_examples_seen\": 30090, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:58:01.375 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 979 phrases; correct: 0.\n",
      "\n",
      "precision:  58.84%; recall:  55.81%; FB1:  57.28\n",
      "\n",
      "\tO: precision:  69.23%; recall:  90.00%; F1:  78.26 26\n",
      "\n",
      "\tartifact: precision:  65.60%; recall:  50.00%; F1:  56.75 125\n",
      "\n",
      "\tcognition: precision:  59.18%; recall:  53.37%; F1:  56.13 147\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  53.82%; recall:  63.01%; F1:  58.05 288\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  78.57%; recall:  61.60%; F1:  69.06 98\n",
      "\n",
      "\tlocation: precision:  42.86%; recall:  60.00%; F1:  50.00 49\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  40.00%; recall:  33.33%; F1:  36.36 15\n",
      "\n",
      "\tnatural_process: precision:  33.33%; recall:  33.33%; F1:  33.33 12\n",
      "\n",
      "\torganic_process: precision:  50.00%; recall:  17.07%; F1:  25.45 14\n",
      "\n",
      "\tproperty: precision:  50.49%; recall:  61.18%; F1:  55.32 103\n",
      "\n",
      "\tquality: precision:  57.14%; recall:  47.76%; F1:  52.03 56\n",
      "\n",
      "\ttime: precision:  77.78%; recall:  87.50%; F1:  82.35 9\n",
      "\n",
      "\ttime_interval: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
      "\n",
      "\ttime_period: precision:  84.62%; recall:  47.83%; F1:  61.11 13\n",
      "\n",
      "\n",
      "2019-12-18 16:58:01.376 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 57.2849\n",
      "2019-12-18 16:58:01.377 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:58:01.378 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 57.2849}, \"time_spent\": \"0:03:36\", \"epochs_done\": 18, \"batches_seen\": 504, \"train_examples_seen\": 31860, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:58:13.610 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 974 phrases; correct: 0.\n",
      "\n",
      "precision:  59.55%; recall:  56.20%; FB1:  57.83\n",
      "\n",
      "\tO: precision:  76.92%; recall:  100.00%; F1:  86.96 26\n",
      "\n",
      "\tartifact: precision:  65.67%; recall:  53.66%; F1:  59.06 134\n",
      "\n",
      "\tcognition: precision:  60.74%; recall:  50.31%; F1:  55.03 135\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  53.80%; recall:  69.11%; F1:  60.50 316\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  80.00%; recall:  60.80%; F1:  69.09 95\n",
      "\n",
      "\tlocation: precision:  51.61%; recall:  45.71%; F1:  48.48 31\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  36.36%; recall:  22.22%; F1:  27.59 11\n",
      "\n",
      "\tnatural_process: precision:  60.00%; recall:  25.00%; F1:  35.29 5\n",
      "\n",
      "\torganic_process: precision:  41.38%; recall:  29.27%; F1:  34.29 29\n",
      "\n",
      "\tproperty: precision:  52.50%; recall:  49.41%; F1:  50.91 80\n",
      "\n",
      "\tquality: precision:  49.23%; recall:  47.76%; F1:  48.48 65\n",
      "\n",
      "\ttime: precision:  87.50%; recall:  87.50%; F1:  87.50 8\n",
      "\n",
      "\ttime_interval: precision:  25.00%; recall:  100.00%; F1:  40.00 4\n",
      "\n",
      "\ttime_period: precision:  91.67%; recall:  47.83%; F1:  62.86 12\n",
      "\n",
      "\n",
      "2019-12-18 16:58:13.611 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 57.8265\n",
      "2019-12-18 16:58:13.612 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:58:13.613 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 57.8265}, \"time_spent\": \"0:03:48\", \"epochs_done\": 19, \"batches_seen\": 532, \"train_examples_seen\": 33630, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:58:25.645 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 980 phrases; correct: 0.\n",
      "\n",
      "precision:  58.67%; recall:  55.72%; FB1:  57.16\n",
      "\n",
      "\tO: precision:  66.67%; recall:  100.00%; F1:  80.00 30\n",
      "\n",
      "\tartifact: precision:  59.21%; recall:  54.88%; F1:  56.96 152\n",
      "\n",
      "\tcognition: precision:  63.16%; recall:  51.53%; F1:  56.76 133\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  51.56%; recall:  60.57%; F1:  55.70 289\n",
      "\n",
      "\tgeological_formation: precision:  66.67%; recall:  63.16%; F1:  64.86 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  89.53%; recall:  61.60%; F1:  72.99 86\n",
      "\n",
      "\tlocation: precision:  53.12%; recall:  48.57%; F1:  50.75 32\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  37.50%; recall:  33.33%; F1:  35.29 16\n",
      "\n",
      "\tnatural_process: precision:  38.46%; recall:  41.67%; F1:  40.00 13\n",
      "\n",
      "\torganic_process: precision:  77.78%; recall:  17.07%; F1:  28.00 9\n",
      "\n",
      "\tproperty: precision:  49.14%; recall:  67.06%; F1:  56.72 116\n",
      "\n",
      "\tquality: precision:  50.00%; recall:  44.78%; F1:  47.24 60\n",
      "\n",
      "\ttime: precision:  100.00%; recall:  75.00%; F1:  85.71 6\n",
      "\n",
      "\ttime_interval: precision:  25.00%; recall:  100.00%; F1:  40.00 4\n",
      "\n",
      "\ttime_period: precision:  100.00%; recall:  47.83%; F1:  64.71 11\n",
      "\n",
      "\n",
      "2019-12-18 16:58:25.646 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 57.8265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 57.1571}, \"time_spent\": \"0:04:00\", \"epochs_done\": 20, \"batches_seen\": 560, \"train_examples_seen\": 35400, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:58:37.253 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 982 phrases; correct: 0.\n",
      "\n",
      "precision:  59.67%; recall:  56.78%; FB1:  58.19\n",
      "\n",
      "\tO: precision:  71.43%; recall:  100.00%; F1:  83.33 28\n",
      "\n",
      "\tartifact: precision:  67.39%; recall:  56.71%; F1:  61.59 138\n",
      "\n",
      "\tcognition: precision:  63.04%; recall:  53.37%; F1:  57.81 138\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  54.96%; recall:  63.01%; F1:  58.71 282\n",
      "\n",
      "\tgeological_formation: precision:  68.42%; recall:  68.42%; F1:  68.42 19\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  75.96%; recall:  63.20%; F1:  69.00 104\n",
      "\n",
      "\tlocation: precision:  50.00%; recall:  51.43%; F1:  50.70 36\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  52.94%; recall:  50.00%; F1:  51.43 17\n",
      "\n",
      "\tnatural_process: precision:  36.36%; recall:  33.33%; F1:  34.78 11\n",
      "\n",
      "\torganic_process: precision:  27.78%; recall:  36.59%; F1:  31.58 54\n",
      "\n",
      "\tproperty: precision:  59.68%; recall:  43.53%; F1:  50.34 62\n",
      "\n",
      "\tquality: precision:  50.75%; recall:  50.75%; F1:  50.75 67\n",
      "\n",
      "\ttime: precision:  100.00%; recall:  87.50%; F1:  93.33 7\n",
      "\n",
      "\ttime_interval: precision:  50.00%; recall:  100.00%; F1:  66.67 2\n",
      "\n",
      "\ttime_period: precision:  91.67%; recall:  47.83%; F1:  62.86 12\n",
      "\n",
      "\n",
      "2019-12-18 16:58:37.255 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 58.1927\n",
      "2019-12-18 16:58:37.255 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:58:37.256 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 58.1927}, \"time_spent\": \"0:04:11\", \"epochs_done\": 21, \"batches_seen\": 588, \"train_examples_seen\": 37170, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:58:49.190 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 954 phrases; correct: 0.\n",
      "\n",
      "precision:  60.27%; recall:  55.72%; FB1:  57.91\n",
      "\n",
      "\tO: precision:  100.00%; recall:  100.00%; F1:  100.00 20\n",
      "\n",
      "\tartifact: precision:  63.92%; recall:  61.59%; F1:  62.73 158\n",
      "\n",
      "\tcognition: precision:  56.88%; recall:  55.83%; F1:  56.35 160\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  63.96%; recall:  51.22%; F1:  56.88 197\n",
      "\n",
      "\tgeological_formation: precision:  68.42%; recall:  68.42%; F1:  68.42 19\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  77.23%; recall:  62.40%; F1:  69.03 101\n",
      "\n",
      "\tlocation: precision:  51.72%; recall:  42.86%; F1:  46.88 29\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  38.89%; recall:  38.89%; F1:  38.89 18\n",
      "\n",
      "\tnatural_process: precision:  27.27%; recall:  25.00%; F1:  26.09 11\n",
      "\n",
      "\torganic_process: precision:  27.66%; recall:  31.71%; F1:  29.55 47\n",
      "\n",
      "\tproperty: precision:  61.54%; recall:  65.88%; F1:  63.64 91\n",
      "\n",
      "\tquality: precision:  42.47%; recall:  46.27%; F1:  44.29 73\n",
      "\n",
      "\ttime: precision:  77.78%; recall:  87.50%; F1:  82.35 9\n",
      "\n",
      "\ttime_interval: precision:  50.00%; recall:  100.00%; F1:  66.67 2\n",
      "\n",
      "\ttime_period: precision:  90.91%; recall:  43.48%; F1:  58.82 11\n",
      "\n",
      "\ttime_unit: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tvolume: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\n",
      "2019-12-18 16:58:49.192 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 58.1927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 57.9053}, \"time_spent\": \"0:04:23\", \"epochs_done\": 22, \"batches_seen\": 616, \"train_examples_seen\": 38940, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:59:00.789 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 900 phrases; correct: 0.\n",
      "\n",
      "precision:  60.89%; recall:  53.10%; FB1:  56.73\n",
      "\n",
      "\tO: precision:  90.91%; recall:  100.00%; F1:  95.24 22\n",
      "\n",
      "\tartifact: precision:  72.88%; recall:  52.44%; F1:  60.99 118\n",
      "\n",
      "\tcognition: precision:  55.83%; recall:  55.83%; F1:  55.83 163\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  61.42%; recall:  49.19%; F1:  54.63 197\n",
      "\n",
      "\tgeological_formation: precision:  68.42%; recall:  68.42%; F1:  68.42 19\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  81.61%; recall:  56.80%; F1:  66.98 87\n",
      "\n",
      "\tlocation: precision:  48.48%; recall:  45.71%; F1:  47.06 33\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  41.67%; recall:  27.78%; F1:  33.33 12\n",
      "\n",
      "\tnatural_process: precision:  33.33%; recall:  33.33%; F1:  33.33 12\n",
      "\n",
      "\torganic_process: precision:  25.00%; recall:  39.02%; F1:  30.48 64\n",
      "\n",
      "\tproperty: precision:  64.94%; recall:  58.82%; F1:  61.73 77\n",
      "\n",
      "\tquality: precision:  50.00%; recall:  49.25%; F1:  49.62 66\n",
      "\n",
      "\ttime: precision:  70.00%; recall:  87.50%; F1:  77.78 10\n",
      "\n",
      "\ttime_interval: precision:  50.00%; recall:  100.00%; F1:  66.67 2\n",
      "\n",
      "\ttime_period: precision:  84.62%; recall:  47.83%; F1:  61.11 13\n",
      "\n",
      "\n",
      "2019-12-18 16:59:00.790 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 58.1927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 56.7288}, \"time_spent\": \"0:04:35\", \"epochs_done\": 23, \"batches_seen\": 644, \"train_examples_seen\": 40710, \"impatience\": 2, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:59:12.509 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 984 phrases; correct: 0.\n",
      "\n",
      "precision:  60.26%; recall:  57.46%; FB1:  58.83\n",
      "\n",
      "\tO: precision:  100.00%; recall:  100.00%; F1:  100.00 20\n",
      "\n",
      "\tartifact: precision:  79.80%; recall:  48.17%; F1:  60.08 99\n",
      "\n",
      "\tcognition: precision:  61.44%; recall:  57.67%; F1:  59.49 153\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  53.18%; recall:  64.63%; F1:  58.35 299\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  83.16%; recall:  63.20%; F1:  71.82 95\n",
      "\n",
      "\tlocation: precision:  52.50%; recall:  60.00%; F1:  56.00 40\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  37.50%; recall:  33.33%; F1:  35.29 16\n",
      "\n",
      "\tnatural_process: precision:  21.05%; recall:  33.33%; F1:  25.81 19\n",
      "\n",
      "\torganic_process: precision:  55.56%; recall:  12.20%; F1:  20.00 9\n",
      "\n",
      "\tproperty: precision:  51.30%; recall:  69.41%; F1:  59.00 115\n",
      "\n",
      "\tquality: precision:  45.07%; recall:  47.76%; F1:  46.38 71\n",
      "\n",
      "\ttime: precision:  77.78%; recall:  87.50%; F1:  82.35 9\n",
      "\n",
      "\ttime_interval: precision:  50.00%; recall:  100.00%; F1:  66.67 2\n",
      "\n",
      "\ttime_period: precision:  78.57%; recall:  47.83%; F1:  59.46 14\n",
      "\n",
      "\n",
      "2019-12-18 16:59:12.511 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 58.8294\n",
      "2019-12-18 16:59:12.511 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2019-12-18 16:59:12.512 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 58.8294}, \"time_spent\": \"0:04:47\", \"epochs_done\": 24, \"batches_seen\": 672, \"train_examples_seen\": 42480, \"impatience\": 0, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:59:24.429 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 965 phrases; correct: 0.\n",
      "\n",
      "precision:  59.38%; recall:  55.52%; FB1:  57.39\n",
      "\n",
      "\tO: precision:  90.91%; recall:  100.00%; F1:  95.24 22\n",
      "\n",
      "\tartifact: precision:  66.92%; recall:  54.27%; F1:  59.93 133\n",
      "\n",
      "\tcognition: precision:  62.83%; recall:  43.56%; F1:  51.45 113\n",
      "\n",
      "\tevent: precision:  52.60%; recall:  65.85%; F1:  58.48 308\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  88.24%; recall:  60.00%; F1:  71.43 85\n",
      "\n",
      "\tlocation: precision:  70.00%; recall:  40.00%; F1:  50.91 20\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  42.86%; recall:  50.00%; F1:  46.15 21\n",
      "\n",
      "\tnatural_process: precision:  22.22%; recall:  50.00%; F1:  30.77 27\n",
      "\n",
      "\torganic_process: precision:  33.33%; recall:  9.76%; F1:  15.09 12\n",
      "\n",
      "\tproperty: precision:  51.58%; recall:  57.65%; F1:  54.44 95\n",
      "\n",
      "\tquality: precision:  45.78%; recall:  56.72%; F1:  50.67 83\n",
      "\n",
      "\ttime: precision:  63.64%; recall:  87.50%; F1:  73.68 11\n",
      "\n",
      "\ttime_interval: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
      "\n",
      "\ttime_period: precision:  92.31%; recall:  52.17%; F1:  66.67 13\n",
      "\n",
      "\n",
      "2019-12-18 16:59:24.431 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 58.8294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 57.3861}, \"time_spent\": \"0:04:59\", \"epochs_done\": 25, \"batches_seen\": 700, \"train_examples_seen\": 44250, \"impatience\": 1, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:59:37.238 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 963 phrases; correct: 0.\n",
      "\n",
      "precision:  60.02%; recall:  56.01%; FB1:  57.94\n",
      "\n",
      "\tO: precision:  90.91%; recall:  100.00%; F1:  95.24 22\n",
      "\n",
      "\tartifact: precision:  68.18%; recall:  54.88%; F1:  60.81 132\n",
      "\n",
      "\tcognition: precision:  64.29%; recall:  44.17%; F1:  52.36 112\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  54.32%; recall:  71.54%; F1:  61.75 324\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  78.00%; recall:  62.40%; F1:  69.33 100\n",
      "\n",
      "\tlocation: precision:  43.18%; recall:  54.29%; F1:  48.10 44\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  38.89%; recall:  38.89%; F1:  38.89 18\n",
      "\n",
      "\tnatural_process: precision:  25.00%; recall:  16.67%; F1:  20.00 8\n",
      "\n",
      "\torganic_process: precision:  42.86%; recall:  7.32%; F1:  12.50 7\n",
      "\n",
      "\tproperty: precision:  53.01%; recall:  51.76%; F1:  52.38 83\n",
      "\n",
      "\tquality: precision:  50.82%; recall:  46.27%; F1:  48.44 61\n",
      "\n",
      "\ttime: precision:  87.50%; recall:  87.50%; F1:  87.50 8\n",
      "\n",
      "\ttime_interval: precision:  33.33%; recall:  100.00%; F1:  50.00 3\n",
      "\n",
      "\ttime_period: precision:  70.59%; recall:  52.17%; F1:  60.00 17\n",
      "\n",
      "\ttime_unit: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\n",
      "2019-12-18 16:59:37.239 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 58.8294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 57.9449}, \"time_spent\": \"0:05:11\", \"epochs_done\": 26, \"batches_seen\": 728, \"train_examples_seen\": 46020, \"impatience\": 2, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 16:59:48.844 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 991 phrases; correct: 0.\n",
      "\n",
      "precision:  60.04%; recall:  57.66%; FB1:  58.82\n",
      "\n",
      "\tO: precision:  66.67%; recall:  100.00%; F1:  80.00 30\n",
      "\n",
      "\tartifact: precision:  73.11%; recall:  53.05%; F1:  61.48 119\n",
      "\n",
      "\tcognition: precision:  60.49%; recall:  60.12%; F1:  60.31 162\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  57.81%; recall:  60.16%; F1:  58.96 256\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  78.12%; recall:  60.00%; F1:  67.87 96\n",
      "\n",
      "\tlocation: precision:  48.65%; recall:  51.43%; F1:  50.00 37\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  47.37%; recall:  50.00%; F1:  48.65 19\n",
      "\n",
      "\tnatural_process: precision:  33.33%; recall:  41.67%; F1:  37.04 15\n",
      "\n",
      "\torganic_process: precision:  31.82%; recall:  34.15%; F1:  32.94 44\n",
      "\n",
      "\tproperty: precision:  56.25%; recall:  63.53%; F1:  59.67 96\n",
      "\n",
      "\tquality: precision:  45.31%; recall:  43.28%; F1:  44.27 64\n",
      "\n",
      "\ttime: precision:  100.00%; recall:  75.00%; F1:  85.71 6\n",
      "\n",
      "\ttime_interval: precision:  33.33%; recall:  100.00%; F1:  50.00 3\n",
      "\n",
      "\ttime_period: precision:  75.00%; recall:  65.22%; F1:  69.77 20\n",
      "\n",
      "\tvolume: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\n",
      "2019-12-18 16:59:48.845 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 58.8294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 58.8235}, \"time_spent\": \"0:05:23\", \"epochs_done\": 27, \"batches_seen\": 756, \"train_examples_seen\": 47790, \"impatience\": 3, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 17:00:00.427 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 958 phrases; correct: 0.\n",
      "\n",
      "precision:  60.02%; recall:  55.72%; FB1:  57.79\n",
      "\n",
      "\tO: precision:  90.91%; recall:  100.00%; F1:  95.24 22\n",
      "\n",
      "\tartifact: precision:  68.03%; recall:  50.61%; F1:  58.04 122\n",
      "\n",
      "\tcognition: precision:  70.75%; recall:  46.01%; F1:  55.76 106\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  53.55%; recall:  67.48%; F1:  59.71 310\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  76.36%; recall:  67.20%; F1:  71.49 110\n",
      "\n",
      "\tlocation: precision:  51.72%; recall:  42.86%; F1:  46.88 29\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  30.00%; recall:  33.33%; F1:  31.58 20\n",
      "\n",
      "\tnatural_process: precision:  28.57%; recall:  16.67%; F1:  21.05 7\n",
      "\n",
      "\torganic_process: precision:  30.77%; recall:  9.76%; F1:  14.81 13\n",
      "\n",
      "\tproperty: precision:  55.91%; recall:  61.18%; F1:  58.43 93\n",
      "\n",
      "\tquality: precision:  42.50%; recall:  50.75%; F1:  46.26 80\n",
      "\n",
      "\ttime: precision:  87.50%; recall:  87.50%; F1:  87.50 8\n",
      "\n",
      "\ttime_interval: precision:  33.33%; recall:  100.00%; F1:  50.00 3\n",
      "\n",
      "\ttime_period: precision:  83.33%; recall:  43.48%; F1:  57.14 12\n",
      "\n",
      "\n",
      "2019-12-18 17:00:00.428 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 58.8294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 57.7889}, \"time_spent\": \"0:05:35\", \"epochs_done\": 28, \"batches_seen\": 784, \"train_examples_seen\": 49560, \"impatience\": 4, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 17:00:12.173 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 958 phrases; correct: 0.\n",
      "\n",
      "precision:  59.60%; recall:  55.33%; FB1:  57.39\n",
      "\n",
      "\tO: precision:  62.50%; recall:  100.00%; F1:  76.92 32\n",
      "\n",
      "\tartifact: precision:  74.07%; recall:  48.78%; F1:  58.82 108\n",
      "\n",
      "\tcognition: precision:  55.95%; recall:  57.67%; F1:  56.80 168\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  56.10%; recall:  56.10%; F1:  56.10 246\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  86.90%; recall:  58.40%; F1:  69.86 84\n",
      "\n",
      "\tlocation: precision:  48.48%; recall:  45.71%; F1:  47.06 33\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  39.13%; recall:  50.00%; F1:  43.90 23\n",
      "\n",
      "\tnatural_process: precision:  29.41%; recall:  41.67%; F1:  34.48 17\n",
      "\n",
      "\torganic_process: precision:  38.24%; recall:  31.71%; F1:  34.67 34\n",
      "\n",
      "\tproperty: precision:  54.21%; recall:  68.24%; F1:  60.42 107\n",
      "\n",
      "\tquality: precision:  50.00%; recall:  44.78%; F1:  47.24 60\n",
      "\n",
      "\ttime: precision:  100.00%; recall:  75.00%; F1:  85.71 6\n",
      "\n",
      "\ttime_interval: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
      "\n",
      "\ttime_period: precision:  80.00%; recall:  52.17%; F1:  63.16 15\n",
      "\n",
      "\tvolume: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\n",
      "2019-12-18 17:00:12.174 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 58.8294\n",
      "2019-12-18 17:00:12.291 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 57.3869}, \"time_spent\": \"0:05:46\", \"epochs_done\": 29, \"batches_seen\": 812, \"train_examples_seen\": 51330, \"impatience\": 5, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 17:00:23.942 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 963 phrases; correct: 0.\n",
      "\n",
      "precision:  60.02%; recall:  56.01%; FB1:  57.94\n",
      "\n",
      "\tO: precision:  71.43%; recall:  100.00%; F1:  83.33 28\n",
      "\n",
      "\tartifact: precision:  70.80%; recall:  48.78%; F1:  57.76 113\n",
      "\n",
      "\tcognition: precision:  63.41%; recall:  47.85%; F1:  54.55 123\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  54.03%; recall:  65.45%; F1:  59.19 298\n",
      "\n",
      "\tgeological_formation: precision:  68.42%; recall:  68.42%; F1:  68.42 19\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  84.09%; recall:  59.20%; F1:  69.48 88\n",
      "\n",
      "\tlocation: precision:  47.37%; recall:  51.43%; F1:  49.32 38\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  42.86%; recall:  50.00%; F1:  46.15 21\n",
      "\n",
      "\tnatural_process: precision:  33.33%; recall:  41.67%; F1:  37.04 15\n",
      "\n",
      "\torganic_process: precision:  35.48%; recall:  26.83%; F1:  30.56 31\n",
      "\n",
      "\tproperty: precision:  58.70%; recall:  63.53%; F1:  61.02 92\n",
      "\n",
      "\tquality: precision:  45.59%; recall:  46.27%; F1:  45.93 68\n",
      "\n",
      "\ttime: precision:  100.00%; recall:  87.50%; F1:  93.33 7\n",
      "\n",
      "\ttime_interval: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
      "\n",
      "\ttime_period: precision:  86.67%; recall:  56.52%; F1:  68.42 15\n",
      "\n",
      "\tvolume: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\n",
      "2019-12-18 17:00:23.943 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 58.8294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 57.9449}, \"time_spent\": \"0:05:58\", \"epochs_done\": 30, \"batches_seen\": 840, \"train_examples_seen\": 53100, \"impatience\": 6, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 17:00:35.246 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 968 phrases; correct: 0.\n",
      "\n",
      "precision:  60.33%; recall:  56.59%; FB1:  58.40\n",
      "\n",
      "\tO: precision:  71.43%; recall:  100.00%; F1:  83.33 28\n",
      "\n",
      "\tartifact: precision:  72.73%; recall:  48.78%; F1:  58.39 110\n",
      "\n",
      "\tcognition: precision:  60.00%; recall:  53.37%; F1:  56.49 145\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  54.80%; recall:  62.60%; F1:  58.44 281\n",
      "\n",
      "\tgeological_formation: precision:  68.42%; recall:  68.42%; F1:  68.42 19\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  86.36%; recall:  60.80%; F1:  71.36 88\n",
      "\n",
      "\tlocation: precision:  46.34%; recall:  54.29%; F1:  50.00 41\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  42.86%; recall:  50.00%; F1:  46.15 21\n",
      "\n",
      "\tnatural_process: precision:  38.46%; recall:  41.67%; F1:  40.00 13\n",
      "\n",
      "\torganic_process: precision:  33.33%; recall:  24.39%; F1:  28.17 30\n",
      "\n",
      "\tproperty: precision:  59.38%; recall:  67.06%; F1:  62.98 96\n",
      "\n",
      "\tquality: precision:  46.27%; recall:  46.27%; F1:  46.27 67\n",
      "\n",
      "\ttime: precision:  100.00%; recall:  75.00%; F1:  85.71 6\n",
      "\n",
      "\ttime_interval: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
      "\n",
      "\ttime_period: precision:  81.25%; recall:  56.52%; F1:  66.67 16\n",
      "\n",
      "\tvolume: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\n",
      "2019-12-18 17:00:35.247 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 58.8294\n",
      "2019-12-18 17:00:35.377 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 328: Ran out of patience\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 58.4}, \"time_spent\": \"0:06:09\", \"epochs_done\": 31, \"batches_seen\": 868, \"train_examples_seen\": 54870, \"impatience\": 7, \"patience_limit\": 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 17:00:35.970 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/word_3_ft.dict]\n",
      "2019-12-18 17:00:35.979 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/tag_3_ft.dict]\n",
      "2019-12-18 17:00:35.981 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/char_3_ft.dict]\n",
      "2019-12-18 17:00:35.982 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 67: [loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/wiki.en.bin`]\n",
      "2019-12-18 17:00:47.526 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 17:00:47.625 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 17:00:50.203 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 17:00:51.451 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 984 phrases; correct: 0.\n",
      "\n",
      "precision:  60.26%; recall:  57.46%; FB1:  58.83\n",
      "\n",
      "\tO: precision:  100.00%; recall:  100.00%; F1:  100.00 20\n",
      "\n",
      "\tartifact: precision:  79.80%; recall:  48.17%; F1:  60.08 99\n",
      "\n",
      "\tcognition: precision:  61.44%; recall:  57.67%; F1:  59.49 153\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  53.18%; recall:  64.63%; F1:  58.35 299\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  83.16%; recall:  63.20%; F1:  71.82 95\n",
      "\n",
      "\tlocation: precision:  52.50%; recall:  60.00%; F1:  56.00 40\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  37.50%; recall:  33.33%; F1:  35.29 16\n",
      "\n",
      "\tnatural_process: precision:  21.05%; recall:  33.33%; F1:  25.81 19\n",
      "\n",
      "\torganic_process: precision:  55.56%; recall:  12.20%; F1:  20.00 9\n",
      "\n",
      "\tproperty: precision:  51.30%; recall:  69.41%; F1:  59.00 115\n",
      "\n",
      "\tquality: precision:  45.07%; recall:  47.76%; F1:  46.38 71\n",
      "\n",
      "\ttime: precision:  77.78%; recall:  87.50%; F1:  82.35 9\n",
      "\n",
      "\ttime_interval: precision:  50.00%; recall:  100.00%; F1:  66.67 2\n",
      "\n",
      "\ttime_period: precision:  78.57%; recall:  47.83%; F1:  59.46 14\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 58.8294}, \"time_spent\": \"0:00:02\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 17:00:52.446 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 4290 tokens with 973 phrases; found: 940 phrases; correct: 0.\n",
      "\n",
      "precision:  60.00%; recall:  57.97%; FB1:  58.96\n",
      "\n",
      "\tO: precision:  60.00%; recall:  35.29%; F1:  44.44 20\n",
      "\n",
      "\tartifact: precision:  70.59%; recall:  57.14%; F1:  63.16 119\n",
      "\n",
      "\tcognition: precision:  58.25%; recall:  61.08%; F1:  59.63 194\n",
      "\n",
      "\teconomic_process: precision:  9.09%; recall:  25.00%; F1:  13.33 11\n",
      "\n",
      "\tevent: precision:  58.65%; recall:  58.65%; F1:  58.65 266\n",
      "\n",
      "\tgeological_formation: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tland: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  79.49%; recall:  73.81%; F1:  76.54 117\n",
      "\n",
      "\tlocation: precision:  61.90%; recall:  50.00%; F1:  55.32 21\n",
      "\n",
      "\tmotivation: precision:  66.67%; recall:  100.00%; F1:  80.00 3\n",
      "\n",
      "\tnatural_object: precision:  33.33%; recall:  30.00%; F1:  31.58 9\n",
      "\n",
      "\tnatural_process: precision:  25.00%; recall:  50.00%; F1:  33.33 8\n",
      "\n",
      "\torganic_process: precision:  44.44%; recall:  17.39%; F1:  25.00 9\n",
      "\n",
      "\tproperty: precision:  39.34%; recall:  55.81%; F1:  46.15 61\n",
      "\n",
      "\tquality: precision:  50.00%; recall:  50.79%; F1:  50.39 64\n",
      "\n",
      "\ttime: precision:  60.00%; recall:  75.00%; F1:  66.67 5\n",
      "\n",
      "\ttime_interval: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
      "\n",
      "\ttime_period: precision:  65.38%; recall:  70.83%; F1:  68.00 26\n",
      "\n",
      "\ttime_unit: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
      "\n",
      "\tvalue: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"test\": {\"eval_examples_count\": 222, \"metrics\": {\"ner_f1\": 58.965}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 17:00:52.891 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/word_3_ft.dict]\n",
      "2019-12-18 17:00:52.901 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/tag_3_ft.dict]\n",
      "2019-12-18 17:00:52.902 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/char_3_ft.dict]\n",
      "2019-12-18 17:00:52.904 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 67: [loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/wiki.en.bin`]\n",
      "2019-12-18 17:01:03.675 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 17:01:03.780 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 17:01:05.593 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft\n"
     ]
    }
   ],
   "source": [
    "model2 = train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EpPOnV8dV-oH",
    "outputId": "e8d0bdf0-de0f-4458-fc62-49219cf7ace4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 17:01:05.758 WARNING in 'deeppavlov.core.commands.train'['train'] at line 108: \"validate_best\" and \"test_best\" parameters are deprecated. Please, use \"evaluation_targets\" list instead\n",
      "2019-12-18 17:01:05.970 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/word_3_ft.dict]\n",
      "2019-12-18 17:01:05.980 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/tag_3_ft.dict]\n",
      "2019-12-18 17:01:05.981 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/onthology_objects/char_3_ft.dict]\n",
      "2019-12-18 17:01:05.983 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 67: [loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/wiki.en.bin`]\n",
      "2019-12-18 17:01:17.332 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 17:01:17.431 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-12-18 17:01:19.224 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/onthology_objects/model_no_pos_3_ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 17:01:20.429 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 5037 tokens with 1032 phrases; found: 984 phrases; correct: 0.\n",
      "\n",
      "precision:  60.26%; recall:  57.46%; FB1:  58.83\n",
      "\n",
      "\tO: precision:  100.00%; recall:  100.00%; F1:  100.00 20\n",
      "\n",
      "\tartifact: precision:  79.80%; recall:  48.17%; F1:  60.08 99\n",
      "\n",
      "\tcognition: precision:  61.44%; recall:  57.67%; F1:  59.49 153\n",
      "\n",
      "\teconomic_process: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tevent: precision:  53.18%; recall:  64.63%; F1:  58.35 299\n",
      "\n",
      "\tgeological_formation: precision:  72.22%; recall:  68.42%; F1:  70.27 18\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  83.16%; recall:  63.20%; F1:  71.82 95\n",
      "\n",
      "\tlocation: precision:  52.50%; recall:  60.00%; F1:  56.00 40\n",
      "\n",
      "\tmotivation: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
      "\n",
      "\tnatural_object: precision:  37.50%; recall:  33.33%; F1:  35.29 16\n",
      "\n",
      "\tnatural_process: precision:  21.05%; recall:  33.33%; F1:  25.81 19\n",
      "\n",
      "\torganic_process: precision:  55.56%; recall:  12.20%; F1:  20.00 9\n",
      "\n",
      "\tproperty: precision:  51.30%; recall:  69.41%; F1:  59.00 115\n",
      "\n",
      "\tquality: precision:  45.07%; recall:  47.76%; F1:  46.38 71\n",
      "\n",
      "\ttime: precision:  77.78%; recall:  87.50%; F1:  82.35 9\n",
      "\n",
      "\ttime_interval: precision:  50.00%; recall:  100.00%; F1:  66.67 2\n",
      "\n",
      "\ttime_period: precision:  78.57%; recall:  47.83%; F1:  59.46 14\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 217, \"metrics\": {\"ner_f1\": 58.8294}, \"time_spent\": \"0:00:02\", \"examples\": [{\"x\": [\"the\", \"key\", \"consideration\", \"is\", \"whether\", \"and\", \"to\", \"what\", \"extent\", \"the\", \"administrative\", \"record\", \"data\", \"re\", \"examined\", \"retroactively\", \"a\", \"decade\", \"later\", \"for\", \"the\", \"original\", \"study's\", \"time\", \"period\", \"would\", \"yield\", \"comparable\", \"results\", \"to\", \"those\", \"based\", \"on\", \"data\", \"acquired\", \"at\", \"the\", \"time\", \"of\", \"the\", \"study\", \".\"], \"y_predicted\": [[\"O\", \"B-property\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-time_period\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"B-property\", \"B-time\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"B-living_thing\", \"O\"], [\"the\", \"key\", \"consideration\", \"is\", \"whether\", \"and\", \"to\", \"what\", \"extent\", \"the\", \"administrative\", \"record\", \"data\", \"re\", \"examined\", \"retroactively\", \"a\", \"decade\", \"later\", \"for\", \"the\", \"original\", \"study's\", \"time\", \"period\", \"would\", \"yield\", \"comparable\", \"results\", \"to\", \"those\", \"based\", \"on\", \"data\", \"acquired\", \"at\", \"the\", \"time\", \"of\", \"the\", \"study\", \".\"]], \"y_true\": [\"O\", \"B-artifact\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-time_period\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"B-time\", \"I-property\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-time_period\", \"O\", \"O\", \"B-artifact\", \"O\"]}, {\"x\": [\"the\", \"results\", \"indicated\", \"that\", \"despite\", \"small\", \"changes\", \"over\", \"time\", \",\", \"the\", \"same\", \"data\", \"patterns\", \"and\", \"statistical\", \"effects\", \"were\", \"reproducible\", \"for\", \"the\", \"two\", \"archival\", \"outcome\", \"variables\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"B-event\", \"B-property\", \"O\", \"B-cognition\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\"], [\"the\", \"results\", \"indicated\", \"that\", \"despite\", \"small\", \"changes\", \"over\", \"time\", \",\", \"the\", \"same\", \"data\", \"patterns\", \"and\", \"statistical\", \"effects\", \"were\", \"reproducible\", \"for\", \"the\", \"two\", \"archival\", \"outcome\", \"variables\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"B-event\", \"B-property\", \"O\", \"B-cognition\", \"B-time_period\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\"]}, {\"x\": [\"for\", \"substantiated\", \"cm\", \",\", \"the\", \"reproduced\", \"analyses\", \"reflected\", \"higher\", \"effect\", \"sizes\", \"and\", \"a\", \"clear\", \"pattern\", \"of\", \"reduction\", \"as\", \"a\", \"function\", \"of\", \"intervention\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"B-location\", \"B-cognition\", \"O\", \"B-natural_process\", \"O\", \"O\", \"B-quality\", \"O\", \"B-event\", \"O\"], [\"for\", \"substantiated\", \"cm\", \",\", \"the\", \"reproduced\", \"analyses\", \"reflected\", \"higher\", \"effect\", \"sizes\", \"and\", \"a\", \"clear\", \"pattern\", \"of\", \"reduction\", \"as\", \"a\", \"function\", \"of\", \"intervention\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"B-location\", \"B-cognition\", \"O\", \"B-event\", \"O\", \"O\", \"B-event\", \"O\", \"B-event\", \"O\"]}, {\"x\": [\"for\", \"out\", \"of\", \"home\", \"placements\", \",\", \"effect\", \"sizes\", \"were\", \"quite\", \"comparable\", \"to\", \"the\", \"original\", \"ones\", \",\", \"reflecting\", \"preventive\", \"impact\", \".\"], \"y_predicted\": [[\"O\", \"B-event\", \"O\", \"B-artifact\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\"], [\"for\", \"out\", \"of\", \"home\", \"placements\", \",\", \"effect\", \"sizes\", \"were\", \"quite\", \"comparable\", \"to\", \"the\", \"original\", \"ones\", \",\", \"reflecting\", \"preventive\", \"impact\", \".\"]], \"y_true\": [\"O\", \"B-event\", \"O\", \"B-artifact\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"B-artifact\", \"B-event\", \"O\"]}, {\"x\": [\"overall\", \",\", \"this\", \"case\", \"study\", \"illustrated\", \"the\", \"verifiability\", \"of\", \"data\", \"reproducibility\", \"in\", \"the\", \"context\", \"of\", \"a\", \"population\", \"outcome\", \"evaluation\", \",\", \"which\", \"underscores\", \"the\", \"importance\", \"of\", \"reliable\", \"population\", \"prevalence\", \"measurement\", \"as\", \"an\", \"essential\", \"part\", \"of\", \"a\", \"comprehensive\", \"public\", \"health\", \"strategy\", \"aimed\", \"at\", \"the\", \"prevention\", \"of\", \"cm\", \".\"], \"y_predicted\": [[\"B-artifact\", \"O\", \"O\", \"B-event\", \"B-cognition\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"B-event\", \"B-event\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"B-event\", \"B-property\", \"B-event\", \"O\", \"O\", \"O\", \"B-location\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\"], [\"overall\", \",\", \"this\", \"case\", \"study\", \"illustrated\", \"the\", \"verifiability\", \"of\", \"data\", \"reproducibility\", \"in\", \"the\", \"context\", \"of\", \"a\", \"population\", \"outcome\", \"evaluation\", \",\", \"which\", \"underscores\", \"the\", \"importance\", \"of\", \"reliable\", \"population\", \"prevalence\", \"measurement\", \"as\", \"an\", \"essential\", \"part\", \"of\", \"a\", \"comprehensive\", \"public\", \"health\", \"strategy\", \"aimed\", \"at\", \"the\", \"prevention\", \"of\", \"cm\", \".\"]], \"y_true\": [\"B-artifact\", \"O\", \"O\", \"B-natural_object\", \"I-living_thing\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"B-event\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"B-event\", \"B-property\", \"B-event\", \"O\", \"O\", \"O\", \"B-location\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\"]}, {\"x\": [\"c\", \"2016\", \"elsevier\", \"ltd\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\"], [\"c\", \"2016\", \"elsevier\", \"ltd\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"all\", \"rights\", \"reserved\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\"], [\"all\", \"rights\", \"reserved\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"aims\", \"ancient\", \"dna\", \"adna\", \"extracted\", \"from\", \"historical\", \"bones\", \"is\", \"damaged\", \"and\", \"fragmented\", \"into\", \"short\", \"segments\", \",\", \"present\", \"in\", \"low\", \"quantity\", \",\", \"and\", \"usually\", \"copurified\", \"with\", \"microbial\", \"dna\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-time\", \"O\", \"B-artifact\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"aims\", \"ancient\", \"dna\", \"adna\", \"extracted\", \"from\", \"historical\", \"bones\", \"is\", \"damaged\", \"and\", \"fragmented\", \"into\", \"short\", \"segments\", \",\", \"present\", \"in\", \"low\", \"quantity\", \",\", \"and\", \"usually\", \"copurified\", \"with\", \"microbial\", \"dna\", \".\"]], \"y_true\": [\"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"B-time\", \"O\", \"B-property\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"a\", \"wide\", \"range\", \"of\", \"dna\", \"quantification\", \"methods\", \"are\", \"available\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"B-property\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\"], [\"a\", \"wide\", \"range\", \"of\", \"dna\", \"quantification\", \"methods\", \"are\", \"available\", \".\"]], \"y_true\": [\"O\", \"O\", \"B-location\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"the\", \"aim\", \"of\", \"this\", \"study\", \"was\", \"to\", \"compare\", \"the\", \"five\", \"most\", \"common\", \"dna\", \"quantification\", \"methods\", \"for\", \"adna\", \".\"], \"y_predicted\": [[\"O\", \"B-location\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"B-quality\", \"O\", \"B-artifact\", \"O\", \"B-location\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"aim\", \"of\", \"this\", \"study\", \"was\", \"to\", \"compare\", \"the\", \"five\", \"most\", \"common\", \"dna\", \"quantification\", \"methods\", \"for\", \"adna\", \".\"]], \"y_true\": [\"O\", \"B-location\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"B-quality\", \"O\", \"B-artifact\", \"O\", \"B-location\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"materials\", \"and\", \"methods\", \"quantification\", \"methods\", \"were\", \"tested\", \"on\", \"dna\", \"extracted\", \"from\", \"skeletal\", \"material\", \"originating\", \"from\", \"an\", \"early\", \"medieval\", \"burial\", \"site\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"B-location\", \"O\"], [\"materials\", \"and\", \"methods\", \"quantification\", \"methods\", \"were\", \"tested\", \"on\", \"dna\", \"extracted\", \"from\", \"skeletal\", \"material\", \"originating\", \"from\", \"an\", \"early\", \"medieval\", \"burial\", \"site\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"I-event\", \"O\"]}, {\"x\": [\"the\", \"tested\", \"methods\", \"included\", \"ultraviolet\", \"uv\", \"absorbance\", \",\", \"real\", \"time\", \"quantitative\", \"polymerase\", \"chain\", \"reaction\", \"qpcr\", \"based\", \"on\", \"sybr\", \"r\", \"green\", \"detection\", \",\", \"real\", \"time\", \"qpcr\", \"based\", \"on\", \"a\", \"forensic\", \"kit\", \",\", \"quantification\", \"via\", \"fluorescent\", \"dyes\", \"bonded\", \"to\", \"dna\", \",\", \"and\", \"fragmentary\", \"analysis\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"B-geological_formation\", \"I-geological_formation\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"B-property\", \"B-event\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\"], [\"the\", \"tested\", \"methods\", \"included\", \"ultraviolet\", \"uv\", \"absorbance\", \",\", \"real\", \"time\", \"quantitative\", \"polymerase\", \"chain\", \"reaction\", \"qpcr\", \"based\", \"on\", \"sybr\", \"r\", \"green\", \"detection\", \",\", \"real\", \"time\", \"qpcr\", \"based\", \"on\", \"a\", \"forensic\", \"kit\", \",\", \"quantification\", \"via\", \"fluorescent\", \"dyes\", \"bonded\", \"to\", \"dna\", \",\", \"and\", \"fragmentary\", \"analysis\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"B-geological_formation\", \"I-artifact\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"B-location\", \"B-event\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"B-event\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\"]}, {\"x\": [\"differences\", \"between\", \"groups\", \"were\", \"tested\", \"using\", \"a\", \"paired\", \"t\", \"test\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"B-natural_object\", \"O\"], [\"differences\", \"between\", \"groups\", \"were\", \"tested\", \"using\", \"a\", \"paired\", \"t\", \"test\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"B-event\", \"O\"]}, {\"x\": [\"results\", \"methods\", \"that\", \"measure\", \"total\", \"dna\", \"present\", \"in\", \"the\", \"sample\", \"nanodrop\", \"tm\", \"uv\", \"spectrophotometer\", \"and\", \"qubit\", \"r\", \"fluorometer\", \"showed\", \"the\", \"highest\", \"concentrations\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-event\", \"B-cognition\", \"O\", \"B-time\", \"O\", \"O\", \"B-natural_object\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"results\", \"methods\", \"that\", \"measure\", \"total\", \"dna\", \"present\", \"in\", \"the\", \"sample\", \"nanodrop\", \"tm\", \"uv\", \"spectrophotometer\", \"and\", \"qubit\", \"r\", \"fluorometer\", \"showed\", \"the\", \"highest\", \"concentrations\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-artifact\", \"B-cognition\", \"O\", \"B-time\", \"O\", \"O\", \"B-natural_object\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"methods\", \"based\", \"on\", \"real\", \"time\", \"qpcr\", \"underestimated\", \"the\", \"quantity\", \"of\", \"adna\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"O\"], [\"methods\", \"based\", \"on\", \"real\", \"time\", \"qpcr\", \"underestimated\", \"the\", \"quantity\", \"of\", \"adna\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\"]}, {\"x\": [\"the\", \"most\", \"accurate\", \"method\", \"of\", \"adna\", \"quantification\", \"was\", \"fragmentary\", \"analysis\", \",\", \"which\", \"also\", \"allows\", \"dna\", \"quantification\", \"of\", \"the\", \"desired\", \"length\", \"and\", \"is\", \"not\", \"affected\", \"by\", \"pcr\", \"inhibitors\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"most\", \"accurate\", \"method\", \"of\", \"adna\", \"quantification\", \"was\", \"fragmentary\", \"analysis\", \",\", \"which\", \"also\", \"allows\", \"dna\", \"quantification\", \"of\", \"the\", \"desired\", \"length\", \"and\", \"is\", \"not\", \"affected\", \"by\", \"pcr\", \"inhibitors\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"conclusions\", \"methods\", \"based\", \"on\", \"the\", \"quantification\", \"of\", \"the\", \"total\", \"amount\", \"of\", \"dna\", \"in\", \"samples\", \"are\", \"unsuitable\", \"for\", \"ancient\", \"samples\", \"as\", \"they\", \"overestimate\", \"the\", \"amount\", \"of\", \"dna\", \"presumably\", \"due\", \"to\", \"the\", \"presence\", \"of\", \"microbial\", \"dna\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"B-cognition\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\"], [\"conclusions\", \"methods\", \"based\", \"on\", \"the\", \"quantification\", \"of\", \"the\", \"total\", \"amount\", \"of\", \"dna\", \"in\", \"samples\", \"are\", \"unsuitable\", \"for\", \"ancient\", \"samples\", \"as\", \"they\", \"overestimate\", \"the\", \"amount\", \"of\", \"dna\", \"presumably\", \"due\", \"to\", \"the\", \"presence\", \"of\", \"microbial\", \"dna\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"B-cognition\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"real\", \"time\", \"qpcr\", \"methods\", \"give\", \"undervalued\", \"results\", \"due\", \"to\", \"dna\", \"damage\", \"and\", \"the\", \"presence\", \"of\", \"pcr\", \"inhibitors\", \".\"], \"y_predicted\": [[\"B-O\", \"I-O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\"], [\"real\", \"time\", \"qpcr\", \"methods\", \"give\", \"undervalued\", \"results\", \"due\", \"to\", \"dna\", \"damage\", \"and\", \"the\", \"presence\", \"of\", \"pcr\", \"inhibitors\", \".\"]], \"y_true\": [\"B-O\", \"I-O\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"B-location\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"dna\", \"quantification\", \"methods\", \"based\", \"on\", \"fragment\", \"analysis\", \"show\", \"not\", \"only\", \"the\", \"quantity\", \"of\", \"dna\", \"but\", \"also\", \"fragment\", \"length\", \".\"], \"y_predicted\": [[\"O\", \"B-event\", \"O\", \"O\", \"O\", \"B-event\", \"B-cognition\", \"B-event\", \"O\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"B-property\", \"O\"], [\"dna\", \"quantification\", \"methods\", \"based\", \"on\", \"fragment\", \"analysis\", \"show\", \"not\", \"only\", \"the\", \"quantity\", \"of\", \"dna\", \"but\", \"also\", \"fragment\", \"length\", \".\"]], \"y_true\": [\"O\", \"B-event\", \"O\", \"O\", \"O\", \"B-artifact\", \"B-cognition\", \"B-event\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"B-property\", \"O\"]}, {\"x\": [\"considerable\", \"evidence\", \"suggests\", \"that\", \"adolescent\", \"exposure\", \"to\", \"delta\", \"9\", \"tetrahydrocanabinol\", \"thc\", \",\", \"the\", \"psychoactive\", \"component\", \"in\", \"marijuana\", \",\", \"increases\", \"the\", \"risk\", \"of\", \"developing\", \"schizophrenia\", \"related\", \"symptoms\", \"in\", \"early\", \"adulthood\", \".\"], \"y_predicted\": [[\"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"B-property\", \"O\", \"B-geological_formation\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"considerable\", \"evidence\", \"suggests\", \"that\", \"adolescent\", \"exposure\", \"to\", \"delta\", \"9\", \"tetrahydrocanabinol\", \"thc\", \",\", \"the\", \"psychoactive\", \"component\", \"in\", \"marijuana\", \",\", \"increases\", \"the\", \"risk\", \"of\", \"developing\", \"schizophrenia\", \"related\", \"symptoms\", \"in\", \"early\", \"adulthood\", \".\"]], \"y_true\": [\"O\", \"B-cognition\", \"O\", \"O\", \"B-living_thing\", \"B-property\", \"O\", \"B-geological_formation\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-time_period\", \"O\"]}, {\"x\": [\"in\", \"the\", \"present\", \"study\", \",\", \"we\", \"used\", \"a\", \"combination\", \"of\", \"behavioral\", \"and\", \"molecular\", \"analyses\", \"with\", \"in\", \"vivo\", \"neuronal\", \"electrophysiology\", \"to\", \"compare\", \"the\", \"long\", \"termeffects\", \"of\", \"adolescent\", \"versus\", \"adulthood\", \"thc\", \"exposure\", \"in\", \"rats\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"B-time\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\"], [\"in\", \"the\", \"present\", \"study\", \",\", \"we\", \"used\", \"a\", \"combination\", \"of\", \"behavioral\", \"and\", \"molecular\", \"analyses\", \"with\", \"in\", \"vivo\", \"neuronal\", \"electrophysiology\", \"to\", \"compare\", \"the\", \"long\", \"termeffects\", \"of\", \"adolescent\", \"versus\", \"adulthood\", \"thc\", \"exposure\", \"in\", \"rats\", \".\"]], \"y_true\": [\"O\", \"O\", \"B-time\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"B-time_period\", \"O\", \"B-property\", \"O\", \"O\", \"O\"]}, {\"x\": [\"we\", \"report\", \"that\", \"adolescent\", \",\", \"but\", \"not\", \"adult\", \",\", \"thc\", \"exposure\", \"induces\", \"long\", \"term\", \"neuropsychiatric\", \"like\", \"phenotypes\", \"similar\", \"to\", \"those\", \"observed\", \"in\", \"clinical\", \"populations\", \".\"], \"y_predicted\": [[\"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"B-artifact\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"we\", \"report\", \"that\", \"adolescent\", \",\", \"but\", \"not\", \"adult\", \",\", \"thc\", \"exposure\", \"induces\", \"long\", \"term\", \"neuropsychiatric\", \"like\", \"phenotypes\", \"similar\", \"to\", \"those\", \"observed\", \"in\", \"clinical\", \"populations\", \".\"]], \"y_true\": [\"O\", \"B-event\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"B-cognition\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"thus\", \",\", \"adolescent\", \"thc\", \"exposure\", \"induced\", \"behavioral\", \"abnormalities\", \"resembling\", \"positive\", \"and\", \"negative\", \"schizophrenia\", \"related\", \"endophenotypes\", \"and\", \"a\", \"state\", \"of\", \"neuronal\", \"hyperactivity\", \"in\", \"the\", \"mesocorticolimbic\", \"dopamine\", \"da\", \"pathway\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-location\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\"], [\"thus\", \",\", \"adolescent\", \"thc\", \"exposure\", \"induced\", \"behavioral\", \"abnormalities\", \"resembling\", \"positive\", \"and\", \"negative\", \"schizophrenia\", \"related\", \"endophenotypes\", \"and\", \"a\", \"state\", \"of\", \"neuronal\", \"hyperactivity\", \"in\", \"the\", \"mesocorticolimbic\", \"dopamine\", \"da\", \"pathway\", \".\"]], \"y_true\": [\"O\", \"O\", \"B-living_thing\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-location\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\"]}, {\"x\": [\"furthermore\", \",\", \"we\", \"observed\", \"profound\", \"alterations\", \"in\", \"several\", \"prefrontal\", \"cortical\", \"molecular\", \"pathways\", \"consistent\", \"with\", \"sub\", \"cortical\", \"daergic\", \"dysregulation\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\"], [\"furthermore\", \",\", \"we\", \"observed\", \"profound\", \"alterations\", \"in\", \"several\", \"prefrontal\", \"cortical\", \"molecular\", \"pathways\", \"consistent\", \"with\", \"sub\", \"cortical\", \"daergic\", \"dysregulation\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"our\", \"findings\", \"demonstrate\", \"a\", \"profound\", \"dissociation\", \"in\", \"relative\", \"risk\", \"profiles\", \"for\", \"adolescent\", \"versus\", \"adulthood\", \"exposure\", \"to\", \"thc\", \"in\", \"terms\", \"of\", \"neuronal\", \",\", \"behavioral\", \",\", \"and\", \"molecular\", \"markers\", \"resembling\", \"neuropsychiatric\", \"pathology\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"B-natural_process\", \"O\", \"B-living_thing\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\"], [\"our\", \"findings\", \"demonstrate\", \"a\", \"profound\", \"dissociation\", \"in\", \"relative\", \"risk\", \"profiles\", \"for\", \"adolescent\", \"versus\", \"adulthood\", \"exposure\", \"to\", \"thc\", \"in\", \"terms\", \"of\", \"neuronal\", \",\", \"behavioral\", \",\", \"and\", \"molecular\", \"markers\", \"resembling\", \"neuropsychiatric\", \"pathology\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"B-living_thing\", \"B-event\", \"O\", \"O\", \"B-living_thing\", \"O\", \"B-time_period\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\"]}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 17:01:21.468 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 4290 tokens with 973 phrases; found: 940 phrases; correct: 0.\n",
      "\n",
      "precision:  60.00%; recall:  57.97%; FB1:  58.96\n",
      "\n",
      "\tO: precision:  60.00%; recall:  35.29%; F1:  44.44 20\n",
      "\n",
      "\tartifact: precision:  70.59%; recall:  57.14%; F1:  63.16 119\n",
      "\n",
      "\tcognition: precision:  58.25%; recall:  61.08%; F1:  59.63 194\n",
      "\n",
      "\teconomic_process: precision:  9.09%; recall:  25.00%; F1:  13.33 11\n",
      "\n",
      "\tevent: precision:  58.65%; recall:  58.65%; F1:  58.65 266\n",
      "\n",
      "\tgeological_formation: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\thuman_process: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tland: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tliving_thing: precision:  79.49%; recall:  73.81%; F1:  76.54 117\n",
      "\n",
      "\tlocation: precision:  61.90%; recall:  50.00%; F1:  55.32 21\n",
      "\n",
      "\tmotivation: precision:  66.67%; recall:  100.00%; F1:  80.00 3\n",
      "\n",
      "\tnatural_object: precision:  33.33%; recall:  30.00%; F1:  31.58 9\n",
      "\n",
      "\tnatural_process: precision:  25.00%; recall:  50.00%; F1:  33.33 8\n",
      "\n",
      "\torganic_process: precision:  44.44%; recall:  17.39%; F1:  25.00 9\n",
      "\n",
      "\tproperty: precision:  39.34%; recall:  55.81%; F1:  46.15 61\n",
      "\n",
      "\tquality: precision:  50.00%; recall:  50.79%; F1:  50.39 64\n",
      "\n",
      "\ttime: precision:  60.00%; recall:  75.00%; F1:  66.67 5\n",
      "\n",
      "\ttime_interval: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
      "\n",
      "\ttime_period: precision:  65.38%; recall:  70.83%; F1:  68.00 26\n",
      "\n",
      "\ttime_unit: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
      "\n",
      "\tvalue: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"test\": {\"eval_examples_count\": 222, \"metrics\": {\"ner_f1\": 58.965}, \"time_spent\": \"0:00:02\", \"examples\": [{\"x\": [\"ber\", \"ep4\", \"and\", \"cd44v6\", \"were\", \"shown\", \"to\", \"be\", \"great\", \"markers\", \"for\", \"detecting\", \"lnmm\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"ber\", \"ep4\", \"and\", \"cd44v6\", \"were\", \"shown\", \"to\", \"be\", \"great\", \"markers\", \"for\", \"detecting\", \"lnmm\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"B-event\", \"O\", \"O\"]}, {\"x\": [\"aims\", \"human\", \"papillomavirus\", \"hpv\", \"is\", \"known\", \"as\", \"causative\", \"for\", \"squamous\", \"cell\", \"carcinoma\", \"scc\", \"of\", \"the\", \"oropharynx\", \",\", \"but\", \"is\", \"also\", \"found\", \"not\", \"infrequently\", \"in\", \"carcinomas\", \"of\", \"the\", \"sinonasal\", \"tract\", \".\"], \"y_predicted\": [[\"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-location\", \"O\"], [\"aims\", \"human\", \"papillomavirus\", \"hpv\", \"is\", \"known\", \"as\", \"causative\", \"for\", \"squamous\", \"cell\", \"carcinoma\", \"scc\", \"of\", \"the\", \"oropharynx\", \",\", \"but\", \"is\", \"also\", \"found\", \"not\", \"infrequently\", \"in\", \"carcinomas\", \"of\", \"the\", \"sinonasal\", \"tract\", \".\"]], \"y_true\": [\"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-location\", \"O\"]}, {\"x\": [\"recently\", \",\", \"a\", \"subset\", \"of\", \"these\", \"carcinomas\", \"was\", \"recognized\", \"to\", \"harbour\", \"hpv33\", \"and\", \"have\", \"a\", \"significant\", \"morphological\", \"overlap\", \"with\", \"adenoid\", \"cystic\", \"carcinoma\", \"acc\", \",\", \"a\", \"rare\", \"and\", \"aggressive\", \"carcinoma\", \"originating\", \"in\", \"the\", \"minor\", \"salivary\", \"glands\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\"], [\"recently\", \",\", \"a\", \"subset\", \"of\", \"these\", \"carcinomas\", \"was\", \"recognized\", \"to\", \"harbour\", \"hpv33\", \"and\", \"have\", \"a\", \"significant\", \"morphological\", \"overlap\", \"with\", \"adenoid\", \"cystic\", \"carcinoma\", \"acc\", \",\", \"a\", \"rare\", \"and\", \"aggressive\", \"carcinoma\", \"originating\", \"in\", \"the\", \"minor\", \"salivary\", \"glands\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-location\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\"]}, {\"x\": [\"termed\", \"'hpv\", \"related\", \"carcinoma\", \"with\", \"acc\", \"like\", \"features'\", \",\", \"only\", \"nine\", \"cases\", \"have\", \"been\", \"reported\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\"], [\"termed\", \"'hpv\", \"related\", \"carcinoma\", \"with\", \"acc\", \"like\", \"features'\", \",\", \"only\", \"nine\", \"cases\", \"have\", \"been\", \"reported\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\"]}, {\"x\": [\"to\", \"clarify\", \"the\", \"occurrence\", \"of\", \"these\", \"tumours\", \"we\", \"screened\", \"a\", \"large\", \"material\", \"for\", \"the\", \"presence\", \"of\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"B-living_thing\", \"O\", \"O\", \"B-location\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\"], [\"to\", \"clarify\", \"the\", \"occurrence\", \"of\", \"these\", \"tumours\", \"we\", \"screened\", \"a\", \"large\", \"material\", \"for\", \"the\", \"presence\", \"of\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"B-artifact\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\"]}, {\"x\": [\"the\", \"identified\", \"tumours\", \"were\", \"characterized\", \"immunohistochemically\", \"and\", \"with\", \"fluorescence\", \"in\", \"situ\", \"hybridization\", \",\", \"and\", \"clinicopathological\", \"information\", \"for\", \"all\", \"cases\", \"is\", \"presented\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"identified\", \"tumours\", \"were\", \"characterized\", \"immunohistochemically\", \"and\", \"with\", \"fluorescence\", \"in\", \"situ\", \"hybridization\", \",\", \"and\", \"clinicopathological\", \"information\", \"for\", \"all\", \"cases\", \"is\", \"presented\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"methods\", \"and\", \"results\", \"forty\", \"seven\", \"candidate\", \"cases\", \"were\", \"screened\", \"for\", \"presence\", \"of\", \"hpv\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\"], [\"methods\", \"and\", \"results\", \"forty\", \"seven\", \"candidate\", \"cases\", \"were\", \"screened\", \"for\", \"presence\", \"of\", \"hpv\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\"]}, {\"x\": [\"six\", \"cases\", \"were\", \"identified\", \"and\", \"genotyped\", \"as\", \"hpv\", \"types\", \"33\", \",\", \"35\", \",\", \"and\", \"56\", \".\"], \"y_predicted\": [[\"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"six\", \"cases\", \"were\", \"identified\", \"and\", \"genotyped\", \"as\", \"hpv\", \"types\", \"33\", \",\", \"35\", \",\", \"and\", \"56\", \".\"]], \"y_true\": [\"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"all\", \"six\", \"cases\", \"had\", \"areas\", \"of\", \"dysplastic\", \"mucosal\", \"lining\", \"and\", \"showed\", \"remarkable\", \"heterogeneous\", \"morphologies\", \".\"], \"y_predicted\": [[\"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"all\", \"six\", \"cases\", \"had\", \"areas\", \"of\", \"dysplastic\", \"mucosal\", \"lining\", \"and\", \"showed\", \"remarkable\", \"heterogeneous\", \"morphologies\", \".\"]], \"y_true\": [\"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"myb\", \",\", \"mybl1\", \",\", \"and\", \"nfib\", \"genes\", \"were\", \"intact\", \"and\", \",\", \"interestingly\", \",\", \"staining\", \"for\", \"myb\", \"protein\", \"was\", \"largely\", \"negative\", \"in\", \"contrast\", \"to\", \"what\", \"was\", \"found\", \"in\", \"acc\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"myb\", \",\", \"mybl1\", \",\", \"and\", \"nfib\", \"genes\", \"were\", \"intact\", \"and\", \",\", \"interestingly\", \",\", \"staining\", \"for\", \"myb\", \"protein\", \"was\", \"largely\", \"negative\", \"in\", \"contrast\", \"to\", \"what\", \"was\", \"found\", \"in\", \"acc\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"one\", \"patient\", \"experienced\", \"a\", \"local\", \"recurrence\", \"11\", \"years\", \"after\", \"initial\", \"treatment\", \"and\", \"the\", \"remaining\", \"five\", \"patients\", \"were\", \"alive\", \"without\", \"evidence\", \"of\", \"disease\", \".\"], \"y_predicted\": [[\"B-cognition\", \"B-living_thing\", \"O\", \"O\", \"B-artifact\", \"B-event\", \"O\", \"B-time_period\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\"], [\"one\", \"patient\", \"experienced\", \"a\", \"local\", \"recurrence\", \"11\", \"years\", \"after\", \"initial\", \"treatment\", \"and\", \"the\", \"remaining\", \"five\", \"patients\", \"were\", \"alive\", \"without\", \"evidence\", \"of\", \"disease\", \".\"]], \"y_true\": [\"B-cognition\", \"B-living_thing\", \"O\", \"O\", \"B-artifact\", \"B-event\", \"O\", \"B-time_period\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\"]}, {\"x\": [\"conclusion\", \"we\", \"report\", \"six\", \"new\", \"cases\", \"of\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \"and\", \"found\", \"that\", \",\", \"although\", \"in\", \"a\", \"small\", \"material\", \",\", \"the\", \"prognosis\", \"for\", \"these\", \"patients\", \"seems\", \"more\", \"favourable\", \"than\", \"for\", \"acc\", \".\"], \"y_predicted\": [[\"B-cognition\", \"O\", \"B-event\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"B-living_thing\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"conclusion\", \"we\", \"report\", \"six\", \"new\", \"cases\", \"of\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \"and\", \"found\", \"that\", \",\", \"although\", \"in\", \"a\", \"small\", \"material\", \",\", \"the\", \"prognosis\", \"for\", \"these\", \"patients\", \"seems\", \"more\", \"favourable\", \"than\", \"for\", \"acc\", \".\"]], \"y_true\": [\"B-event\", \"O\", \"B-cognition\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"B-artifact\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"for\", \"the\", \"distinction\", \"between\", \"acc\", \"and\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \",\", \"p16\", \",\", \"myb\", \"immunohistochemistry\", \"or\", \"investigation\", \"of\", \"myb\", \",\", \"mybl1\", \"and\", \"nfib\", \"gene\", \"status\", \"are\", \"valuable\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"for\", \"the\", \"distinction\", \"between\", \"acc\", \"and\", \"hpv\", \"related\", \"acc\", \"like\", \"carcinoma\", \",\", \"p16\", \",\", \"myb\", \"immunohistochemistry\", \"or\", \"investigation\", \"of\", \"myb\", \",\", \"mybl1\", \"and\", \"nfib\", \"gene\", \"status\", \"are\", \"valuable\", \".\"]], \"y_true\": [\"O\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"the\", \"aim\", \"of\", \"the\", \"present\", \"study\", \"was\", \"to\", \"investigate\", \"the\", \"role\", \"of\", \"chemokine\", \"c\", \"x\", \"c\", \"motif\", \"ligand\", \"12\", \"cxcl12\", \"and\", \"its\", \"receptor\", \",\", \"chemokine\", \"c\", \"x\", \"c\", \"motif\", \"receptor\", \"4\", \"cxcr4\", \"in\", \"the\", \"pathogenesis\", \"of\", \"adenomyosis\", \"ad\", \".\"], \"y_predicted\": [[\"O\", \"B-location\", \"O\", \"O\", \"B-time\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"aim\", \"of\", \"the\", \"present\", \"study\", \"was\", \"to\", \"investigate\", \"the\", \"role\", \"of\", \"chemokine\", \"c\", \"x\", \"c\", \"motif\", \"ligand\", \"12\", \"cxcl12\", \"and\", \"its\", \"receptor\", \",\", \"chemokine\", \"c\", \"x\", \"c\", \"motif\", \"receptor\", \"4\", \"cxcr4\", \"in\", \"the\", \"pathogenesis\", \"of\", \"adenomyosis\", \"ad\", \".\"]], \"y_true\": [\"O\", \"B-event\", \"O\", \"O\", \"B-time\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"immunohistochemistry\", \"and\", \"reverse\", \"transcription\", \"quantitative\", \"polymerase\", \"chain\", \"reaction\", \"analysis\", \"were\", \"used\", \"to\", \"measure\", \"the\", \"protein\", \"and\", \"mrna\", \"expression\", \"of\", \"cxcl12\", \"and\", \"cxcr4\", \"in\", \"eutopic\", \"endometrial\", \"and\", \"ectopic\", \"foci\", \"tissue\", \"samples\", \".\"], \"y_predicted\": [[\"B-event\", \"O\", \"B-event\", \"B-event\", \"O\", \"O\", \"B-geological_formation\", \"I-geological_formation\", \"B-event\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"immunohistochemistry\", \"and\", \"reverse\", \"transcription\", \"quantitative\", \"polymerase\", \"chain\", \"reaction\", \"analysis\", \"were\", \"used\", \"to\", \"measure\", \"the\", \"protein\", \"and\", \"mrna\", \"expression\", \"of\", \"cxcl12\", \"and\", \"cxcr4\", \"in\", \"eutopic\", \"endometrial\", \"and\", \"ectopic\", \"foci\", \"tissue\", \"samples\", \".\"]], \"y_true\": [\"B-event\", \"O\", \"B-event\", \"B-artifact\", \"O\", \"O\", \"B-artifact\", \"I-artifact\", \"B-cognition\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"samples\", \"from\", \"a\", \"total\", \"of\", \"36\", \"patients\", \"with\", \"ad\", \"study\", \"group\", \"were\", \"compared\", \"with\", \"endometrial\", \"tissue\", \"samples\", \"from\", \"33\", \"patients\", \"who\", \"underwent\", \"uterine\", \"fibroids\", \"surgery\", \"control\", \"group\", \"during\", \"the\", \"same\", \"period\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\", \"B-time_interval\", \"O\"], [\"samples\", \"from\", \"a\", \"total\", \"of\", \"36\", \"patients\", \"with\", \"ad\", \"study\", \"group\", \"were\", \"compared\", \"with\", \"endometrial\", \"tissue\", \"samples\", \"from\", \"33\", \"patients\", \"who\", \"underwent\", \"uterine\", \"fibroids\", \"surgery\", \"control\", \"group\", \"during\", \"the\", \"same\", \"period\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"B-time\", \"O\"]}, {\"x\": [\"all\", \"data\", \"are\", \"presented\", \"as\", \"the\", \"mean\", \"standard\", \"deviation\", \"and\", \"were\", \"analyzed\", \"with\", \"spss\", \"software\", \"version\", \"16\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"B-cognition\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\"], [\"all\", \"data\", \"are\", \"presented\", \"as\", \"the\", \"mean\", \"standard\", \"deviation\", \"and\", \"were\", \"analyzed\", \"with\", \"spss\", \"software\", \"version\", \"16\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"B-artifact\", \"I-quality\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\"]}, {\"x\": [\"0\", \".\"], \"y_predicted\": [[\"O\", \"O\"], [\"0\", \".\"]], \"y_true\": [\"O\", \"O\"]}, {\"x\": [\"analysis\", \"of\", \"variance\", \"was\", \"used\", \"for\", \"between\", \"group\", \"analysis\", \"and\", \"pairwise\", \"comparison\", \"was\", \"performed\", \"using\", \"fisher's\", \"least\", \"significant\", \"difference\", \"post\", \"hoc\", \"test\", \".\"], \"y_predicted\": [[\"B-cognition\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-cognition\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"B-quality\", \"B-artifact\", \"O\", \"B-natural_object\", \"O\"], [\"analysis\", \"of\", \"variance\", \"was\", \"used\", \"for\", \"between\", \"group\", \"analysis\", \"and\", \"pairwise\", \"comparison\", \"was\", \"performed\", \"using\", \"fisher's\", \"least\", \"significant\", \"difference\", \"post\", \"hoc\", \"test\", \".\"]], \"y_true\": [\"B-event\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"B-quality\", \"B-event\", \"I-artifact\", \"B-natural_object\", \"O\"]}, {\"x\": [\"the\", \"results\", \"of\", \"the\", \"present\", \"study\", \"revealed\", \"that\", \"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"was\", \"significantly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"compared\", \"with\", \"eutopic\", \"endometrial\", \"tissue\", \"samples\", \"from\", \"patients\", \"with\", \"ad\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"B-time\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"results\", \"of\", \"the\", \"present\", \"study\", \"revealed\", \"that\", \"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"was\", \"significantly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"compared\", \"with\", \"eutopic\", \"endometrial\", \"tissue\", \"samples\", \"from\", \"patients\", \"with\", \"ad\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"B-time\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"in\", \"ectopic\", \"foci\", \"and\", \"eutopic\", \"endometrial\", \"tissue\", \"samples\", \"were\", \"significantly\", \"increased\", \"compared\", \"with\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\"], [\"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"in\", \"ectopic\", \"foci\", \"and\", \"eutopic\", \"endometrial\", \"tissue\", \"samples\", \"were\", \"significantly\", \"increased\", \"compared\", \"with\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"no\", \"significant\", \"differences\", \"were\", \"identified\", \"in\", \"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"between\", \"the\", \"proliferative\", \"and\", \"secretory\", \"phases\", \"within\", \"each\", \"group\", \".\"], \"y_predicted\": [[\"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"no\", \"significant\", \"differences\", \"were\", \"identified\", \"in\", \"cxcl12\", \"and\", \"cxcr4\", \"protein\", \"expression\", \"between\", \"the\", \"proliferative\", \"and\", \"secretory\", \"phases\", \"within\", \"each\", \"group\", \".\"]], \"y_true\": [\"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"furthermore\", \",\", \"cxcl12\", \"and\", \"cxcr4\", \"mrna\", \"expression\", \"was\", \"significantly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"and\", \"eutopic\", \"endometrial\", \"tissue\", \"compared\", \"with\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\"], [\"furthermore\", \",\", \"cxcl12\", \"and\", \"cxcr4\", \"mrna\", \"expression\", \"was\", \"significantly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"and\", \"eutopic\", \"endometrial\", \"tissue\", \"compared\", \"with\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-artifact\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"cxcl12\", \"mrna\", \"expression\", \"was\", \"markedly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"compared\", \"with\", \"eutopic\", \"endometrial\", \"tissue\", \"of\", \"patients\", \"with\", \"ad\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"cxcl12\", \"mrna\", \"expression\", \"was\", \"markedly\", \"increased\", \"in\", \"ectopic\", \"foci\", \"tissue\", \"compared\", \"with\", \"eutopic\", \"endometrial\", \"tissue\", \"of\", \"patients\", \"with\", \"ad\", \".\"]], \"y_true\": [\"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"the\", \"expression\", \"of\", \"cxcr4\", \"mrna\", \"was\", \"significantly\", \"increased\", \"in\", \"eutopic\", \"endometrial\", \"tissue\", \"compared\", \"with\", \"ectopic\", \"foci\", \"tissue\", \"and\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"], \"y_predicted\": [[\"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\"], [\"the\", \"expression\", \"of\", \"cxcr4\", \"mrna\", \"was\", \"significantly\", \"increased\", \"in\", \"eutopic\", \"endometrial\", \"tissue\", \"compared\", \"with\", \"ectopic\", \"foci\", \"tissue\", \"and\", \"the\", \"control\", \"group\", \"p\", \"0\", \".\"]], \"y_true\": [\"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-quality\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"], \"y_predicted\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"05\", \"for\", \"between\", \"group\", \"comparisons\", \".\"]], \"y_true\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"no\", \"significant\", \"differences\", \"were\", \"identified\", \"in\", \"cxcl12\", \"and\", \"cxcr4\", \"mrna\", \"expression\", \"between\", \"proliferative\", \"and\", \"secretory\", \"phase\", \"within\", \"each\", \"group\", \".\"], \"y_predicted\": [[\"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"B-time_period\", \"O\", \"O\", \"O\", \"O\"], [\"no\", \"significant\", \"differences\", \"were\", \"identified\", \"in\", \"cxcl12\", \"and\", \"cxcr4\", \"mrna\", \"expression\", \"between\", \"proliferative\", \"and\", \"secretory\", \"phase\", \"within\", \"each\", \"group\", \".\"]], \"y_true\": [\"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"B-O\", \"I-O\", \"O\", \"O\", \"O\", \"O\"]}, {\"x\": [\"in\", \"conclusion\", \",\", \"cxcl12\", \"and\", \"cxcr4\", \"may\", \"induce\", \"the\", \"ectopia\", \",\", \"and\", \"promote\", \"the\", \"spread\", \"and\", \"localized\", \"growth\", \"of\", \"endometrial\", \"cells\", \"in\", \"the\", \"development\", \"of\", \"ad\", \".\"], \"y_predicted\": [[\"O\", \"B-cognition\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-location\", \"O\", \"O\", \"B-organic_process\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-location\", \"O\", \"O\", \"O\"], [\"in\", \"conclusion\", \",\", \"cxcl12\", \"and\", \"cxcr4\", \"may\", \"induce\", \"the\", \"ectopia\", \",\", \"and\", \"promote\", \"the\", \"spread\", \"and\", \"localized\", \"growth\", \"of\", \"endometrial\", \"cells\", \"in\", \"the\", \"development\", \"of\", \"ad\", \".\"]], \"y_true\": [\"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"B-living_thing\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"O\", \"O\", \"B-property\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-event\", \"O\", \"O\", \"O\"]}]}}\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.commands.train import train_evaluate_model_from_config\n",
    "\n",
    "config[\"train\"][\"show_examples\"] = True\n",
    "model2 = train_evaluate_model_from_config(config, to_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmak44sAOYlU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RPF76BPWJVv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Trees_copy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
